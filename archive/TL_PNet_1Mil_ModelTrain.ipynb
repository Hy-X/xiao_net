{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "e2ee661e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python\n",
    "# coding: utf-8\n",
    "\n",
    "import obspy\n",
    "from obspy.clients.fdsn import Client\n",
    "from obspy import UTCDateTime\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import torch\n",
    "\n",
    "import json\n",
    "import time\n",
    "\n",
    "import seisbench.models as sbm\n",
    "import seisbench.data as sbd\n",
    "import seisbench.generate as sbg\n",
    "\n",
    "from seisbench.util import worker_seeding\n",
    "from torch.utils.data import DataLoader\n",
    "from obspy.clients.fdsn import Client\n",
    "from scipy.signal import find_peaks\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "c7482716",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load configuration from JSON file\n",
    "with open('config.json', 'r') as f:\n",
    "    config = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "96b06235",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'peak_detection': {'sampling_rate': 100, 'height': 0.5, 'distance': 100},\n",
       " 'training': {'batch_size': 64,\n",
       "  'num_workers': 4,\n",
       "  'learning_rate': 0.01,\n",
       "  'epochs': 50,\n",
       "  'patience': 5,\n",
       "  'loss_weights': [0.01, 0.4, 0.59],\n",
       "  'optimization': {'mixed_precision': True,\n",
       "   'gradient_accumulation_steps': 1,\n",
       "   'pin_memory': True,\n",
       "   'prefetch_factor': 2,\n",
       "   'persistent_workers': True}},\n",
       " 'device': {'use_cuda': True, 'device_id': 0}}"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "1cac5493",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set random seed for reproducibility\n",
    "import random\n",
    "random.seed(0)\n",
    "np.random.seed(0)\n",
    "torch.manual_seed(0)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "6f080377",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# Loader the picker\n",
    "#model = sbm.EQTransformer.from_pretrained(\"original\")\n",
    "model = sbm.PhaseNet.from_pretrained(\"stead\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "9c820e56",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "PhaseNet(\n",
       "  (inc): Conv1d(3, 8, kernel_size=(7,), stride=(1,), padding=same)\n",
       "  (in_bn): BatchNorm1d(8, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (down_branch): ModuleList(\n",
       "    (0): ModuleList(\n",
       "      (0): Conv1d(8, 8, kernel_size=(7,), stride=(1,), padding=same, bias=False)\n",
       "      (1): BatchNorm1d(8, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): Conv1d(8, 8, kernel_size=(7,), stride=(4,), padding=(3,), bias=False)\n",
       "      (3): BatchNorm1d(8, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (1): ModuleList(\n",
       "      (0): Conv1d(8, 16, kernel_size=(7,), stride=(1,), padding=same, bias=False)\n",
       "      (1): BatchNorm1d(16, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): Conv1d(16, 16, kernel_size=(7,), stride=(4,), bias=False)\n",
       "      (3): BatchNorm1d(16, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (2): ModuleList(\n",
       "      (0): Conv1d(16, 32, kernel_size=(7,), stride=(1,), padding=same, bias=False)\n",
       "      (1): BatchNorm1d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): Conv1d(32, 32, kernel_size=(7,), stride=(4,), bias=False)\n",
       "      (3): BatchNorm1d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (3): ModuleList(\n",
       "      (0): Conv1d(32, 64, kernel_size=(7,), stride=(1,), padding=same, bias=False)\n",
       "      (1): BatchNorm1d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): Conv1d(64, 64, kernel_size=(7,), stride=(4,), bias=False)\n",
       "      (3): BatchNorm1d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (4): ModuleList(\n",
       "      (0): Conv1d(64, 128, kernel_size=(7,), stride=(1,), padding=same, bias=False)\n",
       "      (1): BatchNorm1d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2-3): 2 x None\n",
       "    )\n",
       "  )\n",
       "  (up_branch): ModuleList(\n",
       "    (0): ModuleList(\n",
       "      (0): ConvTranspose1d(128, 64, kernel_size=(7,), stride=(4,), bias=False)\n",
       "      (1): BatchNorm1d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): Conv1d(128, 64, kernel_size=(7,), stride=(1,), padding=same, bias=False)\n",
       "      (3): BatchNorm1d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (1): ModuleList(\n",
       "      (0): ConvTranspose1d(64, 32, kernel_size=(7,), stride=(4,), bias=False)\n",
       "      (1): BatchNorm1d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): Conv1d(64, 32, kernel_size=(7,), stride=(1,), padding=same, bias=False)\n",
       "      (3): BatchNorm1d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (2): ModuleList(\n",
       "      (0): ConvTranspose1d(32, 16, kernel_size=(7,), stride=(4,), bias=False)\n",
       "      (1): BatchNorm1d(16, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): Conv1d(32, 16, kernel_size=(7,), stride=(1,), padding=same, bias=False)\n",
       "      (3): BatchNorm1d(16, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (3): ModuleList(\n",
       "      (0): ConvTranspose1d(16, 8, kernel_size=(7,), stride=(4,), bias=False)\n",
       "      (1): BatchNorm1d(8, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): Conv1d(16, 8, kernel_size=(7,), stride=(1,), padding=same, bias=False)\n",
       "      (3): BatchNorm1d(8, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (out): Conv1d(8, 3, kernel_size=(1,), stride=(1,), padding=same)\n",
       "  (softmax): Softmax(dim=1)\n",
       ")"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Set up device\n",
    "device = torch.device(f\"cuda:{config['device']['device_id']}\" if torch.cuda.is_available() and config['device']['use_cuda'] else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "model.to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "33f94ec8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data...\n"
     ]
    }
   ],
   "source": [
    "# Load the data\n",
    "print(\"Loading data...\")\n",
    "data = sbd.OKLA_1Mil_120s_Ver_3(sampling_rate=100, force=True, component_order=\"ENZ\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "f44060f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating random sample of 2.0% of the data...\n"
     ]
    }
   ],
   "source": [
    "# Create a random sample\n",
    "sample_fraction = 0.02  # Sample 20% of the data\n",
    "print(f\"Creating random sample of {sample_fraction*100}% of the data...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "6ed9bc20",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sampled dataset size: 22782\n"
     ]
    }
   ],
   "source": [
    "# Create a random mask for sampling\n",
    "np.random.seed(42)  # For reproducibility\n",
    "\n",
    "mask = np.random.random(len(data)) < sample_fraction\n",
    "data.filter(mask)\n",
    "\n",
    "print(f\"Sampled dataset size: {len(data)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "189aeaa1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample metadata:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>station_network_code</th>\n",
       "      <th>station_code</th>\n",
       "      <th>trace_channel</th>\n",
       "      <th>station_latitude_deg</th>\n",
       "      <th>station_longitude_deg</th>\n",
       "      <th>station_elevation_m</th>\n",
       "      <th>trace_p_arrival_sample</th>\n",
       "      <th>trace_p_status</th>\n",
       "      <th>trace_p_weight</th>\n",
       "      <th>...</th>\n",
       "      <th>trace_snr_db</th>\n",
       "      <th>trace_coda_end_sample</th>\n",
       "      <th>trace_start_time</th>\n",
       "      <th>trace_category</th>\n",
       "      <th>trace_name</th>\n",
       "      <th>split</th>\n",
       "      <th>trace_name_original</th>\n",
       "      <th>trace_chunk</th>\n",
       "      <th>trace_sampling_rate_hz</th>\n",
       "      <th>trace_component_order</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>72</td>\n",
       "      <td>2V</td>\n",
       "      <td>TG11</td>\n",
       "      <td>EHE</td>\n",
       "      <td>35.2689</td>\n",
       "      <td>-97.8146</td>\n",
       "      <td>407.0</td>\n",
       "      <td>6000.0</td>\n",
       "      <td>manual</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2023-09-11T10:04:26.195000Z</td>\n",
       "      <td>earthquake_local</td>\n",
       "      <td>bucket0$53,:3,:12001</td>\n",
       "      <td>train</td>\n",
       "      <td>2V.TG11.EHE.EHN.EHZ.2023-09-11T1004262023-09-1...</td>\n",
       "      <td></td>\n",
       "      <td>100</td>\n",
       "      <td>ZNE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128</th>\n",
       "      <td>128</td>\n",
       "      <td>2V</td>\n",
       "      <td>TG11</td>\n",
       "      <td>EHE</td>\n",
       "      <td>35.2689</td>\n",
       "      <td>-97.8146</td>\n",
       "      <td>407.0</td>\n",
       "      <td>6000.0</td>\n",
       "      <td>manual</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2023-10-15T03:02:11.464999Z</td>\n",
       "      <td>earthquake_local</td>\n",
       "      <td>bucket0$97,:3,:12001</td>\n",
       "      <td>train</td>\n",
       "      <td>2V.TG11.EHE.EHN.EHZ.2023-10-15T0302112023-10-1...</td>\n",
       "      <td></td>\n",
       "      <td>100</td>\n",
       "      <td>ZNE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>171</th>\n",
       "      <td>171</td>\n",
       "      <td>2V</td>\n",
       "      <td>TG11</td>\n",
       "      <td>EHE</td>\n",
       "      <td>35.2689</td>\n",
       "      <td>-97.8146</td>\n",
       "      <td>407.0</td>\n",
       "      <td>6000.0</td>\n",
       "      <td>manual</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2023-11-02T09:08:31.285000Z</td>\n",
       "      <td>earthquake_local</td>\n",
       "      <td>bucket0$124,:3,:12001</td>\n",
       "      <td>train</td>\n",
       "      <td>2V.TG11.EHE.EHN.EHZ.2023-11-02T0908312023-11-0...</td>\n",
       "      <td></td>\n",
       "      <td>100</td>\n",
       "      <td>ZNE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>205</th>\n",
       "      <td>205</td>\n",
       "      <td>2V</td>\n",
       "      <td>TG11</td>\n",
       "      <td>EHE</td>\n",
       "      <td>35.2689</td>\n",
       "      <td>-97.8146</td>\n",
       "      <td>407.0</td>\n",
       "      <td>6000.0</td>\n",
       "      <td>manual</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2023-11-29T04:45:18.075000Z</td>\n",
       "      <td>earthquake_local</td>\n",
       "      <td>bucket5$28,:3,:12001</td>\n",
       "      <td>test</td>\n",
       "      <td>2V.TG11.EHE.EHN.EHZ.2023-11-29T0445182023-11-2...</td>\n",
       "      <td></td>\n",
       "      <td>100</td>\n",
       "      <td>ZNE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>208</th>\n",
       "      <td>208</td>\n",
       "      <td>2V</td>\n",
       "      <td>TG11</td>\n",
       "      <td>EHE</td>\n",
       "      <td>35.2689</td>\n",
       "      <td>-97.8146</td>\n",
       "      <td>407.0</td>\n",
       "      <td>5999.0</td>\n",
       "      <td>manual</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2023-11-30T00:58:44.934999Z</td>\n",
       "      <td>earthquake_local</td>\n",
       "      <td>bucket0$153,:3,:12001</td>\n",
       "      <td>train</td>\n",
       "      <td>2V.TG11.EHE.EHN.EHZ.2023-11-30T0058442023-11-3...</td>\n",
       "      <td></td>\n",
       "      <td>100</td>\n",
       "      <td>ZNE</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 41 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     index station_network_code station_code trace_channel  \\\n",
       "72      72                   2V         TG11           EHE   \n",
       "128    128                   2V         TG11           EHE   \n",
       "171    171                   2V         TG11           EHE   \n",
       "205    205                   2V         TG11           EHE   \n",
       "208    208                   2V         TG11           EHE   \n",
       "\n",
       "     station_latitude_deg  station_longitude_deg  station_elevation_m  \\\n",
       "72                35.2689               -97.8146                407.0   \n",
       "128               35.2689               -97.8146                407.0   \n",
       "171               35.2689               -97.8146                407.0   \n",
       "205               35.2689               -97.8146                407.0   \n",
       "208               35.2689               -97.8146                407.0   \n",
       "\n",
       "     trace_p_arrival_sample trace_p_status  trace_p_weight  ...  trace_snr_db  \\\n",
       "72                   6000.0         manual             1.0  ...           NaN   \n",
       "128                  6000.0         manual             1.0  ...           NaN   \n",
       "171                  6000.0         manual             1.0  ...           NaN   \n",
       "205                  6000.0         manual             1.0  ...           NaN   \n",
       "208                  5999.0         manual             1.0  ...           NaN   \n",
       "\n",
       "     trace_coda_end_sample             trace_start_time    trace_category  \\\n",
       "72                     NaN  2023-09-11T10:04:26.195000Z  earthquake_local   \n",
       "128                    NaN  2023-10-15T03:02:11.464999Z  earthquake_local   \n",
       "171                    NaN  2023-11-02T09:08:31.285000Z  earthquake_local   \n",
       "205                    NaN  2023-11-29T04:45:18.075000Z  earthquake_local   \n",
       "208                    NaN  2023-11-30T00:58:44.934999Z  earthquake_local   \n",
       "\n",
       "                trace_name  split  \\\n",
       "72    bucket0$53,:3,:12001  train   \n",
       "128   bucket0$97,:3,:12001  train   \n",
       "171  bucket0$124,:3,:12001  train   \n",
       "205   bucket5$28,:3,:12001   test   \n",
       "208  bucket0$153,:3,:12001  train   \n",
       "\n",
       "                                   trace_name_original  trace_chunk  \\\n",
       "72   2V.TG11.EHE.EHN.EHZ.2023-09-11T1004262023-09-1...                \n",
       "128  2V.TG11.EHE.EHN.EHZ.2023-10-15T0302112023-10-1...                \n",
       "171  2V.TG11.EHE.EHN.EHZ.2023-11-02T0908312023-11-0...                \n",
       "205  2V.TG11.EHE.EHN.EHZ.2023-11-29T0445182023-11-2...                \n",
       "208  2V.TG11.EHE.EHN.EHZ.2023-11-30T0058442023-11-3...                \n",
       "\n",
       "     trace_sampling_rate_hz  trace_component_order  \n",
       "72                      100                    ZNE  \n",
       "128                     100                    ZNE  \n",
       "171                     100                    ZNE  \n",
       "205                     100                    ZNE  \n",
       "208                     100                    ZNE  \n",
       "\n",
       "[5 rows x 41 columns]"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Sample metadata:\")\n",
    "data.metadata.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "935662b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data\n",
    "train, dev, test = data.train_dev_test()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "0d00a4a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: OKLA_1Mil_120s_Ver_3 - 15909 traces\n",
      "Dev: OKLA_1Mil_120s_Ver_3 - 3429 traces\n",
      "Test: OKLA_1Mil_120s_Ver_3 - 3444 traces\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(\"Train:\", train)\n",
    "print(\"Dev:\", dev)\n",
    "print(\"Test:\", test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "7b87844d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Set up data augmentation\n",
    "\n",
    "phase_dict = {\n",
    "    \"trace_p_arrival_sample\": \"P\",\n",
    "    \"trace_pP_arrival_sample\": \"P\",\n",
    "    \"trace_P_arrival_sample\": \"P\",\n",
    "    \"trace_P1_arrival_sample\": \"P\",\n",
    "    \"trace_Pg_arrival_sample\": \"P\",\n",
    "    \"trace_Pn_arrival_sample\": \"P\",\n",
    "    \"trace_PmP_arrival_sample\": \"P\",\n",
    "    \"trace_pwP_arrival_sample\": \"P\",\n",
    "    \"trace_pwPm_arrival_sample\": \"P\",\n",
    "    \"trace_s_arrival_sample\": \"S\",\n",
    "    \"trace_S_arrival_sample\": \"S\",\n",
    "    \"trace_S1_arrival_sample\": \"S\",\n",
    "    \"trace_Sg_arrival_sample\": \"S\",\n",
    "    \"trace_SmS_arrival_sample\": \"S\",\n",
    "    \"trace_Sn_arrival_sample\": \"S\",\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "6caeb986",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the data generators for training and validation\n",
    "train_generator = sbg.GenericGenerator(train)\n",
    "dev_generator = sbg.GenericGenerator(dev)\n",
    "test_generator = sbg.GenericGenerator(test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "5bce0e53",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define phase lists for labeling\n",
    "p_phases = [key for key, val in phase_dict.items() if val == \"P\"]\n",
    "s_phases = [key for key, val in phase_dict.items() if val == \"S\"]\n",
    "\n",
    "train_generator = sbg.GenericGenerator(train)\n",
    "dev_generator = sbg.GenericGenerator(dev)\n",
    "test_generator = sbg.GenericGenerator(test)\n",
    "\n",
    "augmentations = [\n",
    "    sbg.WindowAroundSample(list(phase_dict.keys()), samples_before=3000, windowlen=6000, selection=\"random\", strategy=\"variable\"),\n",
    "    sbg.RandomWindow(windowlen=3001, strategy=\"pad\"),\n",
    "    sbg.Normalize(demean_axis=-1, detrend_axis=-1, amp_norm_axis=-1, amp_norm_type=\"peak\"),\n",
    "    sbg.ChangeDtype(np.float32),\n",
    "    sbg.ProbabilisticLabeller(sigma=30, dim=0),\n",
    "]\n",
    "\n",
    "train_generator.add_augmentations(augmentations)\n",
    "dev_generator.add_augmentations(augmentations)\n",
    "test_generator.add_augmentations(augmentations)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "45694b35",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters for peak detection\n",
    "sampling_rate = config['peak_detection']['sampling_rate']\n",
    "height = config['peak_detection']['height']\n",
    "distance = config['peak_detection']['distance']\n",
    "\n",
    "batch_size = config['training']['batch_size']\n",
    "num_workers = config['training']['num_workers']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "17af6672",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the data for machine learning\n",
    "\n",
    "train_loader = DataLoader(train_generator,batch_size=batch_size, shuffle=True, num_workers=num_workers, worker_init_fn=worker_seeding,pin_memory=True,prefetch_factor=4,persistent_workers=True)\n",
    "test_loader = DataLoader(test_generator, batch_size=batch_size, shuffle=False, num_workers=num_workers, worker_init_fn=worker_seeding,pin_memory=True,prefetch_factor=4,persistent_workers=True)\n",
    "val_loader = DataLoader(dev_generator, batch_size=batch_size, shuffle=False, num_workers=num_workers, worker_init_fn=worker_seeding,pin_memory=True,prefetch_factor=4,persistent_workers=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "dd3ceba8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define loss function\n",
    "def loss_fn(y_pred, y_true, eps=1e-5):\n",
    "    h = y_true * torch.log(y_pred + eps)\n",
    "    h = h.mean(-1).sum(-1)\n",
    "    h = h.mean()\n",
    "    return -h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "46a133ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Learning rate and number of epochs\n",
    "learning_rate = config['training']['learning_rate']\n",
    "epochs = config['training']['epochs']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "8121db73",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "f0b00d7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# EarlyStopping class\n",
    "class EarlyStopping:\n",
    "    def __init__(self, patience=7, verbose=False, delta=0, checkpoint_path='checkpoint.pt', \n",
    "                 best_model_path='best_model.pth', final_model_path='final_model.pth'):\n",
    "        self.patience = patience\n",
    "        self.verbose = verbose\n",
    "        self.counter = 0\n",
    "        self.best_score = None\n",
    "        self.early_stop = False\n",
    "        self.val_loss_min = float('inf')\n",
    "        self.delta = delta\n",
    "        self.checkpoint_path = checkpoint_path\n",
    "        self.best_model_path = best_model_path\n",
    "        self.final_model_path = final_model_path\n",
    "\n",
    "    def __call__(self, val_loss, model):\n",
    "        score = -val_loss\n",
    "        if self.best_score is None:\n",
    "            self.best_score = score\n",
    "            self.save_checkpoint(val_loss, model)\n",
    "            self.save_best_model(model)\n",
    "        elif score < self.best_score + self.delta:\n",
    "            self.counter += 1\n",
    "            if self.verbose:\n",
    "                print(f'EarlyStopping counter: {self.counter} out of {self.patience}')\n",
    "            if self.counter >= self.patience:\n",
    "                self.early_stop = True\n",
    "                self.save_final_model(model)\n",
    "        else:\n",
    "            self.best_score = score\n",
    "            self.save_checkpoint(val_loss, model)\n",
    "            self.save_best_model(model)\n",
    "            self.counter = 0\n",
    "\n",
    "    def save_checkpoint(self, val_loss, model):\n",
    "        if self.verbose:\n",
    "            print(f'Validation loss decreased ({self.val_loss_min:.6f} --> {val_loss:.6f}). Saving model...')\n",
    "        torch.save(model.state_dict(), self.checkpoint_path)\n",
    "        self.val_loss_min = val_loss\n",
    "\n",
    "    def save_best_model(self, model):\n",
    "        if self.verbose:\n",
    "            print(f'Saving best model to {self.best_model_path}')\n",
    "        torch.save(model.state_dict(), self.best_model_path)\n",
    "\n",
    "    def save_final_model(self, model):\n",
    "        if self.verbose:\n",
    "            print(f'Early stopping triggered. Saving final model to {self.final_model_path}')\n",
    "        torch.save(model.state_dict(), self.final_model_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "f5e97a18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to train for one epoch\n",
    "def train_one_epoch(dataloader, model, loss_fn, optimizer, device):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    size = len(dataloader.dataset)\n",
    "\n",
    "    for batch_id, batch in enumerate(dataloader):\n",
    "        pred = model(batch[\"X\"].to(device))\n",
    "        loss = loss_fn(pred, batch[\"y\"].to(device))\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if batch_id % 5 == 0:\n",
    "            print(f\"loss: {loss.item():>7f}  [{batch_id * len(batch['X']):>5d}/{size:>5d}]\")\n",
    "\n",
    "        total_loss += loss.item()\n",
    "\n",
    "    return total_loss / len(dataloader)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "bd322460",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to evaluate the model\n",
    "def evaluate_model(dataloader, model, loss_fn, device):\n",
    "    model.eval()\n",
    "    val_loss = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in dataloader:\n",
    "            pred = model(batch[\"X\"].to(device))\n",
    "            val_loss += loss_fn(pred, batch[\"y\"].to(device)).item()\n",
    "\n",
    "    return val_loss / len(dataloader)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "ef876741",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to plot training history\n",
    "def plot_training_history(history):\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.plot(history['train_loss'], label='Training Loss')\n",
    "    plt.plot(history['val_loss'], label='Validation Loss')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.title('Training and Validation Loss Over Time')\n",
    "    plt.legend()\n",
    "    plt.grid(True, linestyle='--', alpha=0.6)\n",
    "    plt.fill_between(range(len(history['train_loss'])), \n",
    "                     history['train_loss'], history['val_loss'],\n",
    "                     alpha=0.3, color='red', \n",
    "                     where=(np.array(history['val_loss']) > np.array(history['train_loss'])),\n",
    "                     label='Potential Overfitting Gap')\n",
    "    plt.savefig('training_history.png')\n",
    "    plt.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "41ead9eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/ML/lib/python3.12/site-packages/torch/optim/lr_scheduler.py:28: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
      "  warnings.warn(\"The verbose parameter is deprecated. Please use get_last_lr() \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 0.214218  [    0/15909]\n",
      "loss: 0.134593  [  320/15909]\n",
      "loss: 0.113847  [  640/15909]\n",
      "loss: 0.100160  [  960/15909]\n",
      "loss: 0.092996  [ 1280/15909]\n",
      "loss: 0.105860  [ 1600/15909]\n",
      "loss: 0.081091  [ 1920/15909]\n",
      "loss: 0.084028  [ 2240/15909]\n",
      "loss: 0.077439  [ 2560/15909]\n",
      "loss: 0.076635  [ 2880/15909]\n",
      "loss: 0.085372  [ 3200/15909]\n",
      "loss: 0.074468  [ 3520/15909]\n",
      "loss: 0.077225  [ 3840/15909]\n",
      "loss: 0.079956  [ 4160/15909]\n",
      "loss: 0.075479  [ 4480/15909]\n",
      "loss: 0.084582  [ 4800/15909]\n",
      "loss: 0.081816  [ 5120/15909]\n",
      "loss: 0.074436  [ 5440/15909]\n",
      "loss: 0.066858  [ 5760/15909]\n",
      "loss: 0.083428  [ 6080/15909]\n",
      "loss: 0.081881  [ 6400/15909]\n",
      "loss: 0.067153  [ 6720/15909]\n",
      "loss: 0.069370  [ 7040/15909]\n",
      "loss: 0.074499  [ 7360/15909]\n",
      "loss: 0.071951  [ 7680/15909]\n",
      "loss: 0.077865  [ 8000/15909]\n",
      "loss: 0.071058  [ 8320/15909]\n",
      "loss: 0.074053  [ 8640/15909]\n",
      "loss: 0.068093  [ 8960/15909]\n",
      "loss: 0.062439  [ 9280/15909]\n",
      "loss: 0.085430  [ 9600/15909]\n",
      "loss: 0.072582  [ 9920/15909]\n",
      "loss: 0.061198  [10240/15909]\n",
      "loss: 0.076199  [10560/15909]\n",
      "loss: 0.069212  [10880/15909]\n",
      "loss: 0.072804  [11200/15909]\n",
      "loss: 0.072486  [11520/15909]\n",
      "loss: 0.073234  [11840/15909]\n",
      "loss: 0.073602  [12160/15909]\n",
      "loss: 0.060575  [12480/15909]\n",
      "loss: 0.069801  [12800/15909]\n",
      "loss: 0.063911  [13120/15909]\n",
      "loss: 0.071901  [13440/15909]\n",
      "loss: 0.073369  [13760/15909]\n",
      "loss: 0.072792  [14080/15909]\n",
      "loss: 0.066686  [14400/15909]\n",
      "loss: 0.054938  [14720/15909]\n",
      "loss: 0.067864  [15040/15909]\n",
      "loss: 0.072024  [15360/15909]\n",
      "loss: 0.071247  [15680/15909]\n",
      "Epoch 1 results: Train loss: 0.077890, Val loss: 0.066892\n",
      "Validation loss decreased (inf --> 0.066892). Saving model...\n",
      "Saving best model to best_model.pth\n",
      "Epoch 2/50\n",
      "loss: 0.075451  [    0/15909]\n",
      "loss: 0.065802  [  320/15909]\n",
      "loss: 0.073412  [  640/15909]\n",
      "loss: 0.068876  [  960/15909]\n",
      "loss: 0.072493  [ 1280/15909]\n",
      "loss: 0.060278  [ 1600/15909]\n",
      "loss: 0.061294  [ 1920/15909]\n",
      "loss: 0.071180  [ 2240/15909]\n",
      "loss: 0.065939  [ 2560/15909]\n",
      "loss: 0.062926  [ 2880/15909]\n",
      "loss: 0.070781  [ 3200/15909]\n",
      "loss: 0.056691  [ 3520/15909]\n",
      "loss: 0.068558  [ 3840/15909]\n",
      "loss: 0.059186  [ 4160/15909]\n",
      "loss: 0.065080  [ 4480/15909]\n",
      "loss: 0.059642  [ 4800/15909]\n",
      "loss: 0.061912  [ 5120/15909]\n",
      "loss: 0.058633  [ 5440/15909]\n",
      "loss: 0.065780  [ 5760/15909]\n",
      "loss: 0.065491  [ 6080/15909]\n",
      "loss: 0.062509  [ 6400/15909]\n",
      "loss: 0.066811  [ 6720/15909]\n",
      "loss: 0.072158  [ 7040/15909]\n",
      "loss: 0.061156  [ 7360/15909]\n",
      "loss: 0.061186  [ 7680/15909]\n",
      "loss: 0.066546  [ 8000/15909]\n",
      "loss: 0.067288  [ 8320/15909]\n",
      "loss: 0.065329  [ 8640/15909]\n",
      "loss: 0.071537  [ 8960/15909]\n",
      "loss: 0.067746  [ 9280/15909]\n",
      "loss: 0.079550  [ 9600/15909]\n",
      "loss: 0.070165  [ 9920/15909]\n",
      "loss: 0.059367  [10240/15909]\n",
      "loss: 0.067391  [10560/15909]\n",
      "loss: 0.067689  [10880/15909]\n",
      "loss: 0.071806  [11200/15909]\n",
      "loss: 0.062839  [11520/15909]\n",
      "loss: 0.060049  [11840/15909]\n",
      "loss: 0.060087  [12160/15909]\n",
      "loss: 0.063387  [12480/15909]\n",
      "loss: 0.063336  [12800/15909]\n",
      "loss: 0.069347  [13120/15909]\n",
      "loss: 0.067652  [13440/15909]\n",
      "loss: 0.066918  [13760/15909]\n",
      "loss: 0.063970  [14080/15909]\n",
      "loss: 0.060914  [14400/15909]\n",
      "loss: 0.065208  [14720/15909]\n",
      "loss: 0.064879  [15040/15909]\n",
      "loss: 0.059649  [15360/15909]\n",
      "loss: 0.062773  [15680/15909]\n",
      "Epoch 2 results: Train loss: 0.064984, Val loss: 0.063632\n",
      "Validation loss decreased (0.066892 --> 0.063632). Saving model...\n",
      "Saving best model to best_model.pth\n",
      "Epoch 3/50\n",
      "loss: 0.060380  [    0/15909]\n",
      "loss: 0.073640  [  320/15909]\n",
      "loss: 0.062755  [  640/15909]\n",
      "loss: 0.063370  [  960/15909]\n",
      "loss: 0.069644  [ 1280/15909]\n",
      "loss: 0.061897  [ 1600/15909]\n",
      "loss: 0.059683  [ 1920/15909]\n",
      "loss: 0.065157  [ 2240/15909]\n",
      "loss: 0.057962  [ 2560/15909]\n",
      "loss: 0.062510  [ 2880/15909]\n",
      "loss: 0.058537  [ 3200/15909]\n",
      "loss: 0.058875  [ 3520/15909]\n",
      "loss: 0.063203  [ 3840/15909]\n",
      "loss: 0.065081  [ 4160/15909]\n",
      "loss: 0.061708  [ 4480/15909]\n",
      "loss: 0.064536  [ 4800/15909]\n",
      "loss: 0.059598  [ 5120/15909]\n",
      "loss: 0.059341  [ 5440/15909]\n",
      "loss: 0.056541  [ 5760/15909]\n",
      "loss: 0.056825  [ 6080/15909]\n",
      "loss: 0.057821  [ 6400/15909]\n",
      "loss: 0.060903  [ 6720/15909]\n",
      "loss: 0.072986  [ 7040/15909]\n",
      "loss: 0.059816  [ 7360/15909]\n",
      "loss: 0.066662  [ 7680/15909]\n",
      "loss: 0.065738  [ 8000/15909]\n",
      "loss: 0.058153  [ 8320/15909]\n",
      "loss: 0.063377  [ 8640/15909]\n",
      "loss: 0.062910  [ 8960/15909]\n",
      "loss: 0.061857  [ 9280/15909]\n",
      "loss: 0.065283  [ 9600/15909]\n",
      "loss: 0.060784  [ 9920/15909]\n",
      "loss: 0.072521  [10240/15909]\n",
      "loss: 0.066684  [10560/15909]\n",
      "loss: 0.053668  [10880/15909]\n",
      "loss: 0.071822  [11200/15909]\n",
      "loss: 0.057234  [11520/15909]\n",
      "loss: 0.052798  [11840/15909]\n",
      "loss: 0.056742  [12160/15909]\n",
      "loss: 0.066830  [12480/15909]\n",
      "loss: 0.059161  [12800/15909]\n",
      "loss: 0.062720  [13120/15909]\n",
      "loss: 0.067256  [13440/15909]\n",
      "loss: 0.064991  [13760/15909]\n",
      "loss: 0.062600  [14080/15909]\n",
      "loss: 0.067577  [14400/15909]\n",
      "loss: 0.074536  [14720/15909]\n",
      "loss: 0.063765  [15040/15909]\n",
      "loss: 0.062731  [15360/15909]\n",
      "loss: 0.053492  [15680/15909]\n",
      "Epoch 3 results: Train loss: 0.062911, Val loss: 0.063351\n",
      "Validation loss decreased (0.063632 --> 0.063351). Saving model...\n",
      "Saving best model to best_model.pth\n",
      "Epoch 4/50\n",
      "loss: 0.061454  [    0/15909]\n",
      "loss: 0.059901  [  320/15909]\n",
      "loss: 0.066199  [  640/15909]\n",
      "loss: 0.056228  [  960/15909]\n",
      "loss: 0.061013  [ 1280/15909]\n",
      "loss: 0.060694  [ 1600/15909]\n",
      "loss: 0.061795  [ 1920/15909]\n",
      "loss: 0.061509  [ 2240/15909]\n",
      "loss: 0.069160  [ 2560/15909]\n",
      "loss: 0.062531  [ 2880/15909]\n",
      "loss: 0.058620  [ 3200/15909]\n",
      "loss: 0.055167  [ 3520/15909]\n",
      "loss: 0.055208  [ 3840/15909]\n",
      "loss: 0.061822  [ 4160/15909]\n",
      "loss: 0.060940  [ 4480/15909]\n",
      "loss: 0.061719  [ 4800/15909]\n",
      "loss: 0.067245  [ 5120/15909]\n",
      "loss: 0.049640  [ 5440/15909]\n",
      "loss: 0.059240  [ 5760/15909]\n",
      "loss: 0.058829  [ 6080/15909]\n",
      "loss: 0.066397  [ 6400/15909]\n",
      "loss: 0.056573  [ 6720/15909]\n",
      "loss: 0.067950  [ 7040/15909]\n",
      "loss: 0.056011  [ 7360/15909]\n",
      "loss: 0.068827  [ 7680/15909]\n",
      "loss: 0.072635  [ 8000/15909]\n",
      "loss: 0.048528  [ 8320/15909]\n",
      "loss: 0.060082  [ 8640/15909]\n",
      "loss: 0.061574  [ 8960/15909]\n",
      "loss: 0.054649  [ 9280/15909]\n",
      "loss: 0.064534  [ 9600/15909]\n",
      "loss: 0.066643  [ 9920/15909]\n",
      "loss: 0.063994  [10240/15909]\n",
      "loss: 0.064095  [10560/15909]\n",
      "loss: 0.060158  [10880/15909]\n",
      "loss: 0.064468  [11200/15909]\n",
      "loss: 0.063931  [11520/15909]\n",
      "loss: 0.054670  [11840/15909]\n",
      "loss: 0.054749  [12160/15909]\n",
      "loss: 0.060999  [12480/15909]\n",
      "loss: 0.059803  [12800/15909]\n",
      "loss: 0.066847  [13120/15909]\n",
      "loss: 0.054640  [13440/15909]\n",
      "loss: 0.055051  [13760/15909]\n",
      "loss: 0.073770  [14080/15909]\n",
      "loss: 0.052916  [14400/15909]\n",
      "loss: 0.063840  [14720/15909]\n",
      "loss: 0.060225  [15040/15909]\n",
      "loss: 0.070857  [15360/15909]\n",
      "loss: 0.070979  [15680/15909]\n",
      "Epoch 4 results: Train loss: 0.061741, Val loss: 0.060945\n",
      "Validation loss decreased (0.063351 --> 0.060945). Saving model...\n",
      "Saving best model to best_model.pth\n",
      "Epoch 5/50\n",
      "loss: 0.060459  [    0/15909]\n",
      "loss: 0.064997  [  320/15909]\n",
      "loss: 0.072509  [  640/15909]\n",
      "loss: 0.062756  [  960/15909]\n",
      "loss: 0.061132  [ 1280/15909]\n",
      "loss: 0.059403  [ 1600/15909]\n",
      "loss: 0.067589  [ 1920/15909]\n",
      "loss: 0.071643  [ 2240/15909]\n",
      "loss: 0.054783  [ 2560/15909]\n",
      "loss: 0.057082  [ 2880/15909]\n",
      "loss: 0.059872  [ 3200/15909]\n",
      "loss: 0.065307  [ 3520/15909]\n",
      "loss: 0.059481  [ 3840/15909]\n",
      "loss: 0.065340  [ 4160/15909]\n",
      "loss: 0.065160  [ 4480/15909]\n",
      "loss: 0.066246  [ 4800/15909]\n",
      "loss: 0.054975  [ 5120/15909]\n",
      "loss: 0.063680  [ 5440/15909]\n",
      "loss: 0.059174  [ 5760/15909]\n",
      "loss: 0.064868  [ 6080/15909]\n",
      "loss: 0.064325  [ 6400/15909]\n",
      "loss: 0.055753  [ 6720/15909]\n",
      "loss: 0.057622  [ 7040/15909]\n",
      "loss: 0.066542  [ 7360/15909]\n",
      "loss: 0.052822  [ 7680/15909]\n",
      "loss: 0.060213  [ 8000/15909]\n",
      "loss: 0.059734  [ 8320/15909]\n",
      "loss: 0.070457  [ 8640/15909]\n",
      "loss: 0.051982  [ 8960/15909]\n",
      "loss: 0.057175  [ 9280/15909]\n",
      "loss: 0.056151  [ 9600/15909]\n",
      "loss: 0.062438  [ 9920/15909]\n",
      "loss: 0.068238  [10240/15909]\n",
      "loss: 0.059383  [10560/15909]\n",
      "loss: 0.068128  [10880/15909]\n",
      "loss: 0.056929  [11200/15909]\n",
      "loss: 0.064333  [11520/15909]\n",
      "loss: 0.056925  [11840/15909]\n",
      "loss: 0.063257  [12160/15909]\n",
      "loss: 0.063998  [12480/15909]\n",
      "loss: 0.061554  [12800/15909]\n",
      "loss: 0.053821  [13120/15909]\n",
      "loss: 0.057243  [13440/15909]\n",
      "loss: 0.058218  [13760/15909]\n",
      "loss: 0.064536  [14080/15909]\n",
      "loss: 0.063961  [14400/15909]\n",
      "loss: 0.062016  [14720/15909]\n",
      "loss: 0.057778  [15040/15909]\n",
      "loss: 0.058543  [15360/15909]\n",
      "loss: 0.062153  [15680/15909]\n",
      "Epoch 5 results: Train loss: 0.060991, Val loss: 0.060616\n",
      "Validation loss decreased (0.060945 --> 0.060616). Saving model...\n",
      "Saving best model to best_model.pth\n",
      "Epoch 6/50\n",
      "loss: 0.065036  [    0/15909]\n",
      "loss: 0.058454  [  320/15909]\n",
      "loss: 0.054871  [  640/15909]\n",
      "loss: 0.055228  [  960/15909]\n",
      "loss: 0.071566  [ 1280/15909]\n",
      "loss: 0.068982  [ 1600/15909]\n",
      "loss: 0.052894  [ 1920/15909]\n",
      "loss: 0.055880  [ 2240/15909]\n",
      "loss: 0.063645  [ 2560/15909]\n",
      "loss: 0.049728  [ 2880/15909]\n",
      "loss: 0.055352  [ 3200/15909]\n",
      "loss: 0.066902  [ 3520/15909]\n",
      "loss: 0.053829  [ 3840/15909]\n",
      "loss: 0.061633  [ 4160/15909]\n",
      "loss: 0.064061  [ 4480/15909]\n",
      "loss: 0.066140  [ 4800/15909]\n",
      "loss: 0.057762  [ 5120/15909]\n",
      "loss: 0.059077  [ 5440/15909]\n",
      "loss: 0.064815  [ 5760/15909]\n",
      "loss: 0.060750  [ 6080/15909]\n",
      "loss: 0.053428  [ 6400/15909]\n",
      "loss: 0.065869  [ 6720/15909]\n",
      "loss: 0.056500  [ 7040/15909]\n",
      "loss: 0.056013  [ 7360/15909]\n",
      "loss: 0.063745  [ 7680/15909]\n",
      "loss: 0.054412  [ 8000/15909]\n",
      "loss: 0.061159  [ 8320/15909]\n",
      "loss: 0.053848  [ 8640/15909]\n",
      "loss: 0.054206  [ 8960/15909]\n",
      "loss: 0.054935  [ 9280/15909]\n",
      "loss: 0.063720  [ 9600/15909]\n",
      "loss: 0.053374  [ 9920/15909]\n",
      "loss: 0.074803  [10240/15909]\n",
      "loss: 0.060654  [10560/15909]\n",
      "loss: 0.051575  [10880/15909]\n",
      "loss: 0.055491  [11200/15909]\n",
      "loss: 0.061776  [11520/15909]\n",
      "loss: 0.063767  [11840/15909]\n",
      "loss: 0.058779  [12160/15909]\n",
      "loss: 0.053043  [12480/15909]\n",
      "loss: 0.071865  [12800/15909]\n",
      "loss: 0.058993  [13120/15909]\n",
      "loss: 0.059110  [13440/15909]\n",
      "loss: 0.067917  [13760/15909]\n",
      "loss: 0.061516  [14080/15909]\n",
      "loss: 0.060662  [14400/15909]\n",
      "loss: 0.059366  [14720/15909]\n",
      "loss: 0.056306  [15040/15909]\n",
      "loss: 0.063901  [15360/15909]\n",
      "loss: 0.058225  [15680/15909]\n",
      "Epoch 6 results: Train loss: 0.060498, Val loss: 0.060262\n",
      "Validation loss decreased (0.060616 --> 0.060262). Saving model...\n",
      "Saving best model to best_model.pth\n",
      "Epoch 7/50\n",
      "loss: 0.054885  [    0/15909]\n",
      "loss: 0.073469  [  320/15909]\n",
      "loss: 0.061863  [  640/15909]\n",
      "loss: 0.066465  [  960/15909]\n",
      "loss: 0.053931  [ 1280/15909]\n",
      "loss: 0.059614  [ 1600/15909]\n",
      "loss: 0.052963  [ 1920/15909]\n",
      "loss: 0.064296  [ 2240/15909]\n",
      "loss: 0.058511  [ 2560/15909]\n",
      "loss: 0.066365  [ 2880/15909]\n",
      "loss: 0.058794  [ 3200/15909]\n",
      "loss: 0.057813  [ 3520/15909]\n",
      "loss: 0.056820  [ 3840/15909]\n",
      "loss: 0.056656  [ 4160/15909]\n",
      "loss: 0.062566  [ 4480/15909]\n",
      "loss: 0.056781  [ 4800/15909]\n",
      "loss: 0.064304  [ 5120/15909]\n",
      "loss: 0.059895  [ 5440/15909]\n",
      "loss: 0.058745  [ 5760/15909]\n",
      "loss: 0.057009  [ 6080/15909]\n",
      "loss: 0.066112  [ 6400/15909]\n",
      "loss: 0.064336  [ 6720/15909]\n",
      "loss: 0.058906  [ 7040/15909]\n",
      "loss: 0.063787  [ 7360/15909]\n",
      "loss: 0.057846  [ 7680/15909]\n",
      "loss: 0.054955  [ 8000/15909]\n",
      "loss: 0.057818  [ 8320/15909]\n",
      "loss: 0.053874  [ 8640/15909]\n",
      "loss: 0.065135  [ 8960/15909]\n",
      "loss: 0.061486  [ 9280/15909]\n",
      "loss: 0.070547  [ 9600/15909]\n",
      "loss: 0.058395  [ 9920/15909]\n",
      "loss: 0.062215  [10240/15909]\n",
      "loss: 0.074681  [10560/15909]\n",
      "loss: 0.051568  [10880/15909]\n",
      "loss: 0.059617  [11200/15909]\n",
      "loss: 0.053130  [11520/15909]\n",
      "loss: 0.062327  [11840/15909]\n",
      "loss: 0.055603  [12160/15909]\n",
      "loss: 0.057740  [12480/15909]\n",
      "loss: 0.054995  [12800/15909]\n",
      "loss: 0.059782  [13120/15909]\n",
      "loss: 0.054059  [13440/15909]\n",
      "loss: 0.066431  [13760/15909]\n",
      "loss: 0.057088  [14080/15909]\n",
      "loss: 0.064084  [14400/15909]\n",
      "loss: 0.061966  [14720/15909]\n",
      "loss: 0.054389  [15040/15909]\n",
      "loss: 0.060031  [15360/15909]\n",
      "loss: 0.061238  [15680/15909]\n",
      "Epoch 7 results: Train loss: 0.059857, Val loss: 0.059734\n",
      "Validation loss decreased (0.060262 --> 0.059734). Saving model...\n",
      "Saving best model to best_model.pth\n",
      "Epoch 8/50\n",
      "loss: 0.060005  [    0/15909]\n",
      "loss: 0.079969  [  320/15909]\n",
      "loss: 0.057155  [  640/15909]\n",
      "loss: 0.056949  [  960/15909]\n",
      "loss: 0.056549  [ 1280/15909]\n",
      "loss: 0.056258  [ 1600/15909]\n",
      "loss: 0.064905  [ 1920/15909]\n",
      "loss: 0.052704  [ 2240/15909]\n",
      "loss: 0.065019  [ 2560/15909]\n",
      "loss: 0.059524  [ 2880/15909]\n",
      "loss: 0.052235  [ 3200/15909]\n",
      "loss: 0.058005  [ 3520/15909]\n",
      "loss: 0.060705  [ 3840/15909]\n",
      "loss: 0.060913  [ 4160/15909]\n",
      "loss: 0.061326  [ 4480/15909]\n",
      "loss: 0.060770  [ 4800/15909]\n",
      "loss: 0.063498  [ 5120/15909]\n",
      "loss: 0.058590  [ 5440/15909]\n",
      "loss: 0.063641  [ 5760/15909]\n",
      "loss: 0.068405  [ 6080/15909]\n",
      "loss: 0.065033  [ 6400/15909]\n",
      "loss: 0.059441  [ 6720/15909]\n",
      "loss: 0.056750  [ 7040/15909]\n",
      "loss: 0.059607  [ 7360/15909]\n",
      "loss: 0.060469  [ 7680/15909]\n",
      "loss: 0.060190  [ 8000/15909]\n",
      "loss: 0.068046  [ 8320/15909]\n",
      "loss: 0.056982  [ 8640/15909]\n",
      "loss: 0.056463  [ 8960/15909]\n",
      "loss: 0.056018  [ 9280/15909]\n",
      "loss: 0.057241  [ 9600/15909]\n",
      "loss: 0.061613  [ 9920/15909]\n",
      "loss: 0.059177  [10240/15909]\n",
      "loss: 0.064579  [10560/15909]\n",
      "loss: 0.058638  [10880/15909]\n",
      "loss: 0.060009  [11200/15909]\n",
      "loss: 0.060190  [11520/15909]\n",
      "loss: 0.055913  [11840/15909]\n",
      "loss: 0.052259  [12160/15909]\n",
      "loss: 0.060391  [12480/15909]\n",
      "loss: 0.057469  [12800/15909]\n",
      "loss: 0.055784  [13120/15909]\n",
      "loss: 0.053644  [13440/15909]\n",
      "loss: 0.068691  [13760/15909]\n",
      "loss: 0.054039  [14080/15909]\n",
      "loss: 0.061708  [14400/15909]\n",
      "loss: 0.067171  [14720/15909]\n",
      "loss: 0.058118  [15040/15909]\n",
      "loss: 0.056395  [15360/15909]\n",
      "loss: 0.055815  [15680/15909]\n",
      "Epoch 8 results: Train loss: 0.059390, Val loss: 0.060585\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Epoch 9/50\n",
      "loss: 0.055941  [    0/15909]\n",
      "loss: 0.057920  [  320/15909]\n",
      "loss: 0.054870  [  640/15909]\n",
      "loss: 0.059913  [  960/15909]\n",
      "loss: 0.054368  [ 1280/15909]\n",
      "loss: 0.055838  [ 1600/15909]\n",
      "loss: 0.055881  [ 1920/15909]\n",
      "loss: 0.061079  [ 2240/15909]\n",
      "loss: 0.068316  [ 2560/15909]\n",
      "loss: 0.057958  [ 2880/15909]\n",
      "loss: 0.057231  [ 3200/15909]\n",
      "loss: 0.059346  [ 3520/15909]\n",
      "loss: 0.055334  [ 3840/15909]\n",
      "loss: 0.063320  [ 4160/15909]\n",
      "loss: 0.058213  [ 4480/15909]\n",
      "loss: 0.059438  [ 4800/15909]\n",
      "loss: 0.066733  [ 5120/15909]\n",
      "loss: 0.058812  [ 5440/15909]\n",
      "loss: 0.059492  [ 5760/15909]\n",
      "loss: 0.060489  [ 6080/15909]\n",
      "loss: 0.054367  [ 6400/15909]\n",
      "loss: 0.057855  [ 6720/15909]\n",
      "loss: 0.058749  [ 7040/15909]\n",
      "loss: 0.053781  [ 7360/15909]\n",
      "loss: 0.064380  [ 7680/15909]\n",
      "loss: 0.050892  [ 8000/15909]\n",
      "loss: 0.054814  [ 8320/15909]\n",
      "loss: 0.061792  [ 8640/15909]\n",
      "loss: 0.056691  [ 8960/15909]\n",
      "loss: 0.060548  [ 9280/15909]\n",
      "loss: 0.058159  [ 9600/15909]\n",
      "loss: 0.056092  [ 9920/15909]\n",
      "loss: 0.055573  [10240/15909]\n",
      "loss: 0.067454  [10560/15909]\n",
      "loss: 0.055935  [10880/15909]\n",
      "loss: 0.055337  [11200/15909]\n",
      "loss: 0.058359  [11520/15909]\n",
      "loss: 0.060548  [11840/15909]\n",
      "loss: 0.054638  [12160/15909]\n",
      "loss: 0.056657  [12480/15909]\n",
      "loss: 0.054194  [12800/15909]\n",
      "loss: 0.055990  [13120/15909]\n",
      "loss: 0.054445  [13440/15909]\n",
      "loss: 0.067852  [13760/15909]\n",
      "loss: 0.057383  [14080/15909]\n",
      "loss: 0.057199  [14400/15909]\n",
      "loss: 0.058541  [14720/15909]\n",
      "loss: 0.066074  [15040/15909]\n",
      "loss: 0.058080  [15360/15909]\n",
      "loss: 0.058069  [15680/15909]\n",
      "Epoch 9 results: Train loss: 0.059227, Val loss: 0.060103\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Epoch 10/50\n",
      "loss: 0.050734  [    0/15909]\n",
      "loss: 0.055871  [  320/15909]\n",
      "loss: 0.054699  [  640/15909]\n",
      "loss: 0.051875  [  960/15909]\n",
      "loss: 0.055929  [ 1280/15909]\n",
      "loss: 0.059298  [ 1600/15909]\n",
      "loss: 0.062354  [ 1920/15909]\n",
      "loss: 0.058537  [ 2240/15909]\n",
      "loss: 0.058292  [ 2560/15909]\n",
      "loss: 0.062194  [ 2880/15909]\n",
      "loss: 0.060348  [ 3200/15909]\n",
      "loss: 0.055148  [ 3520/15909]\n",
      "loss: 0.054129  [ 3840/15909]\n",
      "loss: 0.049549  [ 4160/15909]\n",
      "loss: 0.053475  [ 4480/15909]\n",
      "loss: 0.056446  [ 4800/15909]\n",
      "loss: 0.057997  [ 5120/15909]\n",
      "loss: 0.053390  [ 5440/15909]\n",
      "loss: 0.063221  [ 5760/15909]\n",
      "loss: 0.062297  [ 6080/15909]\n",
      "loss: 0.061210  [ 6400/15909]\n",
      "loss: 0.063008  [ 6720/15909]\n",
      "loss: 0.061335  [ 7040/15909]\n",
      "loss: 0.050815  [ 7360/15909]\n",
      "loss: 0.060062  [ 7680/15909]\n",
      "loss: 0.060226  [ 8000/15909]\n",
      "loss: 0.061378  [ 8320/15909]\n",
      "loss: 0.063831  [ 8640/15909]\n",
      "loss: 0.059614  [ 8960/15909]\n",
      "loss: 0.053260  [ 9280/15909]\n",
      "loss: 0.052601  [ 9600/15909]\n",
      "loss: 0.054735  [ 9920/15909]\n",
      "loss: 0.051046  [10240/15909]\n",
      "loss: 0.050148  [10560/15909]\n",
      "loss: 0.058311  [10880/15909]\n",
      "loss: 0.054271  [11200/15909]\n",
      "loss: 0.067507  [11520/15909]\n",
      "loss: 0.060546  [11840/15909]\n",
      "loss: 0.061859  [12160/15909]\n",
      "loss: 0.057898  [12480/15909]\n",
      "loss: 0.072092  [12800/15909]\n",
      "loss: 0.058629  [13120/15909]\n",
      "loss: 0.065288  [13440/15909]\n",
      "loss: 0.060272  [13760/15909]\n",
      "loss: 0.055324  [14080/15909]\n",
      "loss: 0.060314  [14400/15909]\n",
      "loss: 0.065114  [14720/15909]\n",
      "loss: 0.056279  [15040/15909]\n",
      "loss: 0.056651  [15360/15909]\n",
      "loss: 0.055904  [15680/15909]\n",
      "Epoch 10 results: Train loss: 0.058744, Val loss: 0.059085\n",
      "Validation loss decreased (0.059734 --> 0.059085). Saving model...\n",
      "Saving best model to best_model.pth\n",
      "Epoch 11/50\n",
      "loss: 0.051140  [    0/15909]\n",
      "loss: 0.062556  [  320/15909]\n",
      "loss: 0.066100  [  640/15909]\n",
      "loss: 0.071989  [  960/15909]\n",
      "loss: 0.060189  [ 1280/15909]\n",
      "loss: 0.055798  [ 1600/15909]\n",
      "loss: 0.060684  [ 1920/15909]\n",
      "loss: 0.061302  [ 2240/15909]\n",
      "loss: 0.056271  [ 2560/15909]\n",
      "loss: 0.060004  [ 2880/15909]\n",
      "loss: 0.060743  [ 3200/15909]\n",
      "loss: 0.060842  [ 3520/15909]\n",
      "loss: 0.057404  [ 3840/15909]\n",
      "loss: 0.057571  [ 4160/15909]\n",
      "loss: 0.060474  [ 4480/15909]\n",
      "loss: 0.063066  [ 4800/15909]\n",
      "loss: 0.059395  [ 5120/15909]\n",
      "loss: 0.059651  [ 5440/15909]\n",
      "loss: 0.061386  [ 5760/15909]\n",
      "loss: 0.059117  [ 6080/15909]\n",
      "loss: 0.064649  [ 6400/15909]\n",
      "loss: 0.055112  [ 6720/15909]\n",
      "loss: 0.063867  [ 7040/15909]\n",
      "loss: 0.055662  [ 7360/15909]\n",
      "loss: 0.060505  [ 7680/15909]\n",
      "loss: 0.060461  [ 8000/15909]\n",
      "loss: 0.053870  [ 8320/15909]\n",
      "loss: 0.056258  [ 8640/15909]\n",
      "loss: 0.058986  [ 8960/15909]\n",
      "loss: 0.057028  [ 9280/15909]\n",
      "loss: 0.055140  [ 9600/15909]\n",
      "loss: 0.060439  [ 9920/15909]\n",
      "loss: 0.067200  [10240/15909]\n",
      "loss: 0.054860  [10560/15909]\n",
      "loss: 0.049524  [10880/15909]\n",
      "loss: 0.060609  [11200/15909]\n",
      "loss: 0.061387  [11520/15909]\n",
      "loss: 0.055479  [11840/15909]\n",
      "loss: 0.054006  [12160/15909]\n",
      "loss: 0.060972  [12480/15909]\n",
      "loss: 0.060617  [12800/15909]\n",
      "loss: 0.052500  [13120/15909]\n",
      "loss: 0.055463  [13440/15909]\n",
      "loss: 0.059361  [13760/15909]\n",
      "loss: 0.064798  [14080/15909]\n",
      "loss: 0.061051  [14400/15909]\n",
      "loss: 0.060053  [14720/15909]\n",
      "loss: 0.052028  [15040/15909]\n",
      "loss: 0.055777  [15360/15909]\n",
      "loss: 0.061150  [15680/15909]\n",
      "Epoch 11 results: Train loss: 0.058513, Val loss: 0.060580\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Epoch 12/50\n",
      "loss: 0.049545  [    0/15909]\n",
      "loss: 0.054103  [  320/15909]\n",
      "loss: 0.056257  [  640/15909]\n",
      "loss: 0.058264  [  960/15909]\n",
      "loss: 0.063858  [ 1280/15909]\n",
      "loss: 0.053006  [ 1600/15909]\n",
      "loss: 0.058442  [ 1920/15909]\n",
      "loss: 0.064456  [ 2240/15909]\n",
      "loss: 0.060815  [ 2560/15909]\n",
      "loss: 0.056413  [ 2880/15909]\n",
      "loss: 0.060302  [ 3200/15909]\n",
      "loss: 0.052026  [ 3520/15909]\n",
      "loss: 0.060099  [ 3840/15909]\n",
      "loss: 0.046414  [ 4160/15909]\n",
      "loss: 0.061790  [ 4480/15909]\n",
      "loss: 0.057038  [ 4800/15909]\n",
      "loss: 0.064014  [ 5120/15909]\n",
      "loss: 0.052153  [ 5440/15909]\n",
      "loss: 0.071321  [ 5760/15909]\n",
      "loss: 0.057932  [ 6080/15909]\n",
      "loss: 0.056842  [ 6400/15909]\n",
      "loss: 0.056308  [ 6720/15909]\n",
      "loss: 0.054891  [ 7040/15909]\n",
      "loss: 0.051243  [ 7360/15909]\n",
      "loss: 0.053684  [ 7680/15909]\n",
      "loss: 0.059020  [ 8000/15909]\n",
      "loss: 0.065865  [ 8320/15909]\n",
      "loss: 0.049455  [ 8640/15909]\n",
      "loss: 0.055129  [ 8960/15909]\n",
      "loss: 0.056741  [ 9280/15909]\n",
      "loss: 0.055900  [ 9600/15909]\n",
      "loss: 0.054298  [ 9920/15909]\n",
      "loss: 0.053705  [10240/15909]\n",
      "loss: 0.061526  [10560/15909]\n",
      "loss: 0.062902  [10880/15909]\n",
      "loss: 0.063179  [11200/15909]\n",
      "loss: 0.058521  [11520/15909]\n",
      "loss: 0.059824  [11840/15909]\n",
      "loss: 0.056026  [12160/15909]\n",
      "loss: 0.058126  [12480/15909]\n",
      "loss: 0.059355  [12800/15909]\n",
      "loss: 0.055974  [13120/15909]\n",
      "loss: 0.059050  [13440/15909]\n",
      "loss: 0.058986  [13760/15909]\n",
      "loss: 0.056028  [14080/15909]\n",
      "loss: 0.058268  [14400/15909]\n",
      "loss: 0.062381  [14720/15909]\n",
      "loss: 0.054493  [15040/15909]\n",
      "loss: 0.056052  [15360/15909]\n",
      "loss: 0.061403  [15680/15909]\n",
      "Epoch 12 results: Train loss: 0.058263, Val loss: 0.058507\n",
      "Validation loss decreased (0.059085 --> 0.058507). Saving model...\n",
      "Saving best model to best_model.pth\n",
      "Epoch 13/50\n",
      "loss: 0.057841  [    0/15909]\n",
      "loss: 0.066046  [  320/15909]\n",
      "loss: 0.056614  [  640/15909]\n",
      "loss: 0.053803  [  960/15909]\n",
      "loss: 0.061641  [ 1280/15909]\n",
      "loss: 0.059969  [ 1600/15909]\n",
      "loss: 0.059773  [ 1920/15909]\n",
      "loss: 0.054976  [ 2240/15909]\n",
      "loss: 0.066383  [ 2560/15909]\n",
      "loss: 0.063186  [ 2880/15909]\n",
      "loss: 0.053080  [ 3200/15909]\n",
      "loss: 0.058127  [ 3520/15909]\n",
      "loss: 0.055210  [ 3840/15909]\n",
      "loss: 0.060690  [ 4160/15909]\n",
      "loss: 0.062907  [ 4480/15909]\n",
      "loss: 0.056074  [ 4800/15909]\n",
      "loss: 0.068663  [ 5120/15909]\n",
      "loss: 0.072197  [ 5440/15909]\n",
      "loss: 0.057065  [ 5760/15909]\n",
      "loss: 0.049977  [ 6080/15909]\n",
      "loss: 0.068703  [ 6400/15909]\n",
      "loss: 0.056216  [ 6720/15909]\n",
      "loss: 0.062690  [ 7040/15909]\n",
      "loss: 0.057037  [ 7360/15909]\n",
      "loss: 0.057968  [ 7680/15909]\n",
      "loss: 0.060229  [ 8000/15909]\n",
      "loss: 0.061670  [ 8320/15909]\n",
      "loss: 0.066629  [ 8640/15909]\n",
      "loss: 0.059638  [ 8960/15909]\n",
      "loss: 0.053903  [ 9280/15909]\n",
      "loss: 0.060067  [ 9600/15909]\n",
      "loss: 0.051216  [ 9920/15909]\n",
      "loss: 0.062210  [10240/15909]\n",
      "loss: 0.061162  [10560/15909]\n",
      "loss: 0.058895  [10880/15909]\n",
      "loss: 0.054736  [11200/15909]\n",
      "loss: 0.059499  [11520/15909]\n",
      "loss: 0.061548  [11840/15909]\n",
      "loss: 0.055091  [12160/15909]\n",
      "loss: 0.065513  [12480/15909]\n",
      "loss: 0.052001  [12800/15909]\n",
      "loss: 0.061704  [13120/15909]\n",
      "loss: 0.067635  [13440/15909]\n",
      "loss: 0.057010  [13760/15909]\n",
      "loss: 0.053464  [14080/15909]\n",
      "loss: 0.055404  [14400/15909]\n",
      "loss: 0.058948  [14720/15909]\n",
      "loss: 0.052206  [15040/15909]\n",
      "loss: 0.058571  [15360/15909]\n",
      "loss: 0.058917  [15680/15909]\n",
      "Epoch 13 results: Train loss: 0.058500, Val loss: 0.059172\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Epoch 14/50\n",
      "loss: 0.061642  [    0/15909]\n",
      "loss: 0.060136  [  320/15909]\n",
      "loss: 0.054462  [  640/15909]\n",
      "loss: 0.058715  [  960/15909]\n",
      "loss: 0.057216  [ 1280/15909]\n",
      "loss: 0.055513  [ 1600/15909]\n",
      "loss: 0.055933  [ 1920/15909]\n",
      "loss: 0.060910  [ 2240/15909]\n",
      "loss: 0.059571  [ 2560/15909]\n",
      "loss: 0.052638  [ 2880/15909]\n",
      "loss: 0.058737  [ 3200/15909]\n",
      "loss: 0.056255  [ 3520/15909]\n",
      "loss: 0.055181  [ 3840/15909]\n",
      "loss: 0.062611  [ 4160/15909]\n",
      "loss: 0.065181  [ 4480/15909]\n",
      "loss: 0.059848  [ 4800/15909]\n",
      "loss: 0.054673  [ 5120/15909]\n",
      "loss: 0.069940  [ 5440/15909]\n",
      "loss: 0.064640  [ 5760/15909]\n",
      "loss: 0.063961  [ 6080/15909]\n",
      "loss: 0.057739  [ 6400/15909]\n",
      "loss: 0.051888  [ 6720/15909]\n",
      "loss: 0.051684  [ 7040/15909]\n",
      "loss: 0.060577  [ 7360/15909]\n",
      "loss: 0.063285  [ 7680/15909]\n",
      "loss: 0.066072  [ 8000/15909]\n",
      "loss: 0.058851  [ 8320/15909]\n",
      "loss: 0.053669  [ 8640/15909]\n",
      "loss: 0.059153  [ 8960/15909]\n",
      "loss: 0.048030  [ 9280/15909]\n",
      "loss: 0.057995  [ 9600/15909]\n",
      "loss: 0.056461  [ 9920/15909]\n",
      "loss: 0.055732  [10240/15909]\n",
      "loss: 0.057119  [10560/15909]\n",
      "loss: 0.057255  [10880/15909]\n",
      "loss: 0.065277  [11200/15909]\n",
      "loss: 0.060414  [11520/15909]\n",
      "loss: 0.055093  [11840/15909]\n",
      "loss: 0.059223  [12160/15909]\n",
      "loss: 0.057517  [12480/15909]\n",
      "loss: 0.056609  [12800/15909]\n",
      "loss: 0.051385  [13120/15909]\n",
      "loss: 0.057161  [13440/15909]\n",
      "loss: 0.054669  [13760/15909]\n",
      "loss: 0.066381  [14080/15909]\n",
      "loss: 0.055673  [14400/15909]\n",
      "loss: 0.056914  [14720/15909]\n",
      "loss: 0.061202  [15040/15909]\n",
      "loss: 0.063106  [15360/15909]\n",
      "loss: 0.058100  [15680/15909]\n",
      "Epoch 14 results: Train loss: 0.058160, Val loss: 0.058826\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Epoch 15/50\n",
      "loss: 0.057927  [    0/15909]\n",
      "loss: 0.051453  [  320/15909]\n",
      "loss: 0.054764  [  640/15909]\n",
      "loss: 0.050504  [  960/15909]\n",
      "loss: 0.064221  [ 1280/15909]\n",
      "loss: 0.062257  [ 1600/15909]\n",
      "loss: 0.054064  [ 1920/15909]\n",
      "loss: 0.060650  [ 2240/15909]\n",
      "loss: 0.058136  [ 2560/15909]\n",
      "loss: 0.057032  [ 2880/15909]\n",
      "loss: 0.059094  [ 3200/15909]\n",
      "loss: 0.055830  [ 3520/15909]\n",
      "loss: 0.050825  [ 3840/15909]\n",
      "loss: 0.056325  [ 4160/15909]\n",
      "loss: 0.048502  [ 4480/15909]\n",
      "loss: 0.059058  [ 4800/15909]\n",
      "loss: 0.051640  [ 5120/15909]\n",
      "loss: 0.059584  [ 5440/15909]\n",
      "loss: 0.055137  [ 5760/15909]\n",
      "loss: 0.056230  [ 6080/15909]\n",
      "loss: 0.059978  [ 6400/15909]\n",
      "loss: 0.060885  [ 6720/15909]\n",
      "loss: 0.055037  [ 7040/15909]\n",
      "loss: 0.055368  [ 7360/15909]\n",
      "loss: 0.057628  [ 7680/15909]\n",
      "loss: 0.057559  [ 8000/15909]\n",
      "loss: 0.057540  [ 8320/15909]\n",
      "loss: 0.057639  [ 8640/15909]\n",
      "loss: 0.063659  [ 8960/15909]\n",
      "loss: 0.049590  [ 9280/15909]\n",
      "loss: 0.053411  [ 9600/15909]\n",
      "loss: 0.058943  [ 9920/15909]\n",
      "loss: 0.054525  [10240/15909]\n",
      "loss: 0.050553  [10560/15909]\n",
      "loss: 0.055571  [10880/15909]\n",
      "loss: 0.065932  [11200/15909]\n",
      "loss: 0.056965  [11520/15909]\n",
      "loss: 0.057608  [11840/15909]\n",
      "loss: 0.053829  [12160/15909]\n",
      "loss: 0.059228  [12480/15909]\n",
      "loss: 0.055539  [12800/15909]\n",
      "loss: 0.060601  [13120/15909]\n",
      "loss: 0.065580  [13440/15909]\n",
      "loss: 0.063576  [13760/15909]\n",
      "loss: 0.063368  [14080/15909]\n",
      "loss: 0.050939  [14400/15909]\n",
      "loss: 0.062051  [14720/15909]\n",
      "loss: 0.056379  [15040/15909]\n",
      "loss: 0.057839  [15360/15909]\n",
      "loss: 0.060683  [15680/15909]\n",
      "Epoch 15 results: Train loss: 0.057361, Val loss: 0.059107\n",
      "EarlyStopping counter: 3 out of 5\n",
      "Epoch 16/50\n",
      "loss: 0.060515  [    0/15909]\n",
      "loss: 0.065341  [  320/15909]\n",
      "loss: 0.056679  [  640/15909]\n",
      "loss: 0.054827  [  960/15909]\n",
      "loss: 0.062481  [ 1280/15909]\n",
      "loss: 0.060133  [ 1600/15909]\n",
      "loss: 0.050682  [ 1920/15909]\n",
      "loss: 0.056931  [ 2240/15909]\n",
      "loss: 0.052860  [ 2560/15909]\n",
      "loss: 0.057538  [ 2880/15909]\n",
      "loss: 0.053811  [ 3200/15909]\n",
      "loss: 0.059944  [ 3520/15909]\n",
      "loss: 0.051009  [ 3840/15909]\n",
      "loss: 0.062776  [ 4160/15909]\n",
      "loss: 0.057238  [ 4480/15909]\n",
      "loss: 0.057094  [ 4800/15909]\n",
      "loss: 0.054444  [ 5120/15909]\n",
      "loss: 0.057496  [ 5440/15909]\n",
      "loss: 0.057463  [ 5760/15909]\n",
      "loss: 0.060189  [ 6080/15909]\n",
      "loss: 0.056838  [ 6400/15909]\n",
      "loss: 0.051215  [ 6720/15909]\n",
      "loss: 0.061299  [ 7040/15909]\n",
      "loss: 0.052022  [ 7360/15909]\n",
      "loss: 0.053386  [ 7680/15909]\n",
      "loss: 0.051057  [ 8000/15909]\n",
      "loss: 0.051796  [ 8320/15909]\n",
      "loss: 0.055579  [ 8640/15909]\n",
      "loss: 0.054351  [ 8960/15909]\n",
      "loss: 0.058214  [ 9280/15909]\n",
      "loss: 0.060054  [ 9600/15909]\n",
      "loss: 0.050633  [ 9920/15909]\n",
      "loss: 0.057827  [10240/15909]\n",
      "loss: 0.057263  [10560/15909]\n",
      "loss: 0.054619  [10880/15909]\n",
      "loss: 0.060351  [11200/15909]\n",
      "loss: 0.053680  [11520/15909]\n",
      "loss: 0.053616  [11840/15909]\n",
      "loss: 0.057337  [12160/15909]\n",
      "loss: 0.069469  [12480/15909]\n",
      "loss: 0.055966  [12800/15909]\n",
      "loss: 0.063458  [13120/15909]\n",
      "loss: 0.062704  [13440/15909]\n",
      "loss: 0.055523  [13760/15909]\n",
      "loss: 0.053761  [14080/15909]\n",
      "loss: 0.057885  [14400/15909]\n",
      "loss: 0.058943  [14720/15909]\n",
      "loss: 0.048148  [15040/15909]\n",
      "loss: 0.058456  [15360/15909]\n",
      "loss: 0.052450  [15680/15909]\n",
      "Epoch 16 results: Train loss: 0.057333, Val loss: 0.058054\n",
      "Validation loss decreased (0.058507 --> 0.058054). Saving model...\n",
      "Saving best model to best_model.pth\n",
      "Epoch 17/50\n",
      "loss: 0.061900  [    0/15909]\n",
      "loss: 0.065915  [  320/15909]\n",
      "loss: 0.059386  [  640/15909]\n",
      "loss: 0.052884  [  960/15909]\n",
      "loss: 0.053987  [ 1280/15909]\n",
      "loss: 0.050631  [ 1600/15909]\n",
      "loss: 0.053599  [ 1920/15909]\n",
      "loss: 0.055062  [ 2240/15909]\n",
      "loss: 0.057116  [ 2560/15909]\n",
      "loss: 0.054259  [ 2880/15909]\n",
      "loss: 0.060744  [ 3200/15909]\n",
      "loss: 0.058478  [ 3520/15909]\n",
      "loss: 0.050979  [ 3840/15909]\n",
      "loss: 0.060685  [ 4160/15909]\n",
      "loss: 0.063424  [ 4480/15909]\n",
      "loss: 0.067003  [ 4800/15909]\n",
      "loss: 0.060915  [ 5120/15909]\n",
      "loss: 0.056152  [ 5440/15909]\n",
      "loss: 0.054584  [ 5760/15909]\n",
      "loss: 0.055673  [ 6080/15909]\n",
      "loss: 0.050117  [ 6400/15909]\n",
      "loss: 0.054707  [ 6720/15909]\n",
      "loss: 0.059134  [ 7040/15909]\n",
      "loss: 0.058655  [ 7360/15909]\n",
      "loss: 0.059043  [ 7680/15909]\n",
      "loss: 0.058587  [ 8000/15909]\n",
      "loss: 0.063344  [ 8320/15909]\n",
      "loss: 0.064414  [ 8640/15909]\n",
      "loss: 0.057545  [ 8960/15909]\n",
      "loss: 0.057272  [ 9280/15909]\n",
      "loss: 0.051447  [ 9600/15909]\n",
      "loss: 0.059429  [ 9920/15909]\n",
      "loss: 0.055606  [10240/15909]\n",
      "loss: 0.061421  [10560/15909]\n",
      "loss: 0.058746  [10880/15909]\n",
      "loss: 0.052269  [11200/15909]\n",
      "loss: 0.058469  [11520/15909]\n",
      "loss: 0.061648  [11840/15909]\n",
      "loss: 0.053009  [12160/15909]\n",
      "loss: 0.052732  [12480/15909]\n",
      "loss: 0.058443  [12800/15909]\n",
      "loss: 0.054147  [13120/15909]\n",
      "loss: 0.059572  [13440/15909]\n",
      "loss: 0.066767  [13760/15909]\n",
      "loss: 0.060994  [14080/15909]\n",
      "loss: 0.054012  [14400/15909]\n",
      "loss: 0.050540  [14720/15909]\n",
      "loss: 0.058417  [15040/15909]\n",
      "loss: 0.062412  [15360/15909]\n",
      "loss: 0.052207  [15680/15909]\n",
      "Epoch 17 results: Train loss: 0.056974, Val loss: 0.058919\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Epoch 18/50\n",
      "loss: 0.060512  [    0/15909]\n",
      "loss: 0.060145  [  320/15909]\n",
      "loss: 0.053180  [  640/15909]\n",
      "loss: 0.055769  [  960/15909]\n",
      "loss: 0.049626  [ 1280/15909]\n",
      "loss: 0.057646  [ 1600/15909]\n",
      "loss: 0.052799  [ 1920/15909]\n",
      "loss: 0.060273  [ 2240/15909]\n",
      "loss: 0.054360  [ 2560/15909]\n",
      "loss: 0.058353  [ 2880/15909]\n",
      "loss: 0.059446  [ 3200/15909]\n",
      "loss: 0.054563  [ 3520/15909]\n",
      "loss: 0.062604  [ 3840/15909]\n",
      "loss: 0.055471  [ 4160/15909]\n",
      "loss: 0.051150  [ 4480/15909]\n",
      "loss: 0.067172  [ 4800/15909]\n",
      "loss: 0.061022  [ 5120/15909]\n",
      "loss: 0.058901  [ 5440/15909]\n",
      "loss: 0.066407  [ 5760/15909]\n",
      "loss: 0.057224  [ 6080/15909]\n",
      "loss: 0.061212  [ 6400/15909]\n",
      "loss: 0.059876  [ 6720/15909]\n",
      "loss: 0.062567  [ 7040/15909]\n",
      "loss: 0.059421  [ 7360/15909]\n",
      "loss: 0.048938  [ 7680/15909]\n",
      "loss: 0.056979  [ 8000/15909]\n",
      "loss: 0.056433  [ 8320/15909]\n",
      "loss: 0.062158  [ 8640/15909]\n",
      "loss: 0.057673  [ 8960/15909]\n",
      "loss: 0.054859  [ 9280/15909]\n",
      "loss: 0.057134  [ 9600/15909]\n",
      "loss: 0.057631  [ 9920/15909]\n",
      "loss: 0.057506  [10240/15909]\n",
      "loss: 0.055214  [10560/15909]\n",
      "loss: 0.063088  [10880/15909]\n",
      "loss: 0.052899  [11200/15909]\n",
      "loss: 0.058646  [11520/15909]\n",
      "loss: 0.058246  [11840/15909]\n",
      "loss: 0.066587  [12160/15909]\n",
      "loss: 0.056802  [12480/15909]\n",
      "loss: 0.048884  [12800/15909]\n",
      "loss: 0.064787  [13120/15909]\n",
      "loss: 0.055233  [13440/15909]\n",
      "loss: 0.048738  [13760/15909]\n",
      "loss: 0.060363  [14080/15909]\n",
      "loss: 0.060441  [14400/15909]\n",
      "loss: 0.062102  [14720/15909]\n",
      "loss: 0.060024  [15040/15909]\n",
      "loss: 0.050767  [15360/15909]\n",
      "loss: 0.058999  [15680/15909]\n",
      "Epoch 18 results: Train loss: 0.057206, Val loss: 0.058633\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Epoch 19/50\n",
      "loss: 0.057523  [    0/15909]\n",
      "loss: 0.062327  [  320/15909]\n",
      "loss: 0.056362  [  640/15909]\n",
      "loss: 0.063597  [  960/15909]\n",
      "loss: 0.062706  [ 1280/15909]\n",
      "loss: 0.055666  [ 1600/15909]\n",
      "loss: 0.051327  [ 1920/15909]\n",
      "loss: 0.052824  [ 2240/15909]\n",
      "loss: 0.059400  [ 2560/15909]\n",
      "loss: 0.058718  [ 2880/15909]\n",
      "loss: 0.056829  [ 3200/15909]\n",
      "loss: 0.066915  [ 3520/15909]\n",
      "loss: 0.061186  [ 3840/15909]\n",
      "loss: 0.050675  [ 4160/15909]\n",
      "loss: 0.054890  [ 4480/15909]\n",
      "loss: 0.061012  [ 4800/15909]\n",
      "loss: 0.056710  [ 5120/15909]\n",
      "loss: 0.050615  [ 5440/15909]\n",
      "loss: 0.062378  [ 5760/15909]\n",
      "loss: 0.059584  [ 6080/15909]\n",
      "loss: 0.062374  [ 6400/15909]\n",
      "loss: 0.051150  [ 6720/15909]\n",
      "loss: 0.055767  [ 7040/15909]\n",
      "loss: 0.052394  [ 7360/15909]\n",
      "loss: 0.059443  [ 7680/15909]\n",
      "loss: 0.056477  [ 8000/15909]\n",
      "loss: 0.056150  [ 8320/15909]\n",
      "loss: 0.059905  [ 8640/15909]\n",
      "loss: 0.053525  [ 8960/15909]\n",
      "loss: 0.059067  [ 9280/15909]\n",
      "loss: 0.060202  [ 9600/15909]\n",
      "loss: 0.064707  [ 9920/15909]\n",
      "loss: 0.062223  [10240/15909]\n",
      "loss: 0.054127  [10560/15909]\n",
      "loss: 0.054232  [10880/15909]\n",
      "loss: 0.061304  [11200/15909]\n",
      "loss: 0.059343  [11520/15909]\n",
      "loss: 0.055099  [11840/15909]\n",
      "loss: 0.050386  [12160/15909]\n",
      "loss: 0.065610  [12480/15909]\n",
      "loss: 0.055130  [12800/15909]\n",
      "loss: 0.055023  [13120/15909]\n",
      "loss: 0.060577  [13440/15909]\n",
      "loss: 0.051728  [13760/15909]\n",
      "loss: 0.054460  [14080/15909]\n",
      "loss: 0.060277  [14400/15909]\n",
      "loss: 0.059337  [14720/15909]\n",
      "loss: 0.060041  [15040/15909]\n",
      "loss: 0.058183  [15360/15909]\n",
      "loss: 0.056872  [15680/15909]\n",
      "Epoch 19 results: Train loss: 0.056786, Val loss: 0.059094\n",
      "EarlyStopping counter: 3 out of 5\n",
      "Epoch 20/50\n",
      "loss: 0.058194  [    0/15909]\n",
      "loss: 0.050281  [  320/15909]\n",
      "loss: 0.058215  [  640/15909]\n",
      "loss: 0.059394  [  960/15909]\n",
      "loss: 0.058280  [ 1280/15909]\n",
      "loss: 0.053912  [ 1600/15909]\n",
      "loss: 0.048359  [ 1920/15909]\n",
      "loss: 0.059634  [ 2240/15909]\n",
      "loss: 0.062254  [ 2560/15909]\n",
      "loss: 0.051501  [ 2880/15909]\n",
      "loss: 0.059164  [ 3200/15909]\n",
      "loss: 0.060034  [ 3520/15909]\n",
      "loss: 0.056781  [ 3840/15909]\n",
      "loss: 0.063328  [ 4160/15909]\n",
      "loss: 0.053209  [ 4480/15909]\n",
      "loss: 0.051401  [ 4800/15909]\n",
      "loss: 0.047742  [ 5120/15909]\n",
      "loss: 0.059003  [ 5440/15909]\n",
      "loss: 0.056697  [ 5760/15909]\n",
      "loss: 0.053418  [ 6080/15909]\n",
      "loss: 0.058521  [ 6400/15909]\n",
      "loss: 0.055009  [ 6720/15909]\n",
      "loss: 0.054780  [ 7040/15909]\n",
      "loss: 0.060064  [ 7360/15909]\n",
      "loss: 0.059545  [ 7680/15909]\n",
      "loss: 0.057545  [ 8000/15909]\n",
      "loss: 0.052231  [ 8320/15909]\n",
      "loss: 0.052479  [ 8640/15909]\n",
      "loss: 0.060515  [ 8960/15909]\n",
      "loss: 0.053382  [ 9280/15909]\n",
      "loss: 0.050010  [ 9600/15909]\n",
      "loss: 0.058101  [ 9920/15909]\n",
      "loss: 0.070833  [10240/15909]\n",
      "loss: 0.052989  [10560/15909]\n",
      "loss: 0.055728  [10880/15909]\n",
      "loss: 0.058481  [11200/15909]\n",
      "loss: 0.056478  [11520/15909]\n",
      "loss: 0.061644  [11840/15909]\n",
      "loss: 0.057327  [12160/15909]\n",
      "loss: 0.050526  [12480/15909]\n",
      "loss: 0.051929  [12800/15909]\n",
      "loss: 0.066169  [13120/15909]\n",
      "loss: 0.050670  [13440/15909]\n",
      "loss: 0.057291  [13760/15909]\n",
      "loss: 0.050738  [14080/15909]\n",
      "loss: 0.051519  [14400/15909]\n",
      "loss: 0.058064  [14720/15909]\n",
      "loss: 0.052046  [15040/15909]\n",
      "loss: 0.060399  [15360/15909]\n",
      "loss: 0.057865  [15680/15909]\n",
      "Epoch 20 results: Train loss: 0.056897, Val loss: 0.059540\n",
      "EarlyStopping counter: 4 out of 5\n",
      "Epoch 21/50\n",
      "loss: 0.058684  [    0/15909]\n",
      "loss: 0.050250  [  320/15909]\n",
      "loss: 0.054326  [  640/15909]\n",
      "loss: 0.053965  [  960/15909]\n",
      "loss: 0.061615  [ 1280/15909]\n",
      "loss: 0.058890  [ 1600/15909]\n",
      "loss: 0.065872  [ 1920/15909]\n",
      "loss: 0.050201  [ 2240/15909]\n",
      "loss: 0.057921  [ 2560/15909]\n",
      "loss: 0.053201  [ 2880/15909]\n",
      "loss: 0.050029  [ 3200/15909]\n",
      "loss: 0.059836  [ 3520/15909]\n",
      "loss: 0.053596  [ 3840/15909]\n",
      "loss: 0.049880  [ 4160/15909]\n",
      "loss: 0.055122  [ 4480/15909]\n",
      "loss: 0.054172  [ 4800/15909]\n",
      "loss: 0.062340  [ 5120/15909]\n",
      "loss: 0.060108  [ 5440/15909]\n",
      "loss: 0.058983  [ 5760/15909]\n",
      "loss: 0.056332  [ 6080/15909]\n",
      "loss: 0.055662  [ 6400/15909]\n",
      "loss: 0.054586  [ 6720/15909]\n",
      "loss: 0.047589  [ 7040/15909]\n",
      "loss: 0.057930  [ 7360/15909]\n",
      "loss: 0.050723  [ 7680/15909]\n",
      "loss: 0.053016  [ 8000/15909]\n",
      "loss: 0.051707  [ 8320/15909]\n",
      "loss: 0.054850  [ 8640/15909]\n",
      "loss: 0.061071  [ 8960/15909]\n",
      "loss: 0.062830  [ 9280/15909]\n",
      "loss: 0.061791  [ 9600/15909]\n",
      "loss: 0.053618  [ 9920/15909]\n",
      "loss: 0.058242  [10240/15909]\n",
      "loss: 0.056191  [10560/15909]\n",
      "loss: 0.052641  [10880/15909]\n",
      "loss: 0.064052  [11200/15909]\n",
      "loss: 0.050146  [11520/15909]\n",
      "loss: 0.054223  [11840/15909]\n",
      "loss: 0.056052  [12160/15909]\n",
      "loss: 0.051344  [12480/15909]\n",
      "loss: 0.052135  [12800/15909]\n",
      "loss: 0.055857  [13120/15909]\n",
      "loss: 0.052218  [13440/15909]\n",
      "loss: 0.053104  [13760/15909]\n",
      "loss: 0.058710  [14080/15909]\n",
      "loss: 0.055261  [14400/15909]\n",
      "loss: 0.056425  [14720/15909]\n",
      "loss: 0.053684  [15040/15909]\n",
      "loss: 0.049658  [15360/15909]\n",
      "loss: 0.055222  [15680/15909]\n",
      "Epoch 21 results: Train loss: 0.056193, Val loss: 0.058242\n",
      "EarlyStopping counter: 5 out of 5\n",
      "Early stopping triggered. Saving final model to final_model.pth\n",
      "Early stopping triggered\n",
      "Final test loss: 0.059652\n",
      "Training completed!\n"
     ]
    }
   ],
   "source": [
    "# Training routine with EarlyStopping and scheduler\n",
    "def train_model(train_loader, val_loader, model, optimizer, loss_fn, device, num_epochs=25, patience=7):\n",
    "    early_stopping = EarlyStopping(patience=patience, verbose=True)\n",
    "    scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.5, patience=3, verbose=True)\n",
    "\n",
    "    history = {\n",
    "        'train_loss': [],\n",
    "        'val_loss': []\n",
    "    }\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        print(f\"Epoch {epoch+1}/{num_epochs}\")\n",
    "        train_loss = train_one_epoch(train_loader, model, loss_fn, optimizer, device)\n",
    "        val_loss = evaluate_model(val_loader, model, loss_fn, device)\n",
    "\n",
    "        history['train_loss'].append(train_loss)\n",
    "        history['val_loss'].append(val_loss)\n",
    "\n",
    "        print(f\"Epoch {epoch+1} results: Train loss: {train_loss:.6f}, Val loss: {val_loss:.6f}\")\n",
    "\n",
    "        scheduler.step(val_loss)\n",
    "        early_stopping(val_loss, model)\n",
    "        if early_stopping.early_stop:\n",
    "            print(\"Early stopping triggered\")\n",
    "            break\n",
    "\n",
    "    model.load_state_dict(torch.load('checkpoint.pt'))\n",
    "    plot_training_history(history)\n",
    "    return model, history\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Call the training function\n",
    "    patience = config['training']['patience'] if 'patience' in config['training'] else 7\n",
    "    trained_model, training_history = train_model(\n",
    "        train_loader=train_loader,\n",
    "        val_loader=val_loader,\n",
    "        model=model,\n",
    "        optimizer=optimizer,\n",
    "        loss_fn=loss_fn,\n",
    "        device=device,\n",
    "        num_epochs=epochs,\n",
    "        patience=patience\n",
    "    )\n",
    "    \n",
    "    # Evaluate on test set\n",
    "    test_loss = evaluate_model(test_loader, trained_model, loss_fn, device)\n",
    "    print(f\"Final test loss: {test_loss:.6f}\")\n",
    "    \n",
    "    print(\"Training completed!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22683322",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ML",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
