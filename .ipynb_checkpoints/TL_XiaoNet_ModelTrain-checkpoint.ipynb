{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "26f20d35-d7d0-4c4d-be67-4940629fac55",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded packages successfully!\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python\n",
    "# coding: utf-8\n",
    "\n",
    "import json\n",
    "import time\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import obspy\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import torch\n",
    "from obspy import UTCDateTime\n",
    "from obspy.clients.fdsn import Client\n",
    "from scipy.signal import find_peaks\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "import seisbench.data as sbd\n",
    "import seisbench.generate as sbg\n",
    "import seisbench.models as sbm\n",
    "from seisbench.util import worker_seeding\n",
    "\n",
    "print(\"Loaded packages successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8401662a-8947-40c9-8ab9-2ac520e52b65",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úì Configuration loaded successfully!\n",
      "Configuration loaded:\n",
      "Training:\n",
      "  batch_size: 64\n",
      "  num_workers: 4\n",
      "  learning_rate: 0.01\n",
      "  epochs: 50\n",
      "  patience: 5\n",
      "Device:\n",
      "  use_cuda: True\n",
      "  device_id: 0\n",
      "Peak detection:\n",
      "  sampling_rate: 100\n",
      "  height: 0.5\n",
      "  distance: 100\n"
     ]
    }
   ],
   "source": [
    "# Load configuration from JSON file\n",
    "try:\n",
    "    with open('config.json', 'r') as f:\n",
    "        config = json.load(f)\n",
    "    print(\"‚úì Configuration loaded successfully!\")\n",
    "except FileNotFoundError:\n",
    "    print(\"‚úó Error: config.json file not found!\")\n",
    "    raise\n",
    "except json.JSONDecodeError as e:\n",
    "    print(f\"‚úó Error: Invalid JSON in config.json: {e}\")\n",
    "    raise\n",
    "except Exception as e:\n",
    "    print(f\"‚úó Unexpected error loading config: {e}\")\n",
    "    raise\n",
    "\n",
    "# Debug: print configuration summary\n",
    "print(\"Configuration loaded:\")\n",
    "print(\"Training:\")\n",
    "print(f\"  batch_size: {config['training']['batch_size']}\")\n",
    "print(f\"  num_workers: {config['training']['num_workers']}\")\n",
    "print(f\"  learning_rate: {config['training']['learning_rate']}\")\n",
    "print(f\"  epochs: {config['training']['epochs']}\")\n",
    "print(f\"  patience: {config['training']['patience']}\")\n",
    "print(\"Device:\")\n",
    "print(f\"  use_cuda: {config['device']['use_cuda']}\")\n",
    "print(f\"  device_id: {config['device']['device_id']}\")\n",
    "print(\"Peak detection:\")\n",
    "print(f\"  sampling_rate: {config['peak_detection']['sampling_rate']}\")\n",
    "print(f\"  height: {config['peak_detection']['height']}\")\n",
    "print(f\"  distance: {config['peak_detection']['distance']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4494e2c8-84dc-433f-8856-07f9a0699696",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random seed selected: 0\n"
     ]
    }
   ],
   "source": [
    "# Set random seed for reproducibility\n",
    "import random\n",
    "import os\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "seed = 0\n",
    "print(f\"Random seed selected: {seed}\")\n",
    "random.seed(seed)\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ed02a712-8a86-4731-a16a-98f2915d8b73",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úì Model loaded successfully!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# Loader the picker\n",
    "try:\n",
    "    model = sbm.PhaseNet.from_pretrained(\"stead\")\n",
    "    print(\"‚úì Model loaded successfully!\")\n",
    "except Exception as e:\n",
    "    print(f\"‚úó Error loading model: {e}\")\n",
    "    raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "72aba97c-78a0-4a7c-aef3-6396493c4556",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "PhaseNet(\n",
       "  (inc): Conv1d(3, 8, kernel_size=(7,), stride=(1,), padding=same)\n",
       "  (in_bn): BatchNorm1d(8, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (down_branch): ModuleList(\n",
       "    (0): ModuleList(\n",
       "      (0): Conv1d(8, 8, kernel_size=(7,), stride=(1,), padding=same, bias=False)\n",
       "      (1): BatchNorm1d(8, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): Conv1d(8, 8, kernel_size=(7,), stride=(4,), padding=(3,), bias=False)\n",
       "      (3): BatchNorm1d(8, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (1): ModuleList(\n",
       "      (0): Conv1d(8, 16, kernel_size=(7,), stride=(1,), padding=same, bias=False)\n",
       "      (1): BatchNorm1d(16, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): Conv1d(16, 16, kernel_size=(7,), stride=(4,), bias=False)\n",
       "      (3): BatchNorm1d(16, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (2): ModuleList(\n",
       "      (0): Conv1d(16, 32, kernel_size=(7,), stride=(1,), padding=same, bias=False)\n",
       "      (1): BatchNorm1d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): Conv1d(32, 32, kernel_size=(7,), stride=(4,), bias=False)\n",
       "      (3): BatchNorm1d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (3): ModuleList(\n",
       "      (0): Conv1d(32, 64, kernel_size=(7,), stride=(1,), padding=same, bias=False)\n",
       "      (1): BatchNorm1d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): Conv1d(64, 64, kernel_size=(7,), stride=(4,), bias=False)\n",
       "      (3): BatchNorm1d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (4): ModuleList(\n",
       "      (0): Conv1d(64, 128, kernel_size=(7,), stride=(1,), padding=same, bias=False)\n",
       "      (1): BatchNorm1d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2-3): 2 x None\n",
       "    )\n",
       "  )\n",
       "  (up_branch): ModuleList(\n",
       "    (0): ModuleList(\n",
       "      (0): ConvTranspose1d(128, 64, kernel_size=(7,), stride=(4,), bias=False)\n",
       "      (1): BatchNorm1d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): Conv1d(128, 64, kernel_size=(7,), stride=(1,), padding=same, bias=False)\n",
       "      (3): BatchNorm1d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (1): ModuleList(\n",
       "      (0): ConvTranspose1d(64, 32, kernel_size=(7,), stride=(4,), bias=False)\n",
       "      (1): BatchNorm1d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): Conv1d(64, 32, kernel_size=(7,), stride=(1,), padding=same, bias=False)\n",
       "      (3): BatchNorm1d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (2): ModuleList(\n",
       "      (0): ConvTranspose1d(32, 16, kernel_size=(7,), stride=(4,), bias=False)\n",
       "      (1): BatchNorm1d(16, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): Conv1d(32, 16, kernel_size=(7,), stride=(1,), padding=same, bias=False)\n",
       "      (3): BatchNorm1d(16, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (3): ModuleList(\n",
       "      (0): ConvTranspose1d(16, 8, kernel_size=(7,), stride=(4,), bias=False)\n",
       "      (1): BatchNorm1d(8, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): Conv1d(16, 8, kernel_size=(7,), stride=(1,), padding=same, bias=False)\n",
       "      (3): BatchNorm1d(8, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (out): Conv1d(8, 3, kernel_size=(1,), stride=(1,), padding=same)\n",
       "  (softmax): Softmax(dim=1)\n",
       ")"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Set up device\n",
    "device = torch.device(f\"cuda:{config['device']['device_id']}\" if torch.cuda.is_available() and config['device']['use_cuda'] else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "model.to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d90d0871-cd56-403e-9769-5a4c1c7b83fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PhaseNet information:\n",
      "Total parameters: 268,443\n",
      "Trainable parameters: 268,443\n",
      "Model size: 1.02 MB (float32)\n"
     ]
    }
   ],
   "source": [
    "# Print PhaseNet model information\n",
    "phasenet_total_params = sum(p.numel() for p in model.parameters())\n",
    "phasenet_trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "print(\"PhaseNet information:\")\n",
    "print(f\"Total parameters: {phasenet_total_params:,}\")\n",
    "print(f\"Trainable parameters: {phasenet_trainable_params:,}\")\n",
    "print(f\"Model size: {phasenet_total_params * 4 / (1024**2):.2f} MB (float32)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e69f637f-8143-4924-913a-11cc0262f7b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úì XiaoNet created successfully!\n",
      "Total parameters: 164,355\n",
      "Trainable parameters: 164,355\n",
      "Model size: 0.63 MB (float32)\n"
     ]
    }
   ],
   "source": [
    "# Import XiaoNet from models\n",
    "import sys\n",
    "import os\n",
    "\n",
    "# Add project root to path (works from any location)\n",
    "# This notebook is in archive/, so go up one level to get to project root\n",
    "notebook_dir = os.path.dirname(os.path.abspath('__file__')) if '__file__' in dir() else os.getcwd()\n",
    "project_root = os.path.abspath(os.path.join(notebook_dir, '..'))\n",
    "if project_root not in sys.path:\n",
    "    sys.path.insert(0, project_root)\n",
    "\n",
    "# Remove old module from cache if it exists\n",
    "if 'models.xn_xiao_net' in sys.modules:\n",
    "    del sys.modules['models.xn_xiao_net']\n",
    "\n",
    "from models.xn_xiao_net import XiaoNet\n",
    "\n",
    "# Create XiaoNet model\n",
    "xiao_net = XiaoNet(\n",
    "    window_len=3001,      # Match the data window length\n",
    "    in_channels=3,        # 3 channels (E, N, Z)\n",
    "    num_phases=3,         # 3 outputs (P, S, noise)\n",
    "    base_channels=16      # Base channel width (can adjust for size)\n",
    ")\n",
    "xiao_net.to(device)\n",
    "\n",
    "# Count parameters\n",
    "total_params = sum(p.numel() for p in xiao_net.parameters())\n",
    "trainable_params = sum(p.numel() for p in xiao_net.parameters() if p.requires_grad)\n",
    "\n",
    "print(f\"‚úì XiaoNet created successfully!\")\n",
    "print(f\"Total parameters: {total_params:,}\")\n",
    "print(f\"Trainable parameters: {trainable_params:,}\")\n",
    "print(f\"Model size: {total_params * 4 / (1024**2):.2f} MB (float32)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e435c9f6-d4b2-4318-87d0-4d22985d9e76",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data...\n",
      "‚úì Data loaded successfully!\n"
     ]
    }
   ],
   "source": [
    "# Load the data\n",
    "print(\"Loading data...\")\n",
    "try:\n",
    "    data = sbd.OKLA_1Mil_120s_Ver_3(sampling_rate=100, force=True, component_order=\"ENZ\")\n",
    "    print(\"‚úì Data loaded successfully!\")\n",
    "\n",
    "except Exception as e:\n",
    "\n",
    "    print(f\"‚úó Error loading data: {e}\")\n",
    "    raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "111ee465-0644-4dfb-bd02-9a172430bbdf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating random sample of 1.0% of the data...\n"
     ]
    }
   ],
   "source": [
    "# Create a random sample\n",
    "sample_fraction = 0.01  # Sample 20% of the data\n",
    "print(f\"Creating random sample of {sample_fraction*100}% of the data...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b39d63aa-0c6c-49db-b196-1db7b14c9903",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sampled dataset size: 11270\n"
     ]
    }
   ],
   "source": [
    "# Create a random mask for sampling\n",
    "\n",
    "mask = np.random.random(len(data)) < sample_fraction\n",
    "data.filter(mask)\n",
    "\n",
    "print(f\"Sampled dataset size: {len(data)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "1db2f777-82ca-4897-931e-4b1fae308569",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample metadata:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>station_network_code</th>\n",
       "      <th>station_code</th>\n",
       "      <th>trace_channel</th>\n",
       "      <th>station_latitude_deg</th>\n",
       "      <th>station_longitude_deg</th>\n",
       "      <th>station_elevation_m</th>\n",
       "      <th>trace_p_arrival_sample</th>\n",
       "      <th>trace_p_status</th>\n",
       "      <th>trace_p_weight</th>\n",
       "      <th>...</th>\n",
       "      <th>trace_snr_db</th>\n",
       "      <th>trace_coda_end_sample</th>\n",
       "      <th>trace_start_time</th>\n",
       "      <th>trace_category</th>\n",
       "      <th>trace_name</th>\n",
       "      <th>split</th>\n",
       "      <th>trace_name_original</th>\n",
       "      <th>trace_chunk</th>\n",
       "      <th>trace_sampling_rate_hz</th>\n",
       "      <th>trace_component_order</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>99</td>\n",
       "      <td>2V</td>\n",
       "      <td>TG11</td>\n",
       "      <td>EHE</td>\n",
       "      <td>35.2689</td>\n",
       "      <td>-97.8146</td>\n",
       "      <td>407.0</td>\n",
       "      <td>5999.0</td>\n",
       "      <td>manual</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2023-09-24T13:16:05.274999Z</td>\n",
       "      <td>earthquake_local</td>\n",
       "      <td>bucket0$75,:3,:12001</td>\n",
       "      <td>train</td>\n",
       "      <td>2V.TG11.EHE.EHN.EHZ.2023-09-24T1316052023-09-2...</td>\n",
       "      <td></td>\n",
       "      <td>100</td>\n",
       "      <td>ZNE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>524</th>\n",
       "      <td>524</td>\n",
       "      <td>2V</td>\n",
       "      <td>TG11</td>\n",
       "      <td>EHE</td>\n",
       "      <td>35.2689</td>\n",
       "      <td>-97.8146</td>\n",
       "      <td>407.0</td>\n",
       "      <td>5999.0</td>\n",
       "      <td>manual</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2024-03-15T18:13:14.055000Z</td>\n",
       "      <td>earthquake_local</td>\n",
       "      <td>bucket0$377,:3,:12001</td>\n",
       "      <td>train</td>\n",
       "      <td>2V.TG11.EHE.EHN.EHZ.2024-03-15T1813142024-03-1...</td>\n",
       "      <td></td>\n",
       "      <td>100</td>\n",
       "      <td>ZNE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>540</th>\n",
       "      <td>540</td>\n",
       "      <td>2V</td>\n",
       "      <td>TG11</td>\n",
       "      <td>EHE</td>\n",
       "      <td>35.2689</td>\n",
       "      <td>-97.8146</td>\n",
       "      <td>407.0</td>\n",
       "      <td>5999.0</td>\n",
       "      <td>manual</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2024-03-22T08:27:12.879999Z</td>\n",
       "      <td>earthquake_local</td>\n",
       "      <td>bucket0$391,:3,:12001</td>\n",
       "      <td>train</td>\n",
       "      <td>2V.TG11.EHE.EHN.EHZ.2024-03-22T0827122024-03-2...</td>\n",
       "      <td></td>\n",
       "      <td>100</td>\n",
       "      <td>ZNE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>742</th>\n",
       "      <td>742</td>\n",
       "      <td>2V</td>\n",
       "      <td>TG11</td>\n",
       "      <td>EHE</td>\n",
       "      <td>35.2689</td>\n",
       "      <td>-97.8146</td>\n",
       "      <td>407.0</td>\n",
       "      <td>6000.0</td>\n",
       "      <td>manual</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2024-07-12T12:18:13.550000Z</td>\n",
       "      <td>earthquake_local</td>\n",
       "      <td>bucket4$82,:3,:12001</td>\n",
       "      <td>dev</td>\n",
       "      <td>2V.TG11.EHE.EHN.EHZ.2024-07-12T1218132024-07-1...</td>\n",
       "      <td></td>\n",
       "      <td>100</td>\n",
       "      <td>ZNE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>757</th>\n",
       "      <td>757</td>\n",
       "      <td>2V</td>\n",
       "      <td>TG11</td>\n",
       "      <td>EHE</td>\n",
       "      <td>35.2689</td>\n",
       "      <td>-97.8146</td>\n",
       "      <td>407.0</td>\n",
       "      <td>5999.0</td>\n",
       "      <td>manual</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2024-07-18T08:17:44.720000Z</td>\n",
       "      <td>earthquake_local</td>\n",
       "      <td>bucket0$549,:3,:12001</td>\n",
       "      <td>train</td>\n",
       "      <td>2V.TG11.EHE.EHN.EHZ.2024-07-18T0817442024-07-1...</td>\n",
       "      <td></td>\n",
       "      <td>100</td>\n",
       "      <td>ZNE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>821</th>\n",
       "      <td>821</td>\n",
       "      <td>2V</td>\n",
       "      <td>TG11</td>\n",
       "      <td>EHE</td>\n",
       "      <td>35.2689</td>\n",
       "      <td>-97.8146</td>\n",
       "      <td>407.0</td>\n",
       "      <td>5999.0</td>\n",
       "      <td>manual</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2024-08-03T03:22:28.699999Z</td>\n",
       "      <td>earthquake_local</td>\n",
       "      <td>bucket0$593,:3,:12001</td>\n",
       "      <td>train</td>\n",
       "      <td>2V.TG11.EHE.EHN.EHZ.2024-08-03T0322282024-08-0...</td>\n",
       "      <td></td>\n",
       "      <td>100</td>\n",
       "      <td>ZNE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>852</th>\n",
       "      <td>852</td>\n",
       "      <td>2V</td>\n",
       "      <td>TG11</td>\n",
       "      <td>EHE</td>\n",
       "      <td>35.2689</td>\n",
       "      <td>-97.8146</td>\n",
       "      <td>407.0</td>\n",
       "      <td>5999.0</td>\n",
       "      <td>manual</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2024-08-09T10:14:19.479999Z</td>\n",
       "      <td>earthquake_local</td>\n",
       "      <td>bucket0$611,:3,:12001</td>\n",
       "      <td>train</td>\n",
       "      <td>2V.TG11.EHE.EHN.EHZ.2024-08-09T1014192024-08-0...</td>\n",
       "      <td></td>\n",
       "      <td>100</td>\n",
       "      <td>ZNE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1062</th>\n",
       "      <td>1062</td>\n",
       "      <td>2V</td>\n",
       "      <td>TG11</td>\n",
       "      <td>EHE</td>\n",
       "      <td>35.2689</td>\n",
       "      <td>-97.8146</td>\n",
       "      <td>407.0</td>\n",
       "      <td>5999.0</td>\n",
       "      <td>manual</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2024-11-19T21:40:44.520000Z</td>\n",
       "      <td>earthquake_local</td>\n",
       "      <td>bucket5$173,:3,:12001</td>\n",
       "      <td>test</td>\n",
       "      <td>2V.TG11.EHE.EHN.EHZ.2024-11-19T2140442024-11-1...</td>\n",
       "      <td></td>\n",
       "      <td>100</td>\n",
       "      <td>ZNE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1070</th>\n",
       "      <td>1070</td>\n",
       "      <td>2V</td>\n",
       "      <td>TG11</td>\n",
       "      <td>EHE</td>\n",
       "      <td>35.2689</td>\n",
       "      <td>-97.8146</td>\n",
       "      <td>407.0</td>\n",
       "      <td>5999.0</td>\n",
       "      <td>manual</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2024-12-07T04:18:22.749999Z</td>\n",
       "      <td>earthquake_local</td>\n",
       "      <td>bucket0$759,:3,:12001</td>\n",
       "      <td>train</td>\n",
       "      <td>2V.TG11.EHE.EHN.EHZ.2024-12-07T0418222024-12-0...</td>\n",
       "      <td></td>\n",
       "      <td>100</td>\n",
       "      <td>ZNE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1130</th>\n",
       "      <td>1130</td>\n",
       "      <td>2V</td>\n",
       "      <td>TG11</td>\n",
       "      <td>EHE</td>\n",
       "      <td>35.2689</td>\n",
       "      <td>-97.8146</td>\n",
       "      <td>407.0</td>\n",
       "      <td>5999.0</td>\n",
       "      <td>manual</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2025-02-19T22:35:23.879999Z</td>\n",
       "      <td>earthquake_local</td>\n",
       "      <td>bucket0$798,:3,:12001</td>\n",
       "      <td>train</td>\n",
       "      <td>2V.TG11.EHE.EHN.EHZ.2025-02-19T2235232025-02-1...</td>\n",
       "      <td></td>\n",
       "      <td>100</td>\n",
       "      <td>ZNE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1234</th>\n",
       "      <td>1234</td>\n",
       "      <td>2V</td>\n",
       "      <td>TG11</td>\n",
       "      <td>EHE</td>\n",
       "      <td>35.2689</td>\n",
       "      <td>-97.8146</td>\n",
       "      <td>407.0</td>\n",
       "      <td>5999.0</td>\n",
       "      <td>manual</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2025-02-22T06:09:46.290000Z</td>\n",
       "      <td>earthquake_local</td>\n",
       "      <td>bucket0$869,:3,:12001</td>\n",
       "      <td>train</td>\n",
       "      <td>2V.TG11.EHE.EHN.EHZ.2025-02-22T0609462025-02-2...</td>\n",
       "      <td></td>\n",
       "      <td>100</td>\n",
       "      <td>ZNE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1633</th>\n",
       "      <td>1633</td>\n",
       "      <td>AG</td>\n",
       "      <td>HHAR</td>\n",
       "      <td>HHE</td>\n",
       "      <td>36.2820</td>\n",
       "      <td>-93.9400</td>\n",
       "      <td>421.0</td>\n",
       "      <td>5999.0</td>\n",
       "      <td>manual</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2014-05-28T19:54:33.040000Z</td>\n",
       "      <td>earthquake_local</td>\n",
       "      <td>bucket1$102,:3,:12001</td>\n",
       "      <td>train</td>\n",
       "      <td>AG.HHAR.HHE.HHN.HHZ.2014-05-28T1954332014-05-2...</td>\n",
       "      <td></td>\n",
       "      <td>100</td>\n",
       "      <td>ZNE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1712</th>\n",
       "      <td>1712</td>\n",
       "      <td>AG</td>\n",
       "      <td>HHAR</td>\n",
       "      <td>HHE</td>\n",
       "      <td>36.2820</td>\n",
       "      <td>-93.9400</td>\n",
       "      <td>421.0</td>\n",
       "      <td>5999.0</td>\n",
       "      <td>manual</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2014-11-15T15:28:44.140000Z</td>\n",
       "      <td>earthquake_local</td>\n",
       "      <td>bucket5$287,:3,:12001</td>\n",
       "      <td>test</td>\n",
       "      <td>AG.HHAR.HHE.HHN.HHZ.2014-11-15T1528442014-11-1...</td>\n",
       "      <td></td>\n",
       "      <td>100</td>\n",
       "      <td>ZNE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1747</th>\n",
       "      <td>1747</td>\n",
       "      <td>AG</td>\n",
       "      <td>HHAR</td>\n",
       "      <td>HHE</td>\n",
       "      <td>36.2820</td>\n",
       "      <td>-93.9400</td>\n",
       "      <td>421.0</td>\n",
       "      <td>5999.0</td>\n",
       "      <td>manual</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2014-12-02T01:51:29.870000Z</td>\n",
       "      <td>earthquake_local</td>\n",
       "      <td>bucket5$289,:3,:12001</td>\n",
       "      <td>test</td>\n",
       "      <td>AG.HHAR.HHE.HHN.HHZ.2014-12-02T0151292014-12-0...</td>\n",
       "      <td></td>\n",
       "      <td>100</td>\n",
       "      <td>ZNE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1923</th>\n",
       "      <td>1923</td>\n",
       "      <td>AG</td>\n",
       "      <td>HHAR</td>\n",
       "      <td>HHE</td>\n",
       "      <td>36.2820</td>\n",
       "      <td>-93.9400</td>\n",
       "      <td>421.0</td>\n",
       "      <td>6000.0</td>\n",
       "      <td>manual</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2015-03-02T20:10:28.440000Z</td>\n",
       "      <td>earthquake_local</td>\n",
       "      <td>bucket1$298,:3,:12001</td>\n",
       "      <td>train</td>\n",
       "      <td>AG.HHAR.HHE.HHN.HHZ.2015-03-02T2010282015-03-0...</td>\n",
       "      <td></td>\n",
       "      <td>100</td>\n",
       "      <td>ZNE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1946</th>\n",
       "      <td>1946</td>\n",
       "      <td>AG</td>\n",
       "      <td>HHAR</td>\n",
       "      <td>HHE</td>\n",
       "      <td>36.2820</td>\n",
       "      <td>-93.9400</td>\n",
       "      <td>421.0</td>\n",
       "      <td>5999.0</td>\n",
       "      <td>manual</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2015-03-07T22:11:05.730000Z</td>\n",
       "      <td>earthquake_local</td>\n",
       "      <td>bucket5$321,:3,:12001</td>\n",
       "      <td>test</td>\n",
       "      <td>AG.HHAR.HHE.HHN.HHZ.2015-03-07T2211052015-03-0...</td>\n",
       "      <td></td>\n",
       "      <td>100</td>\n",
       "      <td>ZNE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1947</th>\n",
       "      <td>1947</td>\n",
       "      <td>AG</td>\n",
       "      <td>HHAR</td>\n",
       "      <td>HHE</td>\n",
       "      <td>36.2820</td>\n",
       "      <td>-93.9400</td>\n",
       "      <td>421.0</td>\n",
       "      <td>5999.0</td>\n",
       "      <td>manual</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2015-03-07T22:26:49.220000Z</td>\n",
       "      <td>earthquake_local</td>\n",
       "      <td>bucket4$282,:3,:12001</td>\n",
       "      <td>dev</td>\n",
       "      <td>AG.HHAR.HHE.HHN.HHZ.2015-03-07T2226492015-03-0...</td>\n",
       "      <td></td>\n",
       "      <td>100</td>\n",
       "      <td>ZNE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1974</th>\n",
       "      <td>1974</td>\n",
       "      <td>AG</td>\n",
       "      <td>HHAR</td>\n",
       "      <td>HHE</td>\n",
       "      <td>36.2820</td>\n",
       "      <td>-93.9400</td>\n",
       "      <td>421.0</td>\n",
       "      <td>6000.0</td>\n",
       "      <td>manual</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2015-03-12T22:20:30.320000Z</td>\n",
       "      <td>earthquake_local</td>\n",
       "      <td>bucket4$286,:3,:12001</td>\n",
       "      <td>dev</td>\n",
       "      <td>AG.HHAR.HHE.HHN.HHZ.2015-03-12T2220302015-03-1...</td>\n",
       "      <td></td>\n",
       "      <td>100</td>\n",
       "      <td>ZNE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2032</th>\n",
       "      <td>2032</td>\n",
       "      <td>AG</td>\n",
       "      <td>HHAR</td>\n",
       "      <td>HHE</td>\n",
       "      <td>36.2820</td>\n",
       "      <td>-93.9400</td>\n",
       "      <td>421.0</td>\n",
       "      <td>6000.0</td>\n",
       "      <td>manual</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2015-03-29T02:45:11.775000Z</td>\n",
       "      <td>earthquake_local</td>\n",
       "      <td>bucket1$375,:3,:12001</td>\n",
       "      <td>train</td>\n",
       "      <td>AG.HHAR.HHE.HHN.HHZ.2015-03-29T0245112015-03-2...</td>\n",
       "      <td></td>\n",
       "      <td>100</td>\n",
       "      <td>ZNE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2055</th>\n",
       "      <td>2055</td>\n",
       "      <td>AG</td>\n",
       "      <td>HHAR</td>\n",
       "      <td>HHE</td>\n",
       "      <td>36.2820</td>\n",
       "      <td>-93.9400</td>\n",
       "      <td>421.0</td>\n",
       "      <td>6000.0</td>\n",
       "      <td>manual</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2015-04-03T22:32:52.065000Z</td>\n",
       "      <td>earthquake_local</td>\n",
       "      <td>bucket4$300,:3,:12001</td>\n",
       "      <td>dev</td>\n",
       "      <td>AG.HHAR.HHE.HHN.HHZ.2015-04-03T2232522015-04-0...</td>\n",
       "      <td></td>\n",
       "      <td>100</td>\n",
       "      <td>ZNE</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>20 rows √ó 41 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      index station_network_code station_code trace_channel  \\\n",
       "99       99                   2V         TG11           EHE   \n",
       "524     524                   2V         TG11           EHE   \n",
       "540     540                   2V         TG11           EHE   \n",
       "742     742                   2V         TG11           EHE   \n",
       "757     757                   2V         TG11           EHE   \n",
       "821     821                   2V         TG11           EHE   \n",
       "852     852                   2V         TG11           EHE   \n",
       "1062   1062                   2V         TG11           EHE   \n",
       "1070   1070                   2V         TG11           EHE   \n",
       "1130   1130                   2V         TG11           EHE   \n",
       "1234   1234                   2V         TG11           EHE   \n",
       "1633   1633                   AG         HHAR           HHE   \n",
       "1712   1712                   AG         HHAR           HHE   \n",
       "1747   1747                   AG         HHAR           HHE   \n",
       "1923   1923                   AG         HHAR           HHE   \n",
       "1946   1946                   AG         HHAR           HHE   \n",
       "1947   1947                   AG         HHAR           HHE   \n",
       "1974   1974                   AG         HHAR           HHE   \n",
       "2032   2032                   AG         HHAR           HHE   \n",
       "2055   2055                   AG         HHAR           HHE   \n",
       "\n",
       "      station_latitude_deg  station_longitude_deg  station_elevation_m  \\\n",
       "99                 35.2689               -97.8146                407.0   \n",
       "524                35.2689               -97.8146                407.0   \n",
       "540                35.2689               -97.8146                407.0   \n",
       "742                35.2689               -97.8146                407.0   \n",
       "757                35.2689               -97.8146                407.0   \n",
       "821                35.2689               -97.8146                407.0   \n",
       "852                35.2689               -97.8146                407.0   \n",
       "1062               35.2689               -97.8146                407.0   \n",
       "1070               35.2689               -97.8146                407.0   \n",
       "1130               35.2689               -97.8146                407.0   \n",
       "1234               35.2689               -97.8146                407.0   \n",
       "1633               36.2820               -93.9400                421.0   \n",
       "1712               36.2820               -93.9400                421.0   \n",
       "1747               36.2820               -93.9400                421.0   \n",
       "1923               36.2820               -93.9400                421.0   \n",
       "1946               36.2820               -93.9400                421.0   \n",
       "1947               36.2820               -93.9400                421.0   \n",
       "1974               36.2820               -93.9400                421.0   \n",
       "2032               36.2820               -93.9400                421.0   \n",
       "2055               36.2820               -93.9400                421.0   \n",
       "\n",
       "      trace_p_arrival_sample trace_p_status  trace_p_weight  ...  \\\n",
       "99                    5999.0         manual             1.0  ...   \n",
       "524                   5999.0         manual             1.0  ...   \n",
       "540                   5999.0         manual             1.0  ...   \n",
       "742                   6000.0         manual             1.0  ...   \n",
       "757                   5999.0         manual             1.0  ...   \n",
       "821                   5999.0         manual             1.0  ...   \n",
       "852                   5999.0         manual             1.0  ...   \n",
       "1062                  5999.0         manual             1.0  ...   \n",
       "1070                  5999.0         manual             1.0  ...   \n",
       "1130                  5999.0         manual             1.0  ...   \n",
       "1234                  5999.0         manual             1.0  ...   \n",
       "1633                  5999.0         manual             1.0  ...   \n",
       "1712                  5999.0         manual             1.0  ...   \n",
       "1747                  5999.0         manual             1.0  ...   \n",
       "1923                  6000.0         manual             1.0  ...   \n",
       "1946                  5999.0         manual             1.0  ...   \n",
       "1947                  5999.0         manual             1.0  ...   \n",
       "1974                  6000.0         manual             1.0  ...   \n",
       "2032                  6000.0         manual             1.0  ...   \n",
       "2055                  6000.0         manual             1.0  ...   \n",
       "\n",
       "      trace_snr_db  trace_coda_end_sample             trace_start_time  \\\n",
       "99             NaN                    NaN  2023-09-24T13:16:05.274999Z   \n",
       "524            NaN                    NaN  2024-03-15T18:13:14.055000Z   \n",
       "540            NaN                    NaN  2024-03-22T08:27:12.879999Z   \n",
       "742            NaN                    NaN  2024-07-12T12:18:13.550000Z   \n",
       "757            NaN                    NaN  2024-07-18T08:17:44.720000Z   \n",
       "821            NaN                    NaN  2024-08-03T03:22:28.699999Z   \n",
       "852            NaN                    NaN  2024-08-09T10:14:19.479999Z   \n",
       "1062           NaN                    NaN  2024-11-19T21:40:44.520000Z   \n",
       "1070           NaN                    NaN  2024-12-07T04:18:22.749999Z   \n",
       "1130           NaN                    NaN  2025-02-19T22:35:23.879999Z   \n",
       "1234           NaN                    NaN  2025-02-22T06:09:46.290000Z   \n",
       "1633           NaN                    NaN  2014-05-28T19:54:33.040000Z   \n",
       "1712           NaN                    NaN  2014-11-15T15:28:44.140000Z   \n",
       "1747           NaN                    NaN  2014-12-02T01:51:29.870000Z   \n",
       "1923           NaN                    NaN  2015-03-02T20:10:28.440000Z   \n",
       "1946           NaN                    NaN  2015-03-07T22:11:05.730000Z   \n",
       "1947           NaN                    NaN  2015-03-07T22:26:49.220000Z   \n",
       "1974           NaN                    NaN  2015-03-12T22:20:30.320000Z   \n",
       "2032           NaN                    NaN  2015-03-29T02:45:11.775000Z   \n",
       "2055           NaN                    NaN  2015-04-03T22:32:52.065000Z   \n",
       "\n",
       "        trace_category             trace_name  split  \\\n",
       "99    earthquake_local   bucket0$75,:3,:12001  train   \n",
       "524   earthquake_local  bucket0$377,:3,:12001  train   \n",
       "540   earthquake_local  bucket0$391,:3,:12001  train   \n",
       "742   earthquake_local   bucket4$82,:3,:12001    dev   \n",
       "757   earthquake_local  bucket0$549,:3,:12001  train   \n",
       "821   earthquake_local  bucket0$593,:3,:12001  train   \n",
       "852   earthquake_local  bucket0$611,:3,:12001  train   \n",
       "1062  earthquake_local  bucket5$173,:3,:12001   test   \n",
       "1070  earthquake_local  bucket0$759,:3,:12001  train   \n",
       "1130  earthquake_local  bucket0$798,:3,:12001  train   \n",
       "1234  earthquake_local  bucket0$869,:3,:12001  train   \n",
       "1633  earthquake_local  bucket1$102,:3,:12001  train   \n",
       "1712  earthquake_local  bucket5$287,:3,:12001   test   \n",
       "1747  earthquake_local  bucket5$289,:3,:12001   test   \n",
       "1923  earthquake_local  bucket1$298,:3,:12001  train   \n",
       "1946  earthquake_local  bucket5$321,:3,:12001   test   \n",
       "1947  earthquake_local  bucket4$282,:3,:12001    dev   \n",
       "1974  earthquake_local  bucket4$286,:3,:12001    dev   \n",
       "2032  earthquake_local  bucket1$375,:3,:12001  train   \n",
       "2055  earthquake_local  bucket4$300,:3,:12001    dev   \n",
       "\n",
       "                                    trace_name_original  trace_chunk  \\\n",
       "99    2V.TG11.EHE.EHN.EHZ.2023-09-24T1316052023-09-2...                \n",
       "524   2V.TG11.EHE.EHN.EHZ.2024-03-15T1813142024-03-1...                \n",
       "540   2V.TG11.EHE.EHN.EHZ.2024-03-22T0827122024-03-2...                \n",
       "742   2V.TG11.EHE.EHN.EHZ.2024-07-12T1218132024-07-1...                \n",
       "757   2V.TG11.EHE.EHN.EHZ.2024-07-18T0817442024-07-1...                \n",
       "821   2V.TG11.EHE.EHN.EHZ.2024-08-03T0322282024-08-0...                \n",
       "852   2V.TG11.EHE.EHN.EHZ.2024-08-09T1014192024-08-0...                \n",
       "1062  2V.TG11.EHE.EHN.EHZ.2024-11-19T2140442024-11-1...                \n",
       "1070  2V.TG11.EHE.EHN.EHZ.2024-12-07T0418222024-12-0...                \n",
       "1130  2V.TG11.EHE.EHN.EHZ.2025-02-19T2235232025-02-1...                \n",
       "1234  2V.TG11.EHE.EHN.EHZ.2025-02-22T0609462025-02-2...                \n",
       "1633  AG.HHAR.HHE.HHN.HHZ.2014-05-28T1954332014-05-2...                \n",
       "1712  AG.HHAR.HHE.HHN.HHZ.2014-11-15T1528442014-11-1...                \n",
       "1747  AG.HHAR.HHE.HHN.HHZ.2014-12-02T0151292014-12-0...                \n",
       "1923  AG.HHAR.HHE.HHN.HHZ.2015-03-02T2010282015-03-0...                \n",
       "1946  AG.HHAR.HHE.HHN.HHZ.2015-03-07T2211052015-03-0...                \n",
       "1947  AG.HHAR.HHE.HHN.HHZ.2015-03-07T2226492015-03-0...                \n",
       "1974  AG.HHAR.HHE.HHN.HHZ.2015-03-12T2220302015-03-1...                \n",
       "2032  AG.HHAR.HHE.HHN.HHZ.2015-03-29T0245112015-03-2...                \n",
       "2055  AG.HHAR.HHE.HHN.HHZ.2015-04-03T2232522015-04-0...                \n",
       "\n",
       "      trace_sampling_rate_hz  trace_component_order  \n",
       "99                       100                    ZNE  \n",
       "524                      100                    ZNE  \n",
       "540                      100                    ZNE  \n",
       "742                      100                    ZNE  \n",
       "757                      100                    ZNE  \n",
       "821                      100                    ZNE  \n",
       "852                      100                    ZNE  \n",
       "1062                     100                    ZNE  \n",
       "1070                     100                    ZNE  \n",
       "1130                     100                    ZNE  \n",
       "1234                     100                    ZNE  \n",
       "1633                     100                    ZNE  \n",
       "1712                     100                    ZNE  \n",
       "1747                     100                    ZNE  \n",
       "1923                     100                    ZNE  \n",
       "1946                     100                    ZNE  \n",
       "1947                     100                    ZNE  \n",
       "1974                     100                    ZNE  \n",
       "2032                     100                    ZNE  \n",
       "2055                     100                    ZNE  \n",
       "\n",
       "[20 rows x 41 columns]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Sample metadata:\")\n",
    "data.metadata.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "4564d0a6-f1ba-4da0-b5e0-cb8f498b32a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data\n",
    "train, dev, test = data.train_dev_test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "fb71ed97-53c8-4a4f-85b5-9c204f178ba4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: OKLA_1Mil_120s_Ver_3 - 7884 traces\n",
      "Dev: OKLA_1Mil_120s_Ver_3 - 1657 traces\n",
      "Test: OKLA_1Mil_120s_Ver_3 - 1729 traces\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(\"Train:\", train)\n",
    "print(\"Dev:\", dev)\n",
    "print(\"Test:\", test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "c37f5b19-d674-4b26-8c2e-bd9524b73a5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up data augmentation\n",
    "\n",
    "phase_dict = {\n",
    "    \"trace_p_arrival_sample\": \"P\",\n",
    "    \"trace_pP_arrival_sample\": \"P\",\n",
    "    \"trace_P_arrival_sample\": \"P\",\n",
    "    \"trace_P1_arrival_sample\": \"P\",\n",
    "    \"trace_Pg_arrival_sample\": \"P\",\n",
    "    \"trace_Pn_arrival_sample\": \"P\",\n",
    "    \"trace_PmP_arrival_sample\": \"P\",\n",
    "    \"trace_pwP_arrival_sample\": \"P\",\n",
    "    \"trace_pwPm_arrival_sample\": \"P\",\n",
    "    \"trace_s_arrival_sample\": \"S\",\n",
    "    \"trace_S_arrival_sample\": \"S\",\n",
    "    \"trace_S1_arrival_sample\": \"S\",\n",
    "    \"trace_Sg_arrival_sample\": \"S\",\n",
    "    \"trace_SmS_arrival_sample\": \"S\",\n",
    "    \"trace_Sn_arrival_sample\": \"S\",\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "f1428383-8e7a-46c2-9072-77b229effb97",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the data generators for training and validation\n",
    "train_generator = sbg.GenericGenerator(train)\n",
    "dev_generator = sbg.GenericGenerator(dev)\n",
    "test_generator = sbg.GenericGenerator(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "607659a4-b41f-4567-9984-e37e90c73581",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define phase lists for labeling\n",
    "p_phases = [key for key, val in phase_dict.items() if val == \"P\"]\n",
    "s_phases = [key for key, val in phase_dict.items() if val == \"S\"]\n",
    "\n",
    "train_generator = sbg.GenericGenerator(train)\n",
    "dev_generator = sbg.GenericGenerator(dev)\n",
    "test_generator = sbg.GenericGenerator(test)\n",
    "\n",
    "augmentations = [\n",
    "    sbg.WindowAroundSample(list(phase_dict.keys()), samples_before=3000, windowlen=6000, selection=\"random\", strategy=\"variable\"),\n",
    "    sbg.RandomWindow(windowlen=3001, strategy=\"pad\"),\n",
    "    sbg.Normalize(demean_axis=-1, detrend_axis=-1, amp_norm_axis=-1, amp_norm_type=\"peak\"),\n",
    "    sbg.ChangeDtype(np.float32),\n",
    "    sbg.ProbabilisticLabeller(sigma=30, dim=0),\n",
    "]\n",
    "\n",
    "train_generator.add_augmentations(augmentations)\n",
    "dev_generator.add_augmentations(augmentations)\n",
    "test_generator.add_augmentations(augmentations)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "d39e13d7-0522-46c8-877e-2015d0856708",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters Setup\n",
    "sampling_rate = config['peak_detection']['sampling_rate']\n",
    "height = config['peak_detection']['height']\n",
    "distance = config['peak_detection']['distance']\n",
    "\n",
    "# Parameter Setup\n",
    "batch_size = config['training']['batch_size']\n",
    "num_workers = config['training']['num_workers']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "aeb2b79d-5622-4091-98d3-d9ba27221680",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the data for machine learning\n",
    "\n",
    "train_loader = DataLoader(train_generator,batch_size=batch_size, shuffle=True, num_workers=num_workers, worker_init_fn=worker_seeding,pin_memory=True,prefetch_factor=4,persistent_workers=True)\n",
    "test_loader = DataLoader(test_generator, batch_size=batch_size, shuffle=False, num_workers=num_workers, worker_init_fn=worker_seeding,pin_memory=True,prefetch_factor=4,persistent_workers=True)\n",
    "val_loader = DataLoader(dev_generator, batch_size=batch_size, shuffle=False, num_workers=num_workers, worker_init_fn=worker_seeding,pin_memory=True,prefetch_factor=4,persistent_workers=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "a50c351e-dac5-4838-a8b7-fb6a47aed807",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "TRAINING CONFIGURATION SANITY CHECK\n",
      "============================================================\n",
      "\n",
      "üìä Dataset Information:\n",
      "  Total dataset size: 11,270 samples\n",
      "  Training set: 7,884 samples\n",
      "  Validation set: 1,657 samples\n",
      "  Test set: 1,729 samples\n",
      "  Sample fraction used: 1.0%\n",
      "\n",
      "üéØ Model Information:\n",
      "  Model type: PhaseNet\n",
      "  Device: cpu\n",
      "\n",
      "‚öôÔ∏è Training Hyperparameters:\n",
      "  Batch size: 64\n",
      "  Number of workers: 4\n",
      "  Learning rate: 0.01\n",
      "  Number of epochs: 50\n",
      "  Patience (early stopping): 5\n",
      "\n",
      "üìà Peak Detection Parameters:\n",
      "  Sampling rate: 100 Hz\n",
      "  Height threshold: 0.5\n",
      "  Distance: 100 samples\n",
      "\n",
      "üî¨ Phase Dictionary:\n",
      "  P-phases: 9 types\n",
      "  S-phases: 6 types\n",
      "\n",
      "============================================================\n",
      "Ready to start training!\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "print(\"=\" * 60)\n",
    "print(\"TRAINING CONFIGURATION SANITY CHECK\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "print(\"\\nüìä Dataset Information:\")\n",
    "print(f\"  Total dataset size: {len(data):,} samples\")\n",
    "print(f\"  Training set: {len(train):,} samples\")\n",
    "print(f\"  Validation set: {len(dev):,} samples\")\n",
    "print(f\"  Test set: {len(test):,} samples\")\n",
    "print(f\"  Sample fraction used: {sample_fraction*100}%\")\n",
    "\n",
    "print(\"\\nüéØ Model Information:\")\n",
    "print(f\"  Model type: {model.__class__.__name__}\")\n",
    "print(f\"  Device: {device}\")\n",
    "\n",
    "print(\"\\n‚öôÔ∏è Training Hyperparameters:\")\n",
    "print(f\"  Batch size: {batch_size}\")\n",
    "print(f\"  Number of workers: {num_workers}\")\n",
    "print(f\"  Learning rate: {config['training']['learning_rate']}\")\n",
    "print(f\"  Number of epochs: {config['training']['epochs']}\")\n",
    "print(f\"  Patience (early stopping): {config['training']['patience']}\")\n",
    "\n",
    "print(\"\\nüìà Peak Detection Parameters:\")\n",
    "print(f\"  Sampling rate: {sampling_rate} Hz\")\n",
    "print(f\"  Height threshold: {height}\")\n",
    "print(f\"  Distance: {distance} samples\")\n",
    "\n",
    "print(\"\\nüî¨ Phase Dictionary:\")\n",
    "print(f\"  P-phases: {len(p_phases)} types\")\n",
    "print(f\"  S-phases: {len(s_phases)} types\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"Ready to start training!\")\n",
    "print(\"=\" * 60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "8d3522bd-0fca-44ba-a285-8cb005f28d95",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define loss function\n",
    "def loss_fn(y_pred, y_true, eps=1e-5):\n",
    "    h = y_true * torch.log(y_pred + eps)\n",
    "    h = h.mean(-1).sum(-1)\n",
    "    h = h.mean()\n",
    "    return -h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "943d5a64-94a9-4948-8c98-f5196c175063",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úì Knowledge distillation loss function defined!\n",
      "  - Temperature: Controls softness of probability distributions\n",
      "  - Alpha: Balances learning from teacher vs ground truth\n"
     ]
    }
   ],
   "source": [
    "# Knowledge Distillation Loss Function\n",
    "def distillation_loss_fn(student_pred, teacher_pred, y_true, temperature=3.0, alpha=0.5, eps=1e-5):\n",
    "    \"\"\"\n",
    "    Combined loss for knowledge distillation.\n",
    "    \n",
    "    Args:\n",
    "        student_pred: Student model predictions (after softmax)\n",
    "        teacher_pred: Teacher model predictions (after softmax)\n",
    "        y_true: Ground truth labels\n",
    "        temperature: Temperature for softening probability distributions (higher = softer)\n",
    "        alpha: Weight between distillation loss and task loss (0-1)\n",
    "               alpha=1.0: only learn from teacher\n",
    "               alpha=0.0: only learn from ground truth\n",
    "        eps: Small epsilon for numerical stability\n",
    "    \n",
    "    Returns:\n",
    "        Combined distillation loss\n",
    "    \"\"\"\n",
    "    # Task loss: student vs ground truth (standard cross-entropy)\n",
    "    task_loss = -(y_true * torch.log(student_pred + eps)).mean(-1).sum(-1).mean()\n",
    "    \n",
    "    # Distillation loss: student vs teacher (KL divergence with temperature scaling)\n",
    "    # Apply temperature scaling to soften the distributions\n",
    "    student_log_soft = torch.log((student_pred ** (1.0/temperature)) + eps)\n",
    "    teacher_soft = teacher_pred ** (1.0/temperature)\n",
    "    \n",
    "    # Normalize after temperature scaling\n",
    "    student_log_soft = student_log_soft - torch.logsumexp(student_log_soft, dim=1, keepdim=True)\n",
    "    teacher_soft = teacher_soft / teacher_soft.sum(dim=1, keepdim=True)\n",
    "    \n",
    "    # KL divergence\n",
    "    distill_loss = -(teacher_soft * student_log_soft).mean(-1).sum(-1).mean()\n",
    "    \n",
    "    # Scale distillation loss by T^2 (common practice in knowledge distillation)\n",
    "    distill_loss = distill_loss * (temperature ** 2)\n",
    "    \n",
    "    # Combine losses\n",
    "    total_loss = alpha * distill_loss + (1 - alpha) * task_loss\n",
    "    \n",
    "    return total_loss\n",
    "\n",
    "print(\"‚úì Knowledge distillation loss function defined!\")\n",
    "print(f\"  - Temperature: Controls softness of probability distributions\")\n",
    "print(f\"  - Alpha: Balances learning from teacher vs ground truth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "6adaf15f-85a9-4dce-918c-3679df6112a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "KNOWLEDGE DISTILLATION SETUP\n",
      "============================================================\n",
      "\n",
      "üë®‚Äçüè´ Teacher Model (PhaseNet):\n",
      "  Total parameters: 268,443\n",
      "  Trainable parameters: 0 (frozen ‚úì)\n",
      "\n",
      "üë®‚Äçüéì Student Model (XiaoNet):\n",
      "  Total parameters: 164,355\n",
      "  Trainable parameters: 164,355\n",
      "\n",
      "üìä Model Comparison:\n",
      "  Parameter reduction: 38.8%\n",
      "\n",
      "============================================================\n",
      "‚úì Teacher-Student configuration complete!\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "# Configure Teacher and Student Models for Knowledge Distillation\n",
    "print(\"=\" * 60)\n",
    "print(\"KNOWLEDGE DISTILLATION SETUP\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Teacher model: PhaseNet (pretrained, frozen)\n",
    "teacher_model = model  # PhaseNet loaded earlier\n",
    "teacher_model.eval()   # Set to evaluation mode\n",
    "\n",
    "# Freeze all teacher parameters - no training\n",
    "for param in teacher_model.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "teacher_params = sum(p.numel() for p in teacher_model.parameters())\n",
    "teacher_trainable = sum(p.numel() for p in teacher_model.parameters() if p.requires_grad)\n",
    "\n",
    "print(\"\\nüë®‚Äçüè´ Teacher Model (PhaseNet):\")\n",
    "print(f\"  Total parameters: {teacher_params:,}\")\n",
    "print(f\"  Trainable parameters: {teacher_trainable:,} (frozen ‚úì)\")\n",
    "\n",
    "# Student model: XiaoNet (will be trained)\n",
    "student_model = xiao_net  # XiaoNet created earlier\n",
    "student_model.train()      # Set to training mode\n",
    "\n",
    "student_params = sum(p.numel() for p in student_model.parameters())\n",
    "student_trainable = sum(p.numel() for p in student_model.parameters() if p.requires_grad)\n",
    "\n",
    "print(\"\\nüë®‚Äçüéì Student Model (XiaoNet):\")\n",
    "print(f\"  Total parameters: {student_params:,}\")\n",
    "print(f\"  Trainable parameters: {student_trainable:,}\")\n",
    "\n",
    "print(\"\\nüìä Model Comparison:\")\n",
    "print(f\"  Parameter reduction: {(1 - student_params/teacher_params)*100:.1f}%\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"‚úì Teacher-Student configuration complete!\")\n",
    "print(\"=\" * 60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "e3c886d3-4788-42c6-a330-ccccc660814f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Learning rate and number of epochs\n",
    "learning_rate = config['training']['learning_rate']\n",
    "epochs = config['training']['epochs']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "57be3281-5e25-488d-af9a-7e1c3d2fc152",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úì Optimizer configured for student model\n",
      "  Learning rate: 0.01\n",
      "  Optimizing 164,355 parameters\n"
     ]
    }
   ],
   "source": [
    "# Setup optimizer for STUDENT model only (teacher is frozen)\n",
    "optimizer = torch.optim.Adam(student_model.parameters(), lr=learning_rate)\n",
    "\n",
    "print(f\"‚úì Optimizer configured for student model\")\n",
    "print(f\"  Learning rate: {learning_rate}\")\n",
    "print(f\"  Optimizing {student_trainable:,} parameters\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "8dcc7e97-b7c7-45fc-9d8f-e6d3a22cf2bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úì Distillation training functions defined!\n",
      "  - train_one_epoch_distillation: Trains student with teacher guidance\n",
      "  - evaluate_student_model: Evaluates student independently\n"
     ]
    }
   ],
   "source": [
    "# Training function with knowledge distillation\n",
    "def train_one_epoch_distillation(dataloader, student_model, teacher_model, optimizer, device, \n",
    "                                   temperature=4.0, alpha=0.5):\n",
    "    \"\"\"\n",
    "    Train student model for one epoch using knowledge distillation.\n",
    "    \n",
    "    Args:\n",
    "        dataloader: Training data loader\n",
    "        student_model: Student model to train\n",
    "        teacher_model: Teacher model (frozen)\n",
    "        optimizer: Optimizer for student model\n",
    "        device: Device to train on\n",
    "        temperature: Temperature for distillation\n",
    "        alpha: Weight between distillation and task loss\n",
    "    \"\"\"\n",
    "    student_model.train()\n",
    "    teacher_model.eval()  # Teacher always in eval mode\n",
    "    \n",
    "    total_loss = 0\n",
    "    task_loss_total = 0\n",
    "    distill_loss_total = 0\n",
    "    size = len(dataloader.dataset)\n",
    "\n",
    "    for batch_id, batch in enumerate(dataloader):\n",
    "        X = batch[\"X\"].to(device)\n",
    "        y_true = batch[\"y\"].to(device)\n",
    "        \n",
    "        # Get predictions from both models\n",
    "        student_pred = student_model(X)\n",
    "        \n",
    "        with torch.no_grad():  # No gradients for teacher\n",
    "            teacher_pred = teacher_model(X)\n",
    "        \n",
    "        # Calculate combined loss\n",
    "        loss = distillation_loss_fn(student_pred, teacher_pred, y_true, \n",
    "                                     temperature=temperature, alpha=alpha)\n",
    "        \n",
    "        # Also calculate individual losses for monitoring\n",
    "        eps = 1e-5\n",
    "        task_loss = -(y_true * torch.log(student_pred + eps)).mean(-1).sum(-1).mean()\n",
    "        \n",
    "        # Backward pass and optimization\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if batch_id % 5 == 0:\n",
    "            print(f\"loss: {loss.item():>7f}  [{batch_id * len(batch['X']):>5d}/{size:>5d}]\")\n",
    "\n",
    "        total_loss += loss.item()\n",
    "        task_loss_total += task_loss.item()\n",
    "\n",
    "    avg_loss = total_loss / len(dataloader)\n",
    "    avg_task_loss = task_loss_total / len(dataloader)\n",
    "    \n",
    "    return avg_loss, avg_task_loss\n",
    "\n",
    "\n",
    "# Evaluation function for student model\n",
    "def evaluate_student_model(dataloader, student_model, device):\n",
    "    \"\"\"\n",
    "    Evaluate student model on validation/test set.\n",
    "    Uses standard cross-entropy loss (no teacher involved).\n",
    "    \"\"\"\n",
    "    student_model.eval()\n",
    "    val_loss = 0\n",
    "    eps = 1e-5\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in dataloader:\n",
    "            X = batch[\"X\"].to(device)\n",
    "            y_true = batch[\"y\"].to(device)\n",
    "            \n",
    "            student_pred = student_model(X)\n",
    "            loss = -(y_true * torch.log(student_pred + eps)).mean(-1).sum(-1).mean()\n",
    "            val_loss += loss.item()\n",
    "\n",
    "    return val_loss / len(dataloader)\n",
    "\n",
    "\n",
    "print(\"‚úì Distillation training functions defined!\")\n",
    "print(\"  - train_one_epoch_distillation: Trains student with teacher guidance\")\n",
    "print(\"  - evaluate_student_model: Evaluates student independently\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "e4f1a573-7aba-411a-afe1-594653a2b305",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to plot training history\n",
    "def plot_training_history(history):\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.plot(history['train_loss'], label='Training Loss')\n",
    "    plt.plot(history['val_loss'], label='Validation Loss')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.title('Training and Validation Loss Over Time')\n",
    "    plt.legend()\n",
    "    plt.grid(True, linestyle='--', alpha=0.6)\n",
    "    plt.fill_between(range(len(history['train_loss'])), \n",
    "                     history['train_loss'], history['val_loss'],\n",
    "                     alpha=0.3, color='red', \n",
    "                     where=(np.array(history['val_loss']) > np.array(history['train_loss'])),\n",
    "                     label='Potential Overfitting Gap')\n",
    "    plt.savefig('training_history.png')\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "5f73bd36-e7ee-4836-bd1a-4db6bc7c27bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# EarlyStopping class\n",
    "class EarlyStopping:\n",
    "    def __init__(self, patience=7, verbose=False, delta=0, checkpoint_path='checkpoint.pt', \n",
    "                 best_model_path='best_model.pth', final_model_path='final_model.pth'):\n",
    "        self.patience = patience\n",
    "        self.verbose = verbose\n",
    "        self.counter = 0\n",
    "        self.best_score = None\n",
    "        self.early_stop = False\n",
    "        self.val_loss_min = float('inf')\n",
    "        self.delta = delta\n",
    "        self.checkpoint_path = checkpoint_path\n",
    "        self.best_model_path = best_model_path\n",
    "        self.final_model_path = final_model_path\n",
    "\n",
    "    def __call__(self, val_loss, model):\n",
    "        score = -val_loss\n",
    "        if self.best_score is None:\n",
    "            self.best_score = score\n",
    "            self.save_checkpoint(val_loss, model)\n",
    "            self.save_best_model(model)\n",
    "        elif score < self.best_score + self.delta:\n",
    "            self.counter += 1\n",
    "            if self.verbose:\n",
    "                print(f'EarlyStopping counter: {self.counter} out of {self.patience}')\n",
    "            if self.counter >= self.patience:\n",
    "                self.early_stop = True\n",
    "                self.save_final_model(model)\n",
    "        else:\n",
    "            self.best_score = score\n",
    "            self.save_checkpoint(val_loss, model)\n",
    "            self.save_best_model(model)\n",
    "            self.counter = 0\n",
    "\n",
    "    def save_checkpoint(self, val_loss, model):\n",
    "        if self.verbose:\n",
    "            print(f'Validation loss decreased ({self.val_loss_min:.6f} --> {val_loss:.6f}). Saving model...')\n",
    "        torch.save(model.state_dict(), self.checkpoint_path)\n",
    "        self.val_loss_min = val_loss\n",
    "\n",
    "    def save_best_model(self, model):\n",
    "        if self.verbose:\n",
    "            print(f'Saving best model to {self.best_model_path}')\n",
    "        torch.save(model.state_dict(), self.best_model_path)\n",
    "\n",
    "    def save_final_model(self, model):\n",
    "        if self.verbose:\n",
    "            print(f'Early stopping triggered. Saving final model to {self.final_model_path}')\n",
    "        torch.save(model.state_dict(), self.final_model_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "74ebcc61-d29a-4840-ac91-33502e18a19c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training routine with EarlyStopping and scheduler for Knowledge Distillation\n",
    "def train_model_distillation(train_loader, val_loader, student_model, teacher_model, optimizer, device, \n",
    "                              num_epochs=25, patience=7, temperature=3.0, alpha=0.5):\n",
    "    \"\"\"\n",
    "    Train student model using knowledge distillation with EarlyStopping and scheduler.\n",
    "    \n",
    "    Args:\n",
    "        train_loader: Training data loader\n",
    "        val_loader: Validation data loader\n",
    "        student_model: Student model to train\n",
    "        teacher_model: Teacher model (frozen)\n",
    "        optimizer: Optimizer for student model\n",
    "        device: Device to train on\n",
    "        num_epochs: Maximum number of epochs\n",
    "        patience: EarlyStopping patience\n",
    "        temperature: Temperature for softening probability distributions\n",
    "        alpha: Weight between distillation and task loss\n",
    "    \"\"\"\n",
    "    early_stopping = EarlyStopping(patience=patience, verbose=True)\n",
    "    scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.5, patience=3, verbose=True)\n",
    "\n",
    "    history = {\n",
    "        'train_loss': [],\n",
    "        'val_loss': []\n",
    "    }\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        print(f\"\\nEpoch {epoch+1}/{num_epochs}\")\n",
    "        print(\"=\" * 60)\n",
    "        \n",
    "        # Training phase (distillation)\n",
    "        train_loss, task_loss = train_one_epoch_distillation(\n",
    "            train_loader, student_model, teacher_model, optimizer, device, \n",
    "            temperature=temperature, alpha=alpha\n",
    "        )\n",
    "        \n",
    "        # Validation phase (student only)\n",
    "        val_loss = evaluate_student_model(val_loader, student_model, device)\n",
    "\n",
    "        history['train_loss'].append(train_loss)\n",
    "        history['val_loss'].append(val_loss)\n",
    "\n",
    "        print(f\"\\nEpoch {epoch+1} Summary:\")\n",
    "        print(f\"  Train Loss: {train_loss:.6f}\")\n",
    "        print(f\"  Train Task Loss: {task_loss:.6f}\")\n",
    "        print(f\"  Val Loss: {val_loss:.6f}\")\n",
    "\n",
    "        scheduler.step(val_loss)\n",
    "        early_stopping(val_loss, student_model)\n",
    "        if early_stopping.early_stop:\n",
    "            print(\"\\n\" + \"=\" * 60)\n",
    "            print(\"‚úì Early stopping triggered!\")\n",
    "            break\n",
    "\n",
    "    # Load best model\n",
    "    student_model.load_state_dict(torch.load('checkpoint.pt'))\n",
    "    plot_training_history(history)\n",
    "    return student_model, history\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "00c5e953-b2c3-4f68-af50-fae15226ff47",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1/50\n",
      "============================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/ML/lib/python3.12/site-packages/torch/optim/lr_scheduler.py:28: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
      "  warnings.warn(\"The verbose parameter is deprecated. Please use get_last_lr() \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 5.450241  [    0/ 7884]\n",
      "loss: 4.238523  [  320/ 7884]\n",
      "loss: 3.479710  [  640/ 7884]\n",
      "loss: 2.860467  [  960/ 7884]\n",
      "loss: 2.327947  [ 1280/ 7884]\n",
      "loss: 1.901031  [ 1600/ 7884]\n",
      "loss: 1.574341  [ 1920/ 7884]\n",
      "loss: 1.383005  [ 2240/ 7884]\n",
      "loss: 1.209440  [ 2560/ 7884]\n",
      "loss: 1.202302  [ 2880/ 7884]\n",
      "loss: 1.279881  [ 3200/ 7884]\n",
      "loss: 1.224012  [ 3520/ 7884]\n",
      "loss: 1.233135  [ 3840/ 7884]\n",
      "loss: 1.255525  [ 4160/ 7884]\n",
      "loss: 1.200552  [ 4480/ 7884]\n",
      "loss: 1.182448  [ 4800/ 7884]\n",
      "loss: 1.162006  [ 5120/ 7884]\n",
      "loss: 1.176758  [ 5440/ 7884]\n",
      "loss: 1.240571  [ 5760/ 7884]\n",
      "loss: 1.176712  [ 6080/ 7884]\n",
      "loss: 1.144414  [ 6400/ 7884]\n",
      "loss: 1.154231  [ 6720/ 7884]\n",
      "loss: 1.165914  [ 7040/ 7884]\n",
      "loss: 1.093527  [ 7360/ 7884]\n",
      "loss: 1.095314  [ 7680/ 7884]\n",
      "\n",
      "Epoch 1 Summary:\n",
      "  Train Loss: 1.658667\n",
      "  Train Task Loss: 0.340586\n",
      "  Val Loss: 0.225564\n",
      "Validation loss decreased (inf --> 0.225564). Saving model...\n",
      "Saving best model to best_model.pth\n",
      "\n",
      "Epoch 2/50\n",
      "============================================================\n",
      "loss: 1.127357  [    0/ 7884]\n",
      "loss: 1.100446  [  320/ 7884]\n",
      "loss: 1.109154  [  640/ 7884]\n",
      "loss: 1.137520  [  960/ 7884]\n",
      "loss: 1.039838  [ 1280/ 7884]\n",
      "loss: 1.118643  [ 1600/ 7884]\n",
      "loss: 1.096809  [ 1920/ 7884]\n",
      "loss: 1.074522  [ 2240/ 7884]\n",
      "loss: 1.109683  [ 2560/ 7884]\n",
      "loss: 1.059497  [ 2880/ 7884]\n",
      "loss: 1.037173  [ 3200/ 7884]\n",
      "loss: 1.087803  [ 3520/ 7884]\n",
      "loss: 1.043596  [ 3840/ 7884]\n",
      "loss: 1.085104  [ 4160/ 7884]\n",
      "loss: 1.082806  [ 4480/ 7884]\n",
      "loss: 1.002801  [ 4800/ 7884]\n",
      "loss: 0.988316  [ 5120/ 7884]\n",
      "loss: 1.046992  [ 5440/ 7884]\n",
      "loss: 1.057264  [ 5760/ 7884]\n",
      "loss: 1.098351  [ 6080/ 7884]\n",
      "loss: 0.993757  [ 6400/ 7884]\n",
      "loss: 1.138522  [ 6720/ 7884]\n",
      "loss: 1.066170  [ 7040/ 7884]\n",
      "loss: 1.000082  [ 7360/ 7884]\n",
      "loss: 1.041610  [ 7680/ 7884]\n",
      "\n",
      "Epoch 2 Summary:\n",
      "  Train Loss: 1.060121\n",
      "  Train Task Loss: 0.260822\n",
      "  Val Loss: 0.256808\n",
      "EarlyStopping counter: 1 out of 5\n",
      "\n",
      "Epoch 3/50\n",
      "============================================================\n",
      "loss: 0.991675  [    0/ 7884]\n",
      "loss: 1.010654  [  320/ 7884]\n",
      "loss: 1.038226  [  640/ 7884]\n",
      "loss: 1.036573  [  960/ 7884]\n",
      "loss: 0.915376  [ 1280/ 7884]\n",
      "loss: 1.015781  [ 1600/ 7884]\n",
      "loss: 1.054450  [ 1920/ 7884]\n",
      "loss: 0.994763  [ 2240/ 7884]\n",
      "loss: 1.112437  [ 2560/ 7884]\n",
      "loss: 1.086557  [ 2880/ 7884]\n",
      "loss: 0.988559  [ 3200/ 7884]\n",
      "loss: 1.002594  [ 3520/ 7884]\n",
      "loss: 0.973144  [ 3840/ 7884]\n",
      "loss: 1.027115  [ 4160/ 7884]\n",
      "loss: 1.071800  [ 4480/ 7884]\n",
      "loss: 0.959774  [ 4800/ 7884]\n",
      "loss: 1.008554  [ 5120/ 7884]\n",
      "loss: 1.047028  [ 5440/ 7884]\n",
      "loss: 1.041085  [ 5760/ 7884]\n",
      "loss: 1.031809  [ 6080/ 7884]\n",
      "loss: 1.143483  [ 6400/ 7884]\n",
      "loss: 1.017016  [ 6720/ 7884]\n",
      "loss: 1.075286  [ 7040/ 7884]\n",
      "loss: 0.958806  [ 7360/ 7884]\n",
      "loss: 1.002824  [ 7680/ 7884]\n",
      "\n",
      "Epoch 3 Summary:\n",
      "  Train Loss: 1.023898\n",
      "  Train Task Loss: 0.237156\n",
      "  Val Loss: 0.228542\n",
      "EarlyStopping counter: 2 out of 5\n",
      "\n",
      "Epoch 4/50\n",
      "============================================================\n",
      "loss: 0.967303  [    0/ 7884]\n",
      "loss: 1.065326  [  320/ 7884]\n",
      "loss: 1.045365  [  640/ 7884]\n",
      "loss: 1.015520  [  960/ 7884]\n",
      "loss: 1.091958  [ 1280/ 7884]\n",
      "loss: 1.079333  [ 1600/ 7884]\n",
      "loss: 1.024108  [ 1920/ 7884]\n",
      "loss: 1.056277  [ 2240/ 7884]\n",
      "loss: 1.000883  [ 2560/ 7884]\n",
      "loss: 1.028849  [ 2880/ 7884]\n",
      "loss: 0.975341  [ 3200/ 7884]\n",
      "loss: 1.047141  [ 3520/ 7884]\n",
      "loss: 0.952915  [ 3840/ 7884]\n",
      "loss: 1.012752  [ 4160/ 7884]\n",
      "loss: 0.970362  [ 4480/ 7884]\n",
      "loss: 1.055480  [ 4800/ 7884]\n",
      "loss: 1.011586  [ 5120/ 7884]\n",
      "loss: 1.023360  [ 5440/ 7884]\n",
      "loss: 0.942844  [ 5760/ 7884]\n",
      "loss: 0.969247  [ 6080/ 7884]\n",
      "loss: 0.990427  [ 6400/ 7884]\n",
      "loss: 1.042165  [ 6720/ 7884]\n",
      "loss: 0.971235  [ 7040/ 7884]\n",
      "loss: 1.024635  [ 7360/ 7884]\n",
      "loss: 1.047009  [ 7680/ 7884]\n",
      "\n",
      "Epoch 4 Summary:\n",
      "  Train Loss: 1.011631\n",
      "  Train Task Loss: 0.228339\n",
      "  Val Loss: 0.229375\n",
      "EarlyStopping counter: 3 out of 5\n",
      "\n",
      "Epoch 5/50\n",
      "============================================================\n",
      "loss: 1.059197  [    0/ 7884]\n",
      "loss: 0.990675  [  320/ 7884]\n",
      "loss: 0.977822  [  640/ 7884]\n",
      "loss: 1.039512  [  960/ 7884]\n",
      "loss: 0.958183  [ 1280/ 7884]\n",
      "loss: 0.946225  [ 1600/ 7884]\n",
      "loss: 0.971052  [ 1920/ 7884]\n",
      "loss: 1.070150  [ 2240/ 7884]\n",
      "loss: 0.981594  [ 2560/ 7884]\n",
      "loss: 1.012960  [ 2880/ 7884]\n",
      "loss: 1.021132  [ 3200/ 7884]\n",
      "loss: 1.079146  [ 3520/ 7884]\n",
      "loss: 1.059103  [ 3840/ 7884]\n",
      "loss: 1.044963  [ 4160/ 7884]\n",
      "loss: 0.996782  [ 4480/ 7884]\n",
      "loss: 1.052002  [ 4800/ 7884]\n",
      "loss: 0.957160  [ 5120/ 7884]\n",
      "loss: 0.963358  [ 5440/ 7884]\n",
      "loss: 0.994379  [ 5760/ 7884]\n",
      "loss: 0.895853  [ 6080/ 7884]\n",
      "loss: 1.052665  [ 6400/ 7884]\n",
      "loss: 0.931467  [ 6720/ 7884]\n",
      "loss: 0.991664  [ 7040/ 7884]\n",
      "loss: 1.012145  [ 7360/ 7884]\n",
      "loss: 0.965357  [ 7680/ 7884]\n",
      "\n",
      "Epoch 5 Summary:\n",
      "  Train Loss: 1.000787\n",
      "  Train Task Loss: 0.220682\n",
      "  Val Loss: 0.230049\n",
      "EarlyStopping counter: 4 out of 5\n",
      "\n",
      "Epoch 6/50\n",
      "============================================================\n",
      "loss: 1.020152  [    0/ 7884]\n",
      "loss: 0.970656  [  320/ 7884]\n",
      "loss: 0.982112  [  640/ 7884]\n",
      "loss: 0.955455  [  960/ 7884]\n",
      "loss: 1.039124  [ 1280/ 7884]\n",
      "loss: 0.958726  [ 1600/ 7884]\n",
      "loss: 0.993415  [ 1920/ 7884]\n",
      "loss: 1.010111  [ 2240/ 7884]\n",
      "loss: 0.995167  [ 2560/ 7884]\n",
      "loss: 1.048463  [ 2880/ 7884]\n",
      "loss: 1.010464  [ 3200/ 7884]\n",
      "loss: 1.025715  [ 3520/ 7884]\n",
      "loss: 0.966445  [ 3840/ 7884]\n",
      "loss: 1.014870  [ 4160/ 7884]\n",
      "loss: 0.958450  [ 4480/ 7884]\n",
      "loss: 1.005745  [ 4800/ 7884]\n",
      "loss: 1.014857  [ 5120/ 7884]\n",
      "loss: 0.933979  [ 5440/ 7884]\n",
      "loss: 1.083881  [ 5760/ 7884]\n",
      "loss: 0.943571  [ 6080/ 7884]\n",
      "loss: 0.987039  [ 6400/ 7884]\n",
      "loss: 0.991834  [ 6720/ 7884]\n",
      "loss: 0.941113  [ 7040/ 7884]\n",
      "loss: 0.991524  [ 7360/ 7884]\n",
      "loss: 0.930190  [ 7680/ 7884]\n",
      "\n",
      "Epoch 6 Summary:\n",
      "  Train Loss: 0.990613\n",
      "  Train Task Loss: 0.211145\n",
      "  Val Loss: 0.199618\n",
      "Validation loss decreased (0.225564 --> 0.199618). Saving model...\n",
      "Saving best model to best_model.pth\n",
      "\n",
      "Epoch 7/50\n",
      "============================================================\n",
      "loss: 1.004548  [    0/ 7884]\n",
      "loss: 0.968106  [  320/ 7884]\n",
      "loss: 0.955044  [  640/ 7884]\n",
      "loss: 0.994959  [  960/ 7884]\n",
      "loss: 0.977492  [ 1280/ 7884]\n",
      "loss: 0.958823  [ 1600/ 7884]\n",
      "loss: 1.014297  [ 1920/ 7884]\n",
      "loss: 0.914431  [ 2240/ 7884]\n",
      "loss: 0.944524  [ 2560/ 7884]\n",
      "loss: 0.901726  [ 2880/ 7884]\n",
      "loss: 0.986621  [ 3200/ 7884]\n",
      "loss: 0.936106  [ 3520/ 7884]\n",
      "loss: 0.879793  [ 3840/ 7884]\n",
      "loss: 0.966197  [ 4160/ 7884]\n",
      "loss: 0.994737  [ 4480/ 7884]\n",
      "loss: 1.043008  [ 4800/ 7884]\n",
      "loss: 1.038503  [ 5120/ 7884]\n",
      "loss: 0.958924  [ 5440/ 7884]\n",
      "loss: 0.927326  [ 5760/ 7884]\n",
      "loss: 0.946860  [ 6080/ 7884]\n",
      "loss: 0.937842  [ 6400/ 7884]\n",
      "loss: 0.996897  [ 6720/ 7884]\n",
      "loss: 0.985077  [ 7040/ 7884]\n",
      "loss: 1.040633  [ 7360/ 7884]\n",
      "loss: 0.935333  [ 7680/ 7884]\n",
      "\n",
      "Epoch 7 Summary:\n",
      "  Train Loss: 0.983108\n",
      "  Train Task Loss: 0.207701\n",
      "  Val Loss: 0.194586\n",
      "Validation loss decreased (0.199618 --> 0.194586). Saving model...\n",
      "Saving best model to best_model.pth\n",
      "\n",
      "Epoch 8/50\n",
      "============================================================\n",
      "loss: 1.006487  [    0/ 7884]\n",
      "loss: 0.987869  [  320/ 7884]\n",
      "loss: 0.975092  [  640/ 7884]\n",
      "loss: 0.967941  [  960/ 7884]\n",
      "loss: 1.073191  [ 1280/ 7884]\n",
      "loss: 0.963348  [ 1600/ 7884]\n",
      "loss: 0.970044  [ 1920/ 7884]\n",
      "loss: 1.083233  [ 2240/ 7884]\n",
      "loss: 0.945249  [ 2560/ 7884]\n",
      "loss: 1.021846  [ 2880/ 7884]\n",
      "loss: 0.952332  [ 3200/ 7884]\n",
      "loss: 0.946697  [ 3520/ 7884]\n",
      "loss: 0.985992  [ 3840/ 7884]\n",
      "loss: 0.986675  [ 4160/ 7884]\n",
      "loss: 1.023638  [ 4480/ 7884]\n",
      "loss: 0.942154  [ 4800/ 7884]\n",
      "loss: 0.975957  [ 5120/ 7884]\n",
      "loss: 0.971551  [ 5440/ 7884]\n",
      "loss: 0.921965  [ 5760/ 7884]\n",
      "loss: 1.036512  [ 6080/ 7884]\n",
      "loss: 0.875480  [ 6400/ 7884]\n",
      "loss: 1.100253  [ 6720/ 7884]\n",
      "loss: 0.945431  [ 7040/ 7884]\n",
      "loss: 1.015528  [ 7360/ 7884]\n",
      "loss: 0.974078  [ 7680/ 7884]\n",
      "\n",
      "Epoch 8 Summary:\n",
      "  Train Loss: 0.980984\n",
      "  Train Task Loss: 0.203585\n",
      "  Val Loss: 0.198371\n",
      "EarlyStopping counter: 1 out of 5\n",
      "\n",
      "Epoch 9/50\n",
      "============================================================\n",
      "loss: 1.013849  [    0/ 7884]\n",
      "loss: 0.948234  [  320/ 7884]\n",
      "loss: 0.942276  [  640/ 7884]\n",
      "loss: 0.910888  [  960/ 7884]\n",
      "loss: 0.975029  [ 1280/ 7884]\n",
      "loss: 1.029672  [ 1600/ 7884]\n",
      "loss: 1.006030  [ 1920/ 7884]\n",
      "loss: 0.951940  [ 2240/ 7884]\n",
      "loss: 0.927046  [ 2560/ 7884]\n",
      "loss: 0.933561  [ 2880/ 7884]\n",
      "loss: 0.931476  [ 3200/ 7884]\n",
      "loss: 1.006378  [ 3520/ 7884]\n",
      "loss: 0.997326  [ 3840/ 7884]\n",
      "loss: 0.980341  [ 4160/ 7884]\n",
      "loss: 0.981583  [ 4480/ 7884]\n",
      "loss: 1.005411  [ 4800/ 7884]\n",
      "loss: 0.971700  [ 5120/ 7884]\n",
      "loss: 0.966252  [ 5440/ 7884]\n",
      "loss: 1.005792  [ 5760/ 7884]\n",
      "loss: 1.032406  [ 6080/ 7884]\n",
      "loss: 0.939130  [ 6400/ 7884]\n",
      "loss: 0.945946  [ 6720/ 7884]\n",
      "loss: 1.004849  [ 7040/ 7884]\n",
      "loss: 0.987748  [ 7360/ 7884]\n",
      "loss: 0.929812  [ 7680/ 7884]\n",
      "\n",
      "Epoch 9 Summary:\n",
      "  Train Loss: 0.980037\n",
      "  Train Task Loss: 0.199225\n",
      "  Val Loss: 0.189529\n",
      "Validation loss decreased (0.194586 --> 0.189529). Saving model...\n",
      "Saving best model to best_model.pth\n",
      "\n",
      "Epoch 10/50\n",
      "============================================================\n",
      "loss: 0.938696  [    0/ 7884]\n",
      "loss: 1.072975  [  320/ 7884]\n",
      "loss: 0.829733  [  640/ 7884]\n",
      "loss: 1.020247  [  960/ 7884]\n",
      "loss: 0.952588  [ 1280/ 7884]\n",
      "loss: 0.910065  [ 1600/ 7884]\n",
      "loss: 0.965845  [ 1920/ 7884]\n",
      "loss: 0.966570  [ 2240/ 7884]\n",
      "loss: 0.958703  [ 2560/ 7884]\n",
      "loss: 1.023628  [ 2880/ 7884]\n",
      "loss: 0.940981  [ 3200/ 7884]\n",
      "loss: 0.907006  [ 3520/ 7884]\n",
      "loss: 1.040708  [ 3840/ 7884]\n",
      "loss: 0.921805  [ 4160/ 7884]\n",
      "loss: 0.984096  [ 4480/ 7884]\n",
      "loss: 0.961761  [ 4800/ 7884]\n",
      "loss: 1.023478  [ 5120/ 7884]\n",
      "loss: 0.969394  [ 5440/ 7884]\n",
      "loss: 0.993365  [ 5760/ 7884]\n",
      "loss: 1.012530  [ 6080/ 7884]\n",
      "loss: 1.043091  [ 6400/ 7884]\n",
      "loss: 0.948972  [ 6720/ 7884]\n",
      "loss: 0.903450  [ 7040/ 7884]\n",
      "loss: 0.956427  [ 7360/ 7884]\n",
      "loss: 0.994499  [ 7680/ 7884]\n",
      "\n",
      "Epoch 10 Summary:\n",
      "  Train Loss: 0.977340\n",
      "  Train Task Loss: 0.199177\n",
      "  Val Loss: 0.192307\n",
      "EarlyStopping counter: 1 out of 5\n",
      "\n",
      "Epoch 11/50\n",
      "============================================================\n",
      "loss: 0.973191  [    0/ 7884]\n",
      "loss: 0.959006  [  320/ 7884]\n",
      "loss: 0.941185  [  640/ 7884]\n",
      "loss: 0.960972  [  960/ 7884]\n",
      "loss: 0.969250  [ 1280/ 7884]\n",
      "loss: 1.009993  [ 1600/ 7884]\n",
      "loss: 1.051540  [ 1920/ 7884]\n",
      "loss: 0.964180  [ 2240/ 7884]\n",
      "loss: 0.937255  [ 2560/ 7884]\n",
      "loss: 1.016135  [ 2880/ 7884]\n",
      "loss: 1.011550  [ 3200/ 7884]\n",
      "loss: 0.978169  [ 3520/ 7884]\n",
      "loss: 1.063939  [ 3840/ 7884]\n",
      "loss: 0.987645  [ 4160/ 7884]\n",
      "loss: 0.941133  [ 4480/ 7884]\n",
      "loss: 0.958966  [ 4800/ 7884]\n",
      "loss: 1.000841  [ 5120/ 7884]\n",
      "loss: 0.965145  [ 5440/ 7884]\n",
      "loss: 0.943565  [ 5760/ 7884]\n",
      "loss: 0.966981  [ 6080/ 7884]\n",
      "loss: 1.037620  [ 6400/ 7884]\n",
      "loss: 0.982904  [ 6720/ 7884]\n",
      "loss: 0.952527  [ 7040/ 7884]\n",
      "loss: 1.001388  [ 7360/ 7884]\n",
      "loss: 1.007571  [ 7680/ 7884]\n",
      "\n",
      "Epoch 11 Summary:\n",
      "  Train Loss: 0.976905\n",
      "  Train Task Loss: 0.198021\n",
      "  Val Loss: 0.195970\n",
      "EarlyStopping counter: 2 out of 5\n",
      "\n",
      "Epoch 12/50\n",
      "============================================================\n",
      "loss: 0.989545  [    0/ 7884]\n",
      "loss: 0.929361  [  320/ 7884]\n",
      "loss: 1.010229  [  640/ 7884]\n",
      "loss: 0.960337  [  960/ 7884]\n",
      "loss: 0.923305  [ 1280/ 7884]\n",
      "loss: 0.948212  [ 1600/ 7884]\n",
      "loss: 1.005340  [ 1920/ 7884]\n",
      "loss: 0.983389  [ 2240/ 7884]\n",
      "loss: 0.978348  [ 2560/ 7884]\n",
      "loss: 1.033683  [ 2880/ 7884]\n",
      "loss: 0.989383  [ 3200/ 7884]\n",
      "loss: 0.926304  [ 3520/ 7884]\n",
      "loss: 0.974009  [ 3840/ 7884]\n",
      "loss: 1.044925  [ 4160/ 7884]\n",
      "loss: 0.963889  [ 4480/ 7884]\n",
      "loss: 0.943566  [ 4800/ 7884]\n",
      "loss: 1.039886  [ 5120/ 7884]\n",
      "loss: 0.989770  [ 5440/ 7884]\n",
      "loss: 1.011569  [ 5760/ 7884]\n",
      "loss: 1.001598  [ 6080/ 7884]\n",
      "loss: 0.995114  [ 6400/ 7884]\n",
      "loss: 1.007186  [ 6720/ 7884]\n",
      "loss: 0.985753  [ 7040/ 7884]\n",
      "loss: 1.014787  [ 7360/ 7884]\n",
      "loss: 1.050223  [ 7680/ 7884]\n",
      "\n",
      "Epoch 12 Summary:\n",
      "  Train Loss: 0.978172\n",
      "  Train Task Loss: 0.196231\n",
      "  Val Loss: 0.193049\n",
      "EarlyStopping counter: 3 out of 5\n",
      "\n",
      "Epoch 13/50\n",
      "============================================================\n",
      "loss: 0.983441  [    0/ 7884]\n",
      "loss: 1.026425  [  320/ 7884]\n",
      "loss: 0.972614  [  640/ 7884]\n",
      "loss: 1.084761  [  960/ 7884]\n",
      "loss: 1.000110  [ 1280/ 7884]\n",
      "loss: 0.982020  [ 1600/ 7884]\n",
      "loss: 0.970560  [ 1920/ 7884]\n",
      "loss: 0.991496  [ 2240/ 7884]\n",
      "loss: 0.987449  [ 2560/ 7884]\n",
      "loss: 1.017653  [ 2880/ 7884]\n",
      "loss: 1.005370  [ 3200/ 7884]\n",
      "loss: 1.042249  [ 3520/ 7884]\n",
      "loss: 0.943270  [ 3840/ 7884]\n",
      "loss: 0.966684  [ 4160/ 7884]\n",
      "loss: 1.075675  [ 4480/ 7884]\n",
      "loss: 1.011293  [ 4800/ 7884]\n",
      "loss: 0.932079  [ 5120/ 7884]\n",
      "loss: 0.941610  [ 5440/ 7884]\n",
      "loss: 1.046590  [ 5760/ 7884]\n",
      "loss: 1.026987  [ 6080/ 7884]\n",
      "loss: 0.917828  [ 6400/ 7884]\n",
      "loss: 1.000306  [ 6720/ 7884]\n",
      "loss: 0.955354  [ 7040/ 7884]\n",
      "loss: 0.961523  [ 7360/ 7884]\n",
      "loss: 0.993226  [ 7680/ 7884]\n",
      "\n",
      "Epoch 13 Summary:\n",
      "  Train Loss: 0.977539\n",
      "  Train Task Loss: 0.195967\n",
      "  Val Loss: 0.189160\n",
      "Validation loss decreased (0.189529 --> 0.189160). Saving model...\n",
      "Saving best model to best_model.pth\n",
      "\n",
      "Epoch 14/50\n",
      "============================================================\n",
      "loss: 1.045310  [    0/ 7884]\n",
      "loss: 0.975964  [  320/ 7884]\n",
      "loss: 0.916109  [  640/ 7884]\n",
      "loss: 1.014738  [  960/ 7884]\n",
      "loss: 0.969593  [ 1280/ 7884]\n",
      "loss: 0.935472  [ 1600/ 7884]\n",
      "loss: 1.041504  [ 1920/ 7884]\n",
      "loss: 0.934445  [ 2240/ 7884]\n",
      "loss: 0.960381  [ 2560/ 7884]\n",
      "loss: 1.038872  [ 2880/ 7884]\n",
      "loss: 0.986454  [ 3200/ 7884]\n",
      "loss: 0.939270  [ 3520/ 7884]\n",
      "loss: 0.922312  [ 3840/ 7884]\n",
      "loss: 1.018548  [ 4160/ 7884]\n",
      "loss: 0.986756  [ 4480/ 7884]\n",
      "loss: 1.020281  [ 4800/ 7884]\n",
      "loss: 1.002708  [ 5120/ 7884]\n",
      "loss: 0.957079  [ 5440/ 7884]\n",
      "loss: 0.972221  [ 5760/ 7884]\n",
      "loss: 1.081602  [ 6080/ 7884]\n",
      "loss: 0.981362  [ 6400/ 7884]\n",
      "loss: 1.049000  [ 6720/ 7884]\n",
      "loss: 0.965016  [ 7040/ 7884]\n",
      "loss: 1.005856  [ 7360/ 7884]\n",
      "loss: 0.996334  [ 7680/ 7884]\n",
      "\n",
      "Epoch 14 Summary:\n",
      "  Train Loss: 0.979058\n",
      "  Train Task Loss: 0.195723\n",
      "  Val Loss: 0.196993\n",
      "EarlyStopping counter: 1 out of 5\n",
      "\n",
      "Epoch 15/50\n",
      "============================================================\n",
      "loss: 1.000670  [    0/ 7884]\n",
      "loss: 1.004712  [  320/ 7884]\n",
      "loss: 0.922493  [  640/ 7884]\n",
      "loss: 1.013483  [  960/ 7884]\n",
      "loss: 0.898937  [ 1280/ 7884]\n",
      "loss: 0.998553  [ 1600/ 7884]\n",
      "loss: 1.010228  [ 1920/ 7884]\n",
      "loss: 0.992887  [ 2240/ 7884]\n",
      "loss: 0.923109  [ 2560/ 7884]\n",
      "loss: 0.949047  [ 2880/ 7884]\n",
      "loss: 1.007090  [ 3200/ 7884]\n",
      "loss: 1.008471  [ 3520/ 7884]\n",
      "loss: 1.025654  [ 3840/ 7884]\n",
      "loss: 0.978287  [ 4160/ 7884]\n",
      "loss: 1.055502  [ 4480/ 7884]\n",
      "loss: 1.000069  [ 4800/ 7884]\n",
      "loss: 0.871490  [ 5120/ 7884]\n",
      "loss: 1.001616  [ 5440/ 7884]\n",
      "loss: 0.957154  [ 5760/ 7884]\n",
      "loss: 1.020064  [ 6080/ 7884]\n",
      "loss: 0.966954  [ 6400/ 7884]\n",
      "loss: 0.948146  [ 6720/ 7884]\n",
      "loss: 0.993171  [ 7040/ 7884]\n",
      "loss: 0.927327  [ 7360/ 7884]\n",
      "loss: 0.953161  [ 7680/ 7884]\n",
      "\n",
      "Epoch 15 Summary:\n",
      "  Train Loss: 0.974521\n",
      "  Train Task Loss: 0.193629\n",
      "  Val Loss: 0.190903\n",
      "EarlyStopping counter: 2 out of 5\n",
      "\n",
      "Epoch 16/50\n",
      "============================================================\n",
      "loss: 0.949318  [    0/ 7884]\n",
      "loss: 1.030358  [  320/ 7884]\n",
      "loss: 1.006047  [  640/ 7884]\n",
      "loss: 1.006714  [  960/ 7884]\n",
      "loss: 1.024995  [ 1280/ 7884]\n",
      "loss: 1.009997  [ 1600/ 7884]\n",
      "loss: 0.921010  [ 1920/ 7884]\n",
      "loss: 0.945534  [ 2240/ 7884]\n",
      "loss: 1.010063  [ 2560/ 7884]\n",
      "loss: 0.916879  [ 2880/ 7884]\n",
      "loss: 0.945601  [ 3200/ 7884]\n",
      "loss: 0.932295  [ 3520/ 7884]\n",
      "loss: 0.916089  [ 3840/ 7884]\n",
      "loss: 0.984740  [ 4160/ 7884]\n",
      "loss: 1.008151  [ 4480/ 7884]\n",
      "loss: 0.955555  [ 4800/ 7884]\n",
      "loss: 0.955003  [ 5120/ 7884]\n",
      "loss: 1.005734  [ 5440/ 7884]\n",
      "loss: 0.857799  [ 5760/ 7884]\n",
      "loss: 0.931998  [ 6080/ 7884]\n",
      "loss: 0.975312  [ 6400/ 7884]\n",
      "loss: 0.932120  [ 6720/ 7884]\n",
      "loss: 1.034554  [ 7040/ 7884]\n",
      "loss: 0.927629  [ 7360/ 7884]\n",
      "loss: 0.971218  [ 7680/ 7884]\n",
      "\n",
      "Epoch 16 Summary:\n",
      "  Train Loss: 0.970243\n",
      "  Train Task Loss: 0.193246\n",
      "  Val Loss: 0.193707\n",
      "EarlyStopping counter: 3 out of 5\n",
      "\n",
      "Epoch 17/50\n",
      "============================================================\n",
      "loss: 0.937705  [    0/ 7884]\n",
      "loss: 0.907056  [  320/ 7884]\n",
      "loss: 0.943810  [  640/ 7884]\n",
      "loss: 0.909322  [  960/ 7884]\n",
      "loss: 0.924486  [ 1280/ 7884]\n",
      "loss: 0.937329  [ 1600/ 7884]\n",
      "loss: 1.033272  [ 1920/ 7884]\n",
      "loss: 0.984134  [ 2240/ 7884]\n",
      "loss: 1.016493  [ 2560/ 7884]\n",
      "loss: 0.961305  [ 2880/ 7884]\n",
      "loss: 0.970890  [ 3200/ 7884]\n",
      "loss: 0.992296  [ 3520/ 7884]\n",
      "loss: 1.000374  [ 3840/ 7884]\n",
      "loss: 0.927317  [ 4160/ 7884]\n",
      "loss: 1.014693  [ 4480/ 7884]\n",
      "loss: 0.975113  [ 4800/ 7884]\n",
      "loss: 0.963844  [ 5120/ 7884]\n",
      "loss: 0.907960  [ 5440/ 7884]\n",
      "loss: 0.968869  [ 5760/ 7884]\n",
      "loss: 0.939966  [ 6080/ 7884]\n",
      "loss: 0.956927  [ 6400/ 7884]\n",
      "loss: 0.883396  [ 6720/ 7884]\n",
      "loss: 0.950190  [ 7040/ 7884]\n",
      "loss: 0.998364  [ 7360/ 7884]\n",
      "loss: 0.930535  [ 7680/ 7884]\n",
      "\n",
      "Epoch 17 Summary:\n",
      "  Train Loss: 0.968265\n",
      "  Train Task Loss: 0.191519\n",
      "  Val Loss: 0.182924\n",
      "Validation loss decreased (0.189160 --> 0.182924). Saving model...\n",
      "Saving best model to best_model.pth\n",
      "\n",
      "Epoch 18/50\n",
      "============================================================\n",
      "loss: 0.991307  [    0/ 7884]\n",
      "loss: 0.994366  [  320/ 7884]\n",
      "loss: 0.969958  [  640/ 7884]\n",
      "loss: 1.005882  [  960/ 7884]\n",
      "loss: 0.992833  [ 1280/ 7884]\n",
      "loss: 0.985339  [ 1600/ 7884]\n",
      "loss: 1.025377  [ 1920/ 7884]\n",
      "loss: 0.953972  [ 2240/ 7884]\n",
      "loss: 0.936935  [ 2560/ 7884]\n",
      "loss: 0.961110  [ 2880/ 7884]\n",
      "loss: 0.943915  [ 3200/ 7884]\n",
      "loss: 0.938173  [ 3520/ 7884]\n",
      "loss: 0.986807  [ 3840/ 7884]\n",
      "loss: 1.044654  [ 4160/ 7884]\n",
      "loss: 0.931806  [ 4480/ 7884]\n",
      "loss: 0.992794  [ 4800/ 7884]\n",
      "loss: 0.994242  [ 5120/ 7884]\n",
      "loss: 0.928414  [ 5440/ 7884]\n",
      "loss: 0.993906  [ 5760/ 7884]\n",
      "loss: 0.861766  [ 6080/ 7884]\n",
      "loss: 1.012706  [ 6400/ 7884]\n",
      "loss: 0.915994  [ 6720/ 7884]\n",
      "loss: 1.028069  [ 7040/ 7884]\n",
      "loss: 0.959068  [ 7360/ 7884]\n",
      "loss: 0.964954  [ 7680/ 7884]\n",
      "\n",
      "Epoch 18 Summary:\n",
      "  Train Loss: 0.972095\n",
      "  Train Task Loss: 0.190332\n",
      "  Val Loss: 0.184755\n",
      "EarlyStopping counter: 1 out of 5\n",
      "\n",
      "Epoch 19/50\n",
      "============================================================\n",
      "loss: 0.951898  [    0/ 7884]\n",
      "loss: 0.977042  [  320/ 7884]\n",
      "loss: 0.964519  [  640/ 7884]\n",
      "loss: 0.998611  [  960/ 7884]\n",
      "loss: 0.886241  [ 1280/ 7884]\n",
      "loss: 1.041820  [ 1600/ 7884]\n",
      "loss: 0.932904  [ 1920/ 7884]\n",
      "loss: 1.055713  [ 2240/ 7884]\n",
      "loss: 0.984280  [ 2560/ 7884]\n",
      "loss: 1.027684  [ 2880/ 7884]\n",
      "loss: 0.949865  [ 3200/ 7884]\n",
      "loss: 0.951063  [ 3520/ 7884]\n",
      "loss: 1.084866  [ 3840/ 7884]\n",
      "loss: 1.013098  [ 4160/ 7884]\n",
      "loss: 1.007576  [ 4480/ 7884]\n",
      "loss: 1.018196  [ 4800/ 7884]\n",
      "loss: 0.980003  [ 5120/ 7884]\n",
      "loss: 0.949406  [ 5440/ 7884]\n",
      "loss: 1.050252  [ 5760/ 7884]\n",
      "loss: 0.992540  [ 6080/ 7884]\n",
      "loss: 0.967185  [ 6400/ 7884]\n",
      "loss: 0.970736  [ 6720/ 7884]\n",
      "loss: 0.984502  [ 7040/ 7884]\n",
      "loss: 0.961504  [ 7360/ 7884]\n",
      "loss: 0.931377  [ 7680/ 7884]\n",
      "\n",
      "Epoch 19 Summary:\n",
      "  Train Loss: 0.969541\n",
      "  Train Task Loss: 0.189706\n",
      "  Val Loss: 0.190264\n",
      "EarlyStopping counter: 2 out of 5\n",
      "\n",
      "Epoch 20/50\n",
      "============================================================\n",
      "loss: 0.981461  [    0/ 7884]\n",
      "loss: 0.936898  [  320/ 7884]\n",
      "loss: 0.970692  [  640/ 7884]\n",
      "loss: 0.901910  [  960/ 7884]\n",
      "loss: 1.005348  [ 1280/ 7884]\n",
      "loss: 0.985001  [ 1600/ 7884]\n",
      "loss: 0.955577  [ 1920/ 7884]\n",
      "loss: 1.033481  [ 2240/ 7884]\n",
      "loss: 0.884822  [ 2560/ 7884]\n",
      "loss: 0.999098  [ 2880/ 7884]\n",
      "loss: 0.916967  [ 3200/ 7884]\n",
      "loss: 0.963261  [ 3520/ 7884]\n",
      "loss: 0.987323  [ 3840/ 7884]\n",
      "loss: 0.981638  [ 4160/ 7884]\n",
      "loss: 0.887236  [ 4480/ 7884]\n",
      "loss: 0.964780  [ 4800/ 7884]\n",
      "loss: 1.046269  [ 5120/ 7884]\n",
      "loss: 0.979602  [ 5440/ 7884]\n",
      "loss: 1.000014  [ 5760/ 7884]\n",
      "loss: 0.956449  [ 6080/ 7884]\n",
      "loss: 0.985597  [ 6400/ 7884]\n",
      "loss: 0.990460  [ 6720/ 7884]\n",
      "loss: 0.915896  [ 7040/ 7884]\n",
      "loss: 1.035577  [ 7360/ 7884]\n",
      "loss: 0.999454  [ 7680/ 7884]\n",
      "\n",
      "Epoch 20 Summary:\n",
      "  Train Loss: 0.966292\n",
      "  Train Task Loss: 0.189592\n",
      "  Val Loss: 0.194344\n",
      "EarlyStopping counter: 3 out of 5\n",
      "\n",
      "Epoch 21/50\n",
      "============================================================\n",
      "loss: 0.901874  [    0/ 7884]\n",
      "loss: 0.964412  [  320/ 7884]\n",
      "loss: 0.914720  [  640/ 7884]\n",
      "loss: 1.015233  [  960/ 7884]\n",
      "loss: 0.944988  [ 1280/ 7884]\n",
      "loss: 0.966284  [ 1600/ 7884]\n",
      "loss: 0.905135  [ 1920/ 7884]\n",
      "loss: 0.959217  [ 2240/ 7884]\n",
      "loss: 0.962433  [ 2560/ 7884]\n",
      "loss: 0.989821  [ 2880/ 7884]\n",
      "loss: 0.919218  [ 3200/ 7884]\n",
      "loss: 0.973399  [ 3520/ 7884]\n",
      "loss: 1.070365  [ 3840/ 7884]\n",
      "loss: 0.901302  [ 4160/ 7884]\n",
      "loss: 0.936313  [ 4480/ 7884]\n",
      "loss: 0.963986  [ 4800/ 7884]\n",
      "loss: 1.016208  [ 5120/ 7884]\n",
      "loss: 1.024905  [ 5440/ 7884]\n",
      "loss: 0.945754  [ 5760/ 7884]\n",
      "loss: 1.008534  [ 6080/ 7884]\n",
      "loss: 0.962490  [ 6400/ 7884]\n",
      "loss: 0.966601  [ 6720/ 7884]\n",
      "loss: 0.965141  [ 7040/ 7884]\n",
      "loss: 0.962484  [ 7360/ 7884]\n",
      "loss: 1.022814  [ 7680/ 7884]\n",
      "\n",
      "Epoch 21 Summary:\n",
      "  Train Loss: 0.971600\n",
      "  Train Task Loss: 0.189092\n",
      "  Val Loss: 0.186467\n",
      "EarlyStopping counter: 4 out of 5\n",
      "\n",
      "Epoch 22/50\n",
      "============================================================\n",
      "loss: 0.949600  [    0/ 7884]\n",
      "loss: 0.883631  [  320/ 7884]\n",
      "loss: 0.902072  [  640/ 7884]\n",
      "loss: 0.964214  [  960/ 7884]\n",
      "loss: 1.002732  [ 1280/ 7884]\n",
      "loss: 1.017640  [ 1600/ 7884]\n",
      "loss: 0.877918  [ 1920/ 7884]\n",
      "loss: 0.938838  [ 2240/ 7884]\n",
      "loss: 0.957613  [ 2560/ 7884]\n",
      "loss: 0.975476  [ 2880/ 7884]\n",
      "loss: 0.996195  [ 3200/ 7884]\n",
      "loss: 0.895522  [ 3520/ 7884]\n",
      "loss: 0.963078  [ 3840/ 7884]\n",
      "loss: 0.973278  [ 4160/ 7884]\n",
      "loss: 0.909158  [ 4480/ 7884]\n",
      "loss: 0.999256  [ 4800/ 7884]\n",
      "loss: 0.950981  [ 5120/ 7884]\n",
      "loss: 0.965911  [ 5440/ 7884]\n",
      "loss: 0.968462  [ 5760/ 7884]\n",
      "loss: 0.977631  [ 6080/ 7884]\n",
      "loss: 0.917569  [ 6400/ 7884]\n",
      "loss: 0.966344  [ 6720/ 7884]\n",
      "loss: 0.986808  [ 7040/ 7884]\n",
      "loss: 0.934794  [ 7360/ 7884]\n",
      "loss: 1.028476  [ 7680/ 7884]\n",
      "\n",
      "Epoch 22 Summary:\n",
      "  Train Loss: 0.960599\n",
      "  Train Task Loss: 0.186736\n",
      "  Val Loss: 0.174788\n",
      "Validation loss decreased (0.182924 --> 0.174788). Saving model...\n",
      "Saving best model to best_model.pth\n",
      "\n",
      "Epoch 23/50\n",
      "============================================================\n",
      "loss: 1.036290  [    0/ 7884]\n",
      "loss: 1.011175  [  320/ 7884]\n",
      "loss: 0.889619  [  640/ 7884]\n",
      "loss: 1.015217  [  960/ 7884]\n",
      "loss: 0.926205  [ 1280/ 7884]\n",
      "loss: 0.930713  [ 1600/ 7884]\n",
      "loss: 0.998309  [ 1920/ 7884]\n",
      "loss: 0.979573  [ 2240/ 7884]\n",
      "loss: 0.934908  [ 2560/ 7884]\n",
      "loss: 0.940727  [ 2880/ 7884]\n",
      "loss: 0.894909  [ 3200/ 7884]\n",
      "loss: 0.973700  [ 3520/ 7884]\n",
      "loss: 0.923283  [ 3840/ 7884]\n",
      "loss: 0.937775  [ 4160/ 7884]\n",
      "loss: 0.919392  [ 4480/ 7884]\n",
      "loss: 1.028756  [ 4800/ 7884]\n",
      "loss: 0.911940  [ 5120/ 7884]\n",
      "loss: 0.984360  [ 5440/ 7884]\n",
      "loss: 1.005913  [ 5760/ 7884]\n",
      "loss: 0.875689  [ 6080/ 7884]\n",
      "loss: 0.956645  [ 6400/ 7884]\n",
      "loss: 0.940968  [ 6720/ 7884]\n",
      "loss: 0.999664  [ 7040/ 7884]\n",
      "loss: 0.962854  [ 7360/ 7884]\n",
      "loss: 0.909961  [ 7680/ 7884]\n",
      "\n",
      "Epoch 23 Summary:\n",
      "  Train Loss: 0.966541\n",
      "  Train Task Loss: 0.184784\n",
      "  Val Loss: 0.181208\n",
      "EarlyStopping counter: 1 out of 5\n",
      "\n",
      "Epoch 24/50\n",
      "============================================================\n",
      "loss: 0.956835  [    0/ 7884]\n",
      "loss: 0.895791  [  320/ 7884]\n",
      "loss: 0.913185  [  640/ 7884]\n",
      "loss: 0.939442  [  960/ 7884]\n",
      "loss: 0.982398  [ 1280/ 7884]\n",
      "loss: 0.945018  [ 1600/ 7884]\n",
      "loss: 0.924044  [ 1920/ 7884]\n",
      "loss: 0.944859  [ 2240/ 7884]\n",
      "loss: 0.993675  [ 2560/ 7884]\n",
      "loss: 0.998194  [ 2880/ 7884]\n",
      "loss: 0.919148  [ 3200/ 7884]\n",
      "loss: 0.903778  [ 3520/ 7884]\n",
      "loss: 0.932650  [ 3840/ 7884]\n",
      "loss: 0.943663  [ 4160/ 7884]\n",
      "loss: 0.935745  [ 4480/ 7884]\n",
      "loss: 0.971424  [ 4800/ 7884]\n",
      "loss: 0.922071  [ 5120/ 7884]\n",
      "loss: 0.894507  [ 5440/ 7884]\n",
      "loss: 0.958311  [ 5760/ 7884]\n",
      "loss: 0.985494  [ 6080/ 7884]\n",
      "loss: 0.887279  [ 6400/ 7884]\n",
      "loss: 0.962213  [ 6720/ 7884]\n",
      "loss: 0.920203  [ 7040/ 7884]\n",
      "loss: 0.965675  [ 7360/ 7884]\n",
      "loss: 0.973912  [ 7680/ 7884]\n",
      "\n",
      "Epoch 24 Summary:\n",
      "  Train Loss: 0.964683\n",
      "  Train Task Loss: 0.184493\n",
      "  Val Loss: 0.173666\n",
      "Validation loss decreased (0.174788 --> 0.173666). Saving model...\n",
      "Saving best model to best_model.pth\n",
      "\n",
      "Epoch 25/50\n",
      "============================================================\n",
      "loss: 0.939272  [    0/ 7884]\n",
      "loss: 0.927959  [  320/ 7884]\n",
      "loss: 1.027748  [  640/ 7884]\n",
      "loss: 0.879461  [  960/ 7884]\n",
      "loss: 0.947762  [ 1280/ 7884]\n",
      "loss: 1.004106  [ 1600/ 7884]\n",
      "loss: 0.990763  [ 1920/ 7884]\n",
      "loss: 0.962086  [ 2240/ 7884]\n",
      "loss: 0.986928  [ 2560/ 7884]\n",
      "loss: 0.919622  [ 2880/ 7884]\n",
      "loss: 1.006178  [ 3200/ 7884]\n",
      "loss: 0.876274  [ 3520/ 7884]\n",
      "loss: 0.958902  [ 3840/ 7884]\n",
      "loss: 0.930562  [ 4160/ 7884]\n",
      "loss: 0.996677  [ 4480/ 7884]\n",
      "loss: 1.035057  [ 4800/ 7884]\n",
      "loss: 1.095731  [ 5120/ 7884]\n",
      "loss: 0.940024  [ 5440/ 7884]\n",
      "loss: 0.921792  [ 5760/ 7884]\n",
      "loss: 0.918910  [ 6080/ 7884]\n",
      "loss: 0.934835  [ 6400/ 7884]\n",
      "loss: 1.011317  [ 6720/ 7884]\n",
      "loss: 1.021279  [ 7040/ 7884]\n",
      "loss: 1.045431  [ 7360/ 7884]\n",
      "loss: 0.884901  [ 7680/ 7884]\n",
      "\n",
      "Epoch 25 Summary:\n",
      "  Train Loss: 0.967344\n",
      "  Train Task Loss: 0.184559\n",
      "  Val Loss: 0.172391\n",
      "Validation loss decreased (0.173666 --> 0.172391). Saving model...\n",
      "Saving best model to best_model.pth\n",
      "\n",
      "Epoch 26/50\n",
      "============================================================\n",
      "loss: 0.928172  [    0/ 7884]\n",
      "loss: 0.979119  [  320/ 7884]\n",
      "loss: 0.975367  [  640/ 7884]\n",
      "loss: 0.968757  [  960/ 7884]\n",
      "loss: 1.072193  [ 1280/ 7884]\n",
      "loss: 0.958632  [ 1600/ 7884]\n",
      "loss: 0.984168  [ 1920/ 7884]\n",
      "loss: 0.876923  [ 2240/ 7884]\n",
      "loss: 0.905352  [ 2560/ 7884]\n",
      "loss: 1.087280  [ 2880/ 7884]\n",
      "loss: 0.990808  [ 3200/ 7884]\n",
      "loss: 0.924817  [ 3520/ 7884]\n",
      "loss: 1.019007  [ 3840/ 7884]\n",
      "loss: 0.923312  [ 4160/ 7884]\n",
      "loss: 0.975721  [ 4480/ 7884]\n",
      "loss: 0.957824  [ 4800/ 7884]\n",
      "loss: 0.951915  [ 5120/ 7884]\n",
      "loss: 0.937671  [ 5440/ 7884]\n",
      "loss: 0.921930  [ 5760/ 7884]\n",
      "loss: 0.926730  [ 6080/ 7884]\n",
      "loss: 1.057657  [ 6400/ 7884]\n",
      "loss: 0.992932  [ 6720/ 7884]\n",
      "loss: 0.966055  [ 7040/ 7884]\n",
      "loss: 0.962272  [ 7360/ 7884]\n",
      "loss: 0.986088  [ 7680/ 7884]\n",
      "\n",
      "Epoch 26 Summary:\n",
      "  Train Loss: 0.959722\n",
      "  Train Task Loss: 0.184043\n",
      "  Val Loss: 0.187423\n",
      "EarlyStopping counter: 1 out of 5\n",
      "\n",
      "Epoch 27/50\n",
      "============================================================\n",
      "loss: 0.997379  [    0/ 7884]\n",
      "loss: 0.956632  [  320/ 7884]\n",
      "loss: 0.944100  [  640/ 7884]\n",
      "loss: 0.982222  [  960/ 7884]\n",
      "loss: 0.966579  [ 1280/ 7884]\n",
      "loss: 1.049145  [ 1600/ 7884]\n",
      "loss: 0.954188  [ 1920/ 7884]\n",
      "loss: 1.019402  [ 2240/ 7884]\n",
      "loss: 1.000802  [ 2560/ 7884]\n",
      "loss: 0.947064  [ 2880/ 7884]\n",
      "loss: 0.974282  [ 3200/ 7884]\n",
      "loss: 0.945119  [ 3520/ 7884]\n",
      "loss: 0.993548  [ 3840/ 7884]\n",
      "loss: 0.986025  [ 4160/ 7884]\n",
      "loss: 1.095122  [ 4480/ 7884]\n",
      "loss: 0.943129  [ 4800/ 7884]\n",
      "loss: 0.972025  [ 5120/ 7884]\n",
      "loss: 0.933787  [ 5440/ 7884]\n",
      "loss: 0.920362  [ 5760/ 7884]\n",
      "loss: 0.961477  [ 6080/ 7884]\n",
      "loss: 0.969532  [ 6400/ 7884]\n",
      "loss: 0.894102  [ 6720/ 7884]\n",
      "loss: 0.939420  [ 7040/ 7884]\n",
      "loss: 0.971320  [ 7360/ 7884]\n",
      "loss: 1.014333  [ 7680/ 7884]\n",
      "\n",
      "Epoch 27 Summary:\n",
      "  Train Loss: 0.963274\n",
      "  Train Task Loss: 0.184527\n",
      "  Val Loss: 0.180614\n",
      "EarlyStopping counter: 2 out of 5\n",
      "\n",
      "Epoch 28/50\n",
      "============================================================\n",
      "loss: 0.946246  [    0/ 7884]\n",
      "loss: 0.951943  [  320/ 7884]\n",
      "loss: 0.926763  [  640/ 7884]\n",
      "loss: 1.002289  [  960/ 7884]\n",
      "loss: 0.891966  [ 1280/ 7884]\n",
      "loss: 1.029359  [ 1600/ 7884]\n",
      "loss: 0.894838  [ 1920/ 7884]\n",
      "loss: 0.931074  [ 2240/ 7884]\n",
      "loss: 0.973883  [ 2560/ 7884]\n",
      "loss: 0.902023  [ 2880/ 7884]\n",
      "loss: 0.955745  [ 3200/ 7884]\n",
      "loss: 0.993176  [ 3520/ 7884]\n",
      "loss: 1.052312  [ 3840/ 7884]\n",
      "loss: 0.996701  [ 4160/ 7884]\n",
      "loss: 1.037196  [ 4480/ 7884]\n",
      "loss: 0.937524  [ 4800/ 7884]\n",
      "loss: 1.012155  [ 5120/ 7884]\n",
      "loss: 0.975430  [ 5440/ 7884]\n",
      "loss: 1.000570  [ 5760/ 7884]\n",
      "loss: 1.040244  [ 6080/ 7884]\n",
      "loss: 0.994056  [ 6400/ 7884]\n",
      "loss: 1.005883  [ 6720/ 7884]\n",
      "loss: 0.933513  [ 7040/ 7884]\n",
      "loss: 1.048349  [ 7360/ 7884]\n",
      "loss: 0.998786  [ 7680/ 7884]\n",
      "\n",
      "Epoch 28 Summary:\n",
      "  Train Loss: 0.963468\n",
      "  Train Task Loss: 0.185459\n",
      "  Val Loss: 0.182973\n",
      "EarlyStopping counter: 3 out of 5\n",
      "\n",
      "Epoch 29/50\n",
      "============================================================\n",
      "loss: 0.887333  [    0/ 7884]\n",
      "loss: 0.977502  [  320/ 7884]\n",
      "loss: 1.051403  [  640/ 7884]\n",
      "loss: 0.992419  [  960/ 7884]\n",
      "loss: 0.928112  [ 1280/ 7884]\n",
      "loss: 0.952018  [ 1600/ 7884]\n",
      "loss: 0.979688  [ 1920/ 7884]\n",
      "loss: 0.960664  [ 2240/ 7884]\n",
      "loss: 0.958216  [ 2560/ 7884]\n",
      "loss: 0.934883  [ 2880/ 7884]\n",
      "loss: 0.956628  [ 3200/ 7884]\n",
      "loss: 1.093265  [ 3520/ 7884]\n",
      "loss: 1.019209  [ 3840/ 7884]\n",
      "loss: 0.972545  [ 4160/ 7884]\n",
      "loss: 0.939993  [ 4480/ 7884]\n",
      "loss: 0.923072  [ 4800/ 7884]\n",
      "loss: 1.001005  [ 5120/ 7884]\n",
      "loss: 0.985091  [ 5440/ 7884]\n",
      "loss: 0.938249  [ 5760/ 7884]\n",
      "loss: 0.947545  [ 6080/ 7884]\n",
      "loss: 1.059451  [ 6400/ 7884]\n",
      "loss: 0.986494  [ 6720/ 7884]\n",
      "loss: 1.001578  [ 7040/ 7884]\n",
      "loss: 0.900162  [ 7360/ 7884]\n",
      "loss: 0.949481  [ 7680/ 7884]\n",
      "\n",
      "Epoch 29 Summary:\n",
      "  Train Loss: 0.956354\n",
      "  Train Task Loss: 0.183954\n",
      "  Val Loss: 0.197063\n",
      "EarlyStopping counter: 4 out of 5\n",
      "\n",
      "Epoch 30/50\n",
      "============================================================\n",
      "loss: 0.954328  [    0/ 7884]\n",
      "loss: 0.931803  [  320/ 7884]\n",
      "loss: 0.988759  [  640/ 7884]\n",
      "loss: 0.949037  [  960/ 7884]\n",
      "loss: 0.920044  [ 1280/ 7884]\n",
      "loss: 0.932434  [ 1600/ 7884]\n",
      "loss: 0.922024  [ 1920/ 7884]\n",
      "loss: 1.040211  [ 2240/ 7884]\n",
      "loss: 0.977067  [ 2560/ 7884]\n",
      "loss: 0.984724  [ 2880/ 7884]\n",
      "loss: 0.969799  [ 3200/ 7884]\n",
      "loss: 1.049772  [ 3520/ 7884]\n",
      "loss: 0.938654  [ 3840/ 7884]\n",
      "loss: 0.959371  [ 4160/ 7884]\n",
      "loss: 0.954595  [ 4480/ 7884]\n",
      "loss: 0.910633  [ 4800/ 7884]\n",
      "loss: 0.917874  [ 5120/ 7884]\n",
      "loss: 0.979197  [ 5440/ 7884]\n",
      "loss: 0.920682  [ 5760/ 7884]\n",
      "loss: 1.032420  [ 6080/ 7884]\n",
      "loss: 0.898602  [ 6400/ 7884]\n",
      "loss: 0.932604  [ 6720/ 7884]\n",
      "loss: 0.971569  [ 7040/ 7884]\n",
      "loss: 0.946651  [ 7360/ 7884]\n",
      "loss: 0.891359  [ 7680/ 7884]\n",
      "\n",
      "Epoch 30 Summary:\n",
      "  Train Loss: 0.956158\n",
      "  Train Task Loss: 0.181414\n",
      "  Val Loss: 0.181488\n",
      "EarlyStopping counter: 5 out of 5\n",
      "Early stopping triggered. Saving final model to final_model.pth\n",
      "\n",
      "============================================================\n",
      "‚úì Early stopping triggered!\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'plot_training_history' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[55], line 5\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m      2\u001b[0m     \u001b[38;5;66;03m# Call the training function with distillation\u001b[39;00m\n\u001b[1;32m      3\u001b[0m     patience \u001b[38;5;241m=\u001b[39m config[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtraining\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpatience\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpatience\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01min\u001b[39;00m config[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtraining\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;241m7\u001b[39m\n\u001b[0;32m----> 5\u001b[0m     trained_student, training_history \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_model_distillation\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43m        \u001b[49m\u001b[43mval_loader\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mval_loader\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstudent_model\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstudent_model\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      9\u001b[0m \u001b[43m        \u001b[49m\u001b[43mteacher_model\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mteacher_model\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     10\u001b[0m \u001b[43m        \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     11\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     12\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnum_epochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mepochs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     13\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpatience\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpatience\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     14\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtemperature\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m3.0\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     15\u001b[0m \u001b[43m        \u001b[49m\u001b[43malpha\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.5\u001b[39;49m\n\u001b[1;32m     16\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     18\u001b[0m     \u001b[38;5;66;03m# Evaluate student on test set\u001b[39;00m\n\u001b[1;32m     19\u001b[0m     test_loss \u001b[38;5;241m=\u001b[39m evaluate_student_model(test_loader, trained_student, device)\n",
      "Cell \u001b[0;32mIn[54], line 57\u001b[0m, in \u001b[0;36mtrain_model_distillation\u001b[0;34m(train_loader, val_loader, student_model, teacher_model, optimizer, device, num_epochs, patience, temperature, alpha)\u001b[0m\n\u001b[1;32m     55\u001b[0m \u001b[38;5;66;03m# Load best model\u001b[39;00m\n\u001b[1;32m     56\u001b[0m student_model\u001b[38;5;241m.\u001b[39mload_state_dict(torch\u001b[38;5;241m.\u001b[39mload(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcheckpoint.pt\u001b[39m\u001b[38;5;124m'\u001b[39m))\n\u001b[0;32m---> 57\u001b[0m \u001b[43mplot_training_history\u001b[49m(history)\n\u001b[1;32m     58\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m student_model, history\n",
      "\u001b[0;31mNameError\u001b[0m: name 'plot_training_history' is not defined"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    # Call the training function with distillation\n",
    "    patience = config['training']['patience'] if 'patience' in config['training'] else 7\n",
    "    \n",
    "    trained_student, training_history = train_model_distillation(\n",
    "        train_loader=train_loader,\n",
    "        val_loader=val_loader,\n",
    "        student_model=student_model,\n",
    "        teacher_model=teacher_model,\n",
    "        optimizer=optimizer,\n",
    "        device=device,\n",
    "        num_epochs=epochs,\n",
    "        patience=patience,\n",
    "        temperature=3.0,\n",
    "        alpha=0.5\n",
    "    )\n",
    "    \n",
    "    # Evaluate student on test set\n",
    "    test_loss = evaluate_student_model(test_loader, trained_student, device)\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"Final Test Loss: {test_loss:.6f}\")\n",
    "    print(f\"{'='*60}\")\n",
    "    \n",
    "    print(\"\\n‚úì Knowledge Distillation Training Completed!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "29cd7d36-1140-4cd6-8c77-75a846b1c882",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'history' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[57], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m plot_training_history(\u001b[43mhistory\u001b[49m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'history' is not defined"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0fc6751-fb02-4b9a-b0db-358b67ede1e3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
