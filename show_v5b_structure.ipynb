{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# XiaoNetV5B Architecture Explorer\n",
    "\n",
    "This notebook visualizes the architecture, parameter count, and data flow of the `XiaoNetV5B` model. You can change the `base_channels` in the configuration cell below to see how it affects the model's size and complexity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from models.xn_xiao_net_v5b_sigmoid import XiaoNetV5B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Model instantiated with base_channels=8\n"
     ]
    }
   ],
   "source": [
    "# --- Configuration ---\n",
    "# Adjust the base_channels to see how the model size and layer parameters change.\n",
    "# The default for Orin Nano optimization is 7.\n",
    "# A value of 16 is used in some training scripts.\n",
    "base_channels = 8\n",
    "# ---------------------\n",
    "\n",
    "# Instantiate model with specified parameters\n",
    "#model = XiaoNetV5B(window_len=3001, in_channels=3, num_phases=3, base_channels=base_channels)\n",
    "model = XiaoNetV5B(window_len=3001, in_channels=3, num_phases=3, base_channels=base_channels)\n",
    "print(f\"✓ Model instantiated with base_channels={base_channels}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Configuration:\n",
      "  • Input: (batch, 3 channels, 3001 samples)\n",
      "  • Output: (batch, 3 phases, 3001 samples) [P, S, Noise]\n",
      "  • Base channels: 8\n",
      "  • Activation: Sigmoid (independent probabilities)\n",
      "\n",
      "Model Statistics:\n",
      "  • Total parameters: 20,208\n",
      "  • Trainable parameters: 20,208\n",
      "\n",
      "Deployment Readiness:\n",
      "  • GPU optimized: True\n",
      "  • TensorRT compatible: True\n"
     ]
    }
   ],
   "source": [
    "# Get model info\n",
    "info = model.get_model_info()\n",
    "total_params, trainable_params = model.count_parameters()\n",
    "\n",
    "print('Model Configuration:')\n",
    "print(f'  • Input: (batch, 3 channels, 3001 samples)')\n",
    "print(f'  • Output: (batch, 3 phases, 3001 samples) [P, S, Noise]')\n",
    "print(f'  • Base channels: {model.base_channels}')\n",
    "print(f'  • Activation: Sigmoid (independent probabilities)')\n",
    "print()\n",
    "print('Model Statistics:')\n",
    "print(f'  • Total parameters: {total_params:,}')\n",
    "print(f'  • Trainable parameters: {trainable_params:,}')\n",
    "print()\n",
    "print('Deployment Readiness:')\n",
    "print(f'  • GPU optimized: {info[\"gpu_optimized\"]}')\n",
    "print(f'  • TensorRT compatible: {info[\"tensorrt_compatible\"]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Layer-by-Layer Breakdown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ENCODER (Downsampling Path):\n",
      "  enc1 (3→8)       :     61 params | kernel=7, stride=1 | Output: (8, 3001)\n",
      "  enc2 (8→16)      :    200 params | kernel=5, stride=4 | Output: (16, 750)\n",
      "  enc3 (16→32)     :    656 params | kernel=5, stride=4 | Output: (32, 187)\n",
      "  bottleneck(32→64):  2,272 params | kernel=3, stride=4 | Output: (64, 46)\n",
      "\n",
      "MULTI-SCALE FEATURE EXTRACTOR (at bottleneck):\n",
      "  multi_scale      : 13,632 params | kernels=[3,5,7], parallel\n",
      "\n",
      "DECODER (Upsampling Path + Skip Connections):\n",
      "  dec3 (64→32)     :  2,432 params | upsample×4, kernel=5 | + skip from enc3\n",
      "  dec2 (32→16)     :    704 params | upsample×4, kernel=5 | + skip from enc2\n",
      "  dec1 (16→8)      :    224 params | upsample×4, kernel=5 | + skip from enc1\n",
      "\n",
      "OUTPUT:\n",
      "  output (8→3)     :     27 params | 1×1 conv\n",
      "  sigmoid          : activation (per-channel independence)\n"
     ]
    }
   ],
   "source": [
    "# Helper function to count parameters in a module\n",
    "def count_layer_params(module):\n",
    "    return sum(p.numel() for p in module.parameters())\n",
    "\n",
    "# Use f-strings to make the channel numbers dynamic\n",
    "bc = model.base_channels\n",
    "\n",
    "print('ENCODER (Downsampling Path):')\n",
    "print(f'  enc1 (3→{bc})       : {count_layer_params(model.enc1):>6,} params | kernel=7, stride=1 | Output: ({bc}, 3001)')\n",
    "print(f'  enc2 ({bc}→{bc*2})      : {count_layer_params(model.enc2):>6,} params | kernel=5, stride=4 | Output: ({bc*2}, 750)')\n",
    "print(f'  enc3 ({bc*2}→{bc*4})     : {count_layer_params(model.enc3):>6,} params | kernel=5, stride=4 | Output: ({bc*4}, 187)')\n",
    "print(f'  bottleneck({bc*4}→{bc*8}): {count_layer_params(model.bottleneck):>6,} params | kernel=3, stride=4 | Output: ({bc*8}, 46)')\n",
    "print()\n",
    "\n",
    "print('MULTI-SCALE FEATURE EXTRACTOR (at bottleneck):')\n",
    "print(f'  multi_scale      : {count_layer_params(model.multi_scale):>6,} params | kernels=[3,5,7], parallel')\n",
    "print()\n",
    "\n",
    "print('DECODER (Upsampling Path + Skip Connections):')\n",
    "print(f'  dec3 ({bc*8}→{bc*4})     : {count_layer_params(model.dec3):>6,} params | upsample×4, kernel=5 | + skip from enc3')\n",
    "print(f'  dec2 ({bc*4}→{bc*2})     : {count_layer_params(model.dec2):>6,} params | upsample×4, kernel=5 | + skip from enc2')\n",
    "print(f'  dec1 ({bc*2}→{bc})      : {count_layer_params(model.dec1):>6,} params | upsample×4, kernel=5 | + skip from enc1')\n",
    "print()\n",
    "\n",
    "print('OUTPUT:')\n",
    "print(f'  output ({bc}→3)     : {count_layer_params(model.output):>6,} params | 1×1 conv')\n",
    "print(f'  sigmoid          : activation (per-channel independence)')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Flow Diagram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input (3, 3001)\n",
      "     ↓\n",
      "enc1 → (8, 3001)  ──────────────────────────┐\n",
      "     ↓                                       │\n",
      "enc2 → (16, 750)  ─────────────────┐        │\n",
      "     ↓                              │        │\n",
      "enc3 → (32, 187)  ───────┐         │        │\n",
      "     ↓                    │         │        │\n",
      "bottleneck → (64, 46)    │         │        │\n",
      "     ↓                    │         │        │\n",
      "multi_scale → (64, 46)   │         │        │\n",
      "     ↓                    │         │        │\n",
      "dec3 → (32, 187) ←───────┘         │        │\n",
      "     ↓                              │        │\n",
      "dec2 → (16, 750) ←─────────────────┘        │\n",
      "     ↓                                       │\n",
      "dec1 → (8, 3001) ←──────────────────────────┘\n",
      "     ↓\n",
      "output + sigmoid → (3, 3001)\n"
     ]
    }
   ],
   "source": [
    "# Using f-strings to make the channel numbers dynamic\n",
    "bc = model.base_channels\n",
    "print('Input (3, 3001)')\n",
    "print('     ↓')\n",
    "print(f'enc1 → ({bc}, 3001)  ──────────────────────────┐')\n",
    "print('     ↓                                       │')\n",
    "print(f'enc2 → ({bc*2}, 750)  ─────────────────┐        │')\n",
    "print('     ↓                              │        │')\n",
    "print(f'enc3 → ({bc*4}, 187)  ───────┐         │        │')\n",
    "print('     ↓                    │         │        │')\n",
    "print(f'bottleneck → ({bc*8}, 46)    │         │        │')\n",
    "print('     ↓                    │         │        │')\n",
    "print(f'multi_scale → ({bc*8}, 46)   │         │        │')\n",
    "print('     ↓                    │         │        │')\n",
    "print(f'dec3 → ({bc*4}, 187) ←───────┘         │        │')\n",
    "print('     ↓                              │        │')\n",
    "print(f'dec2 → ({bc*2}, 750) ←─────────────────┘        │')\n",
    "print('     ↓                                       │')\n",
    "print(f'dec1 → ({bc}, 3001) ←──────────────────────────┘')\n",
    "print('     ↓')\n",
    "print('output + sigmoid → (3, 3001)')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Key Features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*   **Grouped Depthwise Separable Convolutions**: Parameter efficient and GPU-friendly.\n",
    "*   **Multi-scale feature extraction**: At the bottleneck, parallel paths with kernels of size 3, 5, and 7 capture features at different scales.\n",
    "*   **Skip connections**: U-Net style connections preserve high-resolution information for precise phase localization.\n",
    "*   **Sigmoid activation**: Allows for independent probabilities for P, S, and Noise, making it suitable for multi-label classification.\n",
    "*   **GPU-optimized**: Specifically designed with NVIDIA Orin Nano deployment in mind.\n",
    "*   **TensorRT ready**: The architecture uses operations compatible with TensorRT for significant inference speedup on NVIDIA hardware."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ML",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
