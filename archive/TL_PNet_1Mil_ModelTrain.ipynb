{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 185,
   "id": "e2ee661e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python\n",
    "# coding: utf-8\n",
    "\n",
    "import obspy\n",
    "from obspy.clients.fdsn import Client\n",
    "from obspy import UTCDateTime\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import torch\n",
    "\n",
    "import json\n",
    "import time\n",
    "\n",
    "import seisbench.models as sbm\n",
    "import seisbench.data as sbd\n",
    "import seisbench.generate as sbg\n",
    "\n",
    "from seisbench.util import worker_seeding\n",
    "from torch.utils.data import DataLoader\n",
    "from obspy.clients.fdsn import Client\n",
    "from scipy.signal import find_peaks\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "id": "f921a3a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ All imports successful!\n"
     ]
    }
   ],
   "source": [
    "print(\"✓ All imports successful!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "id": "c7482716",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Configuration loaded successfully!\n"
     ]
    }
   ],
   "source": [
    "# Load configuration from JSON file\n",
    "try:\n",
    "    with open('config.json', 'r') as f:\n",
    "        config = json.load(f)\n",
    "    print(\"✓ Configuration loaded successfully!\")\n",
    "except FileNotFoundError:\n",
    "    print(\"✗ Error: config.json file not found!\")\n",
    "    raise\n",
    "except json.JSONDecodeError as e:\n",
    "    print(f\"✗ Error: Invalid JSON in config.json: {e}\")\n",
    "    raise\n",
    "except Exception as e:\n",
    "    print(f\"✗ Unexpected error loading config: {e}\")\n",
    "    raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "id": "96b06235",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'peak_detection': {'sampling_rate': 100, 'height': 0.5, 'distance': 100},\n",
       " 'training': {'batch_size': 64,\n",
       "  'num_workers': 4,\n",
       "  'learning_rate': 0.01,\n",
       "  'epochs': 50,\n",
       "  'patience': 5,\n",
       "  'loss_weights': [0.01, 0.4, 0.59],\n",
       "  'optimization': {'mixed_precision': True,\n",
       "   'gradient_accumulation_steps': 1,\n",
       "   'pin_memory': True,\n",
       "   'prefetch_factor': 2,\n",
       "   'persistent_workers': True}},\n",
       " 'device': {'use_cuda': True, 'device_id': 0}}"
      ]
     },
     "execution_count": 188,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "id": "1cac5493",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set random seed for reproducibility\n",
    "import random\n",
    "random.seed(0)\n",
    "np.random.seed(0)\n",
    "torch.manual_seed(0)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "id": "6f080377",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Model loaded successfully!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# Loader the picker\n",
    "try:\n",
    "    #model = sbm.EQTransformer.from_pretrained(\"original\")\n",
    "    model = sbm.PhaseNet.from_pretrained(\"stead\")\n",
    "    print(\"✓ Model loaded successfully!\")\n",
    "except Exception as e:\n",
    "    print(f\"✗ Error loading model: {e}\")\n",
    "    raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "id": "9c820e56",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "PhaseNet(\n",
       "  (inc): Conv1d(3, 8, kernel_size=(7,), stride=(1,), padding=same)\n",
       "  (in_bn): BatchNorm1d(8, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (down_branch): ModuleList(\n",
       "    (0): ModuleList(\n",
       "      (0): Conv1d(8, 8, kernel_size=(7,), stride=(1,), padding=same, bias=False)\n",
       "      (1): BatchNorm1d(8, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): Conv1d(8, 8, kernel_size=(7,), stride=(4,), padding=(3,), bias=False)\n",
       "      (3): BatchNorm1d(8, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (1): ModuleList(\n",
       "      (0): Conv1d(8, 16, kernel_size=(7,), stride=(1,), padding=same, bias=False)\n",
       "      (1): BatchNorm1d(16, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): Conv1d(16, 16, kernel_size=(7,), stride=(4,), bias=False)\n",
       "      (3): BatchNorm1d(16, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (2): ModuleList(\n",
       "      (0): Conv1d(16, 32, kernel_size=(7,), stride=(1,), padding=same, bias=False)\n",
       "      (1): BatchNorm1d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): Conv1d(32, 32, kernel_size=(7,), stride=(4,), bias=False)\n",
       "      (3): BatchNorm1d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (3): ModuleList(\n",
       "      (0): Conv1d(32, 64, kernel_size=(7,), stride=(1,), padding=same, bias=False)\n",
       "      (1): BatchNorm1d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): Conv1d(64, 64, kernel_size=(7,), stride=(4,), bias=False)\n",
       "      (3): BatchNorm1d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (4): ModuleList(\n",
       "      (0): Conv1d(64, 128, kernel_size=(7,), stride=(1,), padding=same, bias=False)\n",
       "      (1): BatchNorm1d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2-3): 2 x None\n",
       "    )\n",
       "  )\n",
       "  (up_branch): ModuleList(\n",
       "    (0): ModuleList(\n",
       "      (0): ConvTranspose1d(128, 64, kernel_size=(7,), stride=(4,), bias=False)\n",
       "      (1): BatchNorm1d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): Conv1d(128, 64, kernel_size=(7,), stride=(1,), padding=same, bias=False)\n",
       "      (3): BatchNorm1d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (1): ModuleList(\n",
       "      (0): ConvTranspose1d(64, 32, kernel_size=(7,), stride=(4,), bias=False)\n",
       "      (1): BatchNorm1d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): Conv1d(64, 32, kernel_size=(7,), stride=(1,), padding=same, bias=False)\n",
       "      (3): BatchNorm1d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (2): ModuleList(\n",
       "      (0): ConvTranspose1d(32, 16, kernel_size=(7,), stride=(4,), bias=False)\n",
       "      (1): BatchNorm1d(16, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): Conv1d(32, 16, kernel_size=(7,), stride=(1,), padding=same, bias=False)\n",
       "      (3): BatchNorm1d(16, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (3): ModuleList(\n",
       "      (0): ConvTranspose1d(16, 8, kernel_size=(7,), stride=(4,), bias=False)\n",
       "      (1): BatchNorm1d(8, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): Conv1d(16, 8, kernel_size=(7,), stride=(1,), padding=same, bias=False)\n",
       "      (3): BatchNorm1d(8, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (out): Conv1d(8, 3, kernel_size=(1,), stride=(1,), padding=same)\n",
       "  (softmax): Softmax(dim=1)\n",
       ")"
      ]
     },
     "execution_count": 191,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Set up device\n",
    "device = torch.device(f\"cuda:{config['device']['device_id']}\" if torch.cuda.is_available() and config['device']['use_cuda'] else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "model.to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "id": "986b17c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PhaseNet information:\n",
      "Total parameters: 268,443\n",
      "Trainable parameters: 268,443\n",
      "Model size: 1.02 MB (float32)\n"
     ]
    }
   ],
   "source": [
    "# Print PhaseNet model information\n",
    "phasenet_total_params = sum(p.numel() for p in model.parameters())\n",
    "phasenet_trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "print(\"PhaseNet information:\")\n",
    "print(f\"Total parameters: {phasenet_total_params:,}\")\n",
    "print(f\"Trainable parameters: {phasenet_trainable_params:,}\")\n",
    "print(f\"Model size: {phasenet_total_params * 4 / (1024**2):.2f} MB (float32)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "id": "f8c58873",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inc.weight: torch.Size([8, 3, 7])\n",
      "inc.bias: torch.Size([8])\n",
      "in_bn.weight: torch.Size([8])\n",
      "in_bn.bias: torch.Size([8])\n",
      "down_branch.0.0.weight: torch.Size([8, 8, 7])\n",
      "down_branch.0.1.weight: torch.Size([8])\n",
      "down_branch.0.1.bias: torch.Size([8])\n",
      "down_branch.0.2.weight: torch.Size([8, 8, 7])\n",
      "down_branch.0.3.weight: torch.Size([8])\n",
      "down_branch.0.3.bias: torch.Size([8])\n",
      "down_branch.1.0.weight: torch.Size([16, 8, 7])\n",
      "down_branch.1.1.weight: torch.Size([16])\n",
      "down_branch.1.1.bias: torch.Size([16])\n",
      "down_branch.1.2.weight: torch.Size([16, 16, 7])\n",
      "down_branch.1.3.weight: torch.Size([16])\n",
      "down_branch.1.3.bias: torch.Size([16])\n",
      "down_branch.2.0.weight: torch.Size([32, 16, 7])\n",
      "down_branch.2.1.weight: torch.Size([32])\n",
      "down_branch.2.1.bias: torch.Size([32])\n",
      "down_branch.2.2.weight: torch.Size([32, 32, 7])\n",
      "down_branch.2.3.weight: torch.Size([32])\n",
      "down_branch.2.3.bias: torch.Size([32])\n",
      "down_branch.3.0.weight: torch.Size([64, 32, 7])\n",
      "down_branch.3.1.weight: torch.Size([64])\n",
      "down_branch.3.1.bias: torch.Size([64])\n",
      "down_branch.3.2.weight: torch.Size([64, 64, 7])\n",
      "down_branch.3.3.weight: torch.Size([64])\n",
      "down_branch.3.3.bias: torch.Size([64])\n",
      "down_branch.4.0.weight: torch.Size([128, 64, 7])\n",
      "down_branch.4.1.weight: torch.Size([128])\n",
      "down_branch.4.1.bias: torch.Size([128])\n",
      "up_branch.0.0.weight: torch.Size([128, 64, 7])\n",
      "up_branch.0.1.weight: torch.Size([64])\n",
      "up_branch.0.1.bias: torch.Size([64])\n",
      "up_branch.0.2.weight: torch.Size([64, 128, 7])\n",
      "up_branch.0.3.weight: torch.Size([64])\n",
      "up_branch.0.3.bias: torch.Size([64])\n",
      "up_branch.1.0.weight: torch.Size([64, 32, 7])\n",
      "up_branch.1.1.weight: torch.Size([32])\n",
      "up_branch.1.1.bias: torch.Size([32])\n",
      "up_branch.1.2.weight: torch.Size([32, 64, 7])\n",
      "up_branch.1.3.weight: torch.Size([32])\n",
      "up_branch.1.3.bias: torch.Size([32])\n",
      "up_branch.2.0.weight: torch.Size([32, 16, 7])\n",
      "up_branch.2.1.weight: torch.Size([16])\n",
      "up_branch.2.1.bias: torch.Size([16])\n",
      "up_branch.2.2.weight: torch.Size([16, 32, 7])\n",
      "up_branch.2.3.weight: torch.Size([16])\n",
      "up_branch.2.3.bias: torch.Size([16])\n",
      "up_branch.3.0.weight: torch.Size([16, 8, 7])\n",
      "up_branch.3.1.weight: torch.Size([8])\n",
      "up_branch.3.1.bias: torch.Size([8])\n",
      "up_branch.3.2.weight: torch.Size([8, 16, 7])\n",
      "up_branch.3.3.weight: torch.Size([8])\n",
      "up_branch.3.3.bias: torch.Size([8])\n",
      "out.weight: torch.Size([3, 8, 1])\n",
      "out.bias: torch.Size([3])\n",
      "inc.weight: torch.Size([8, 3, 7])\n",
      "inc.bias: torch.Size([8])\n",
      "in_bn.weight: torch.Size([8])\n",
      "in_bn.bias: torch.Size([8])\n",
      "down_branch.0.0.weight: torch.Size([8, 8, 7])\n",
      "down_branch.0.1.weight: torch.Size([8])\n",
      "down_branch.0.1.bias: torch.Size([8])\n",
      "down_branch.0.2.weight: torch.Size([8, 8, 7])\n",
      "down_branch.0.3.weight: torch.Size([8])\n",
      "down_branch.0.3.bias: torch.Size([8])\n",
      "down_branch.1.0.weight: torch.Size([16, 8, 7])\n",
      "down_branch.1.1.weight: torch.Size([16])\n",
      "down_branch.1.1.bias: torch.Size([16])\n",
      "down_branch.1.2.weight: torch.Size([16, 16, 7])\n",
      "down_branch.1.3.weight: torch.Size([16])\n",
      "down_branch.1.3.bias: torch.Size([16])\n",
      "down_branch.2.0.weight: torch.Size([32, 16, 7])\n",
      "down_branch.2.1.weight: torch.Size([32])\n",
      "down_branch.2.1.bias: torch.Size([32])\n",
      "down_branch.2.2.weight: torch.Size([32, 32, 7])\n",
      "down_branch.2.3.weight: torch.Size([32])\n",
      "down_branch.2.3.bias: torch.Size([32])\n",
      "down_branch.3.0.weight: torch.Size([64, 32, 7])\n",
      "down_branch.3.1.weight: torch.Size([64])\n",
      "down_branch.3.1.bias: torch.Size([64])\n",
      "down_branch.3.2.weight: torch.Size([64, 64, 7])\n",
      "down_branch.3.3.weight: torch.Size([64])\n",
      "down_branch.3.3.bias: torch.Size([64])\n",
      "down_branch.4.0.weight: torch.Size([128, 64, 7])\n",
      "down_branch.4.1.weight: torch.Size([128])\n",
      "down_branch.4.1.bias: torch.Size([128])\n",
      "up_branch.0.0.weight: torch.Size([128, 64, 7])\n",
      "up_branch.0.1.weight: torch.Size([64])\n",
      "up_branch.0.1.bias: torch.Size([64])\n",
      "up_branch.0.2.weight: torch.Size([64, 128, 7])\n",
      "up_branch.0.3.weight: torch.Size([64])\n",
      "up_branch.0.3.bias: torch.Size([64])\n",
      "up_branch.1.0.weight: torch.Size([64, 32, 7])\n",
      "up_branch.1.1.weight: torch.Size([32])\n",
      "up_branch.1.1.bias: torch.Size([32])\n",
      "up_branch.1.2.weight: torch.Size([32, 64, 7])\n",
      "up_branch.1.3.weight: torch.Size([32])\n",
      "up_branch.1.3.bias: torch.Size([32])\n",
      "up_branch.2.0.weight: torch.Size([32, 16, 7])\n",
      "up_branch.2.1.weight: torch.Size([16])\n",
      "up_branch.2.1.bias: torch.Size([16])\n",
      "up_branch.2.2.weight: torch.Size([16, 32, 7])\n",
      "up_branch.2.3.weight: torch.Size([16])\n",
      "up_branch.2.3.bias: torch.Size([16])\n",
      "up_branch.3.0.weight: torch.Size([16, 8, 7])\n",
      "up_branch.3.1.weight: torch.Size([8])\n",
      "up_branch.3.1.bias: torch.Size([8])\n",
      "up_branch.3.2.weight: torch.Size([8, 16, 7])\n",
      "up_branch.3.3.weight: torch.Size([8])\n",
      "up_branch.3.3.bias: torch.Size([8])\n",
      "out.weight: torch.Size([3, 8, 1])\n",
      "out.bias: torch.Size([3])\n"
     ]
    }
   ],
   "source": [
    "for name, param in model.named_parameters():\n",
    "    print(f\"{name}: {param.shape}\")# Display all PhaseNet model parameters with their names and shapes\n",
    "for name, param in model.named_parameters():\n",
    "    print(f\"{name}: {param.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "id": "c5718232",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ XiaoNet created successfully!\n",
      "Total parameters: 164,355\n",
      "Trainable parameters: 164,355\n",
      "Model size: 0.63 MB (float32)\n",
      "Base channels: 16\n",
      "Kernel size: 3 (all convolution layers)\n"
     ]
    }
   ],
   "source": [
    "# Import XiaoNet from models\n",
    "import sys\n",
    "sys.path.append('/Users/hongyuxiao/Hongyu_File/xiao_net')\n",
    "from models.xn_xiao_net import XiaoNet\n",
    "\n",
    "# Create XiaoNet model\n",
    "xiao_net = XiaoNet(\n",
    "    window_len=3001,      # Match the data window length\n",
    "    in_channels=3,        # 3 channels (E, N, Z)\n",
    "    num_phases=3,         # 3 outputs (P, S, noise)\n",
    "    base_channels=16      # Base channel width (can adjust for size)\n",
    ")\n",
    "xiao_net.to(device)\n",
    "\n",
    "# Count parameters\n",
    "total_params = sum(p.numel() for p in xiao_net.parameters())\n",
    "trainable_params = sum(p.numel() for p in xiao_net.parameters() if p.requires_grad)\n",
    "\n",
    "print(f\"✓ XiaoNet created successfully!\")\n",
    "print(f\"Total parameters: {total_params:,}\")\n",
    "print(f\"Trainable parameters: {trainable_params:,}\")\n",
    "print(f\"Model size: {total_params * 4 / (1024**2):.2f} MB (float32)\")\n",
    "print(f\"Base channels: 16\")\n",
    "print(f\"Kernel size: 3 (all convolution layers)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "id": "9d2b15ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ XiaoNet forward pass successful!\n",
      "  Input shape: torch.Size([2, 3, 3001])\n",
      "  Output shape: torch.Size([2, 3, 3001])\n",
      "\n",
      "✓ XiaoNet reloaded with fixed forward pass!\n",
      "Total parameters: 164,355\n",
      "Trainable parameters: 164,355\n",
      "Model size: 0.63 MB (float32)\n",
      "Base channels: 16\n",
      "Kernel size: 3 (all convolution layers)\n"
     ]
    }
   ],
   "source": [
    "# Test XiaoNet forward pass with 3001 input to debug dimension flow\n",
    "import importlib\n",
    "import sys\n",
    "\n",
    "# Remove old module from cache if it exists\n",
    "if 'models.xn_xiao_net' in sys.modules:\n",
    "    del sys.modules['models.xn_xiao_net']\n",
    "\n",
    "# Re-import with fresh code\n",
    "from models.xn_xiao_net import XiaoNet\n",
    "\n",
    "# Create XiaoNet model with fixed forward pass\n",
    "xiao_net = XiaoNet(\n",
    "    window_len=3001,      # Match the data window length\n",
    "    in_channels=3,        # 3 channels (E, N, Z)\n",
    "    num_phases=3,         # 3 outputs (P, S, noise)\n",
    "    base_channels=16      # Base channel width (can adjust for size)\n",
    ")\n",
    "xiao_net.to(device)\n",
    "\n",
    "# Test with a dummy batch to verify dimensions\n",
    "test_input = torch.randn(2, 3, 3001).to(device)\n",
    "try:\n",
    "    test_output = xiao_net(test_input)\n",
    "    print(f\"✓ XiaoNet forward pass successful!\")\n",
    "    print(f\"  Input shape: {test_input.shape}\")\n",
    "    print(f\"  Output shape: {test_output.shape}\")\n",
    "except Exception as e:\n",
    "    print(f\"✗ Error during forward pass: {e}\")\n",
    "    raise\n",
    "\n",
    "# Count parameters\n",
    "total_params = sum(p.numel() for p in xiao_net.parameters())\n",
    "trainable_params = sum(p.numel() for p in xiao_net.parameters() if p.requires_grad)\n",
    "\n",
    "print(f\"\\n✓ XiaoNet reloaded with fixed forward pass!\")\n",
    "print(f\"Total parameters: {total_params:,}\")\n",
    "print(f\"Trainable parameters: {trainable_params:,}\")\n",
    "print(f\"Model size: {total_params * 4 / (1024**2):.2f} MB (float32)\")\n",
    "print(f\"Base channels: 16\")\n",
    "print(f\"Kernel size: 3 (all convolution layers)\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "id": "33f94ec8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data...\n",
      "✓ Data loaded successfully!\n"
     ]
    }
   ],
   "source": [
    "# Load the data\n",
    "print(\"Loading data...\")\n",
    "try:\n",
    "    data = sbd.OKLA_1Mil_120s_Ver_3(sampling_rate=100, force=True, component_order=\"ENZ\")\n",
    "    print(\"✓ Data loaded successfully!\")\n",
    "\n",
    "except Exception as e:\n",
    "\n",
    "    print(f\"✗ Error loading data: {e}\")\n",
    "    raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "id": "f44060f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating random sample of 2.0% of the data...\n"
     ]
    }
   ],
   "source": [
    "# Create a random sample\n",
    "sample_fraction = 0.02  # Sample 20% of the data\n",
    "print(f\"Creating random sample of {sample_fraction*100}% of the data...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "id": "6ed9bc20",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sampled dataset size: 22782\n"
     ]
    }
   ],
   "source": [
    "# Create a random mask for sampling\n",
    "np.random.seed(42)  # For reproducibility\n",
    "\n",
    "mask = np.random.random(len(data)) < sample_fraction\n",
    "data.filter(mask)\n",
    "\n",
    "print(f\"Sampled dataset size: {len(data)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "id": "189aeaa1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample metadata:\n"
     ]
    },
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "station_network_code",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "station_code",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "trace_channel",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "station_latitude_deg",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "station_longitude_deg",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "station_elevation_m",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "trace_p_arrival_sample",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "trace_p_status",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "trace_p_weight",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "path_p_travel_sec",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "trace_s_arrival_sample",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "trace_s_status",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "trace_s_weight",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "source_id",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "source_origin_time",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "source_origin_uncertainty_sec",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "source_latitude_deg",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "source_longitude_deg",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "source_error_sec",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "source_gap_deg",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "source_horizontal_uncertainty_km",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "source_depth_km",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "source_depth_uncertainty_km",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "source_magnitude",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "source_magnitude_type",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "source_magnitude_author",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "source_mechanism_strike_dip_rake",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "source_distance_deg",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "source_distance_km",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "path_back_azimuth_deg",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "trace_snr_db",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "trace_coda_end_sample",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "trace_start_time",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "trace_category",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "trace_name",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "split",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "trace_name_original",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "trace_chunk",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "trace_sampling_rate_hz",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "trace_component_order",
         "rawType": "object",
         "type": "string"
        }
       ],
       "ref": "247c5a0d-4ab1-459f-b24f-72613659a239",
       "rows": [
        [
         "72",
         "72",
         "2V",
         "TG11",
         "EHE",
         "35.2689",
         "-97.8146",
         "407.0",
         "6000.0",
         "manual",
         "1.0",
         "7.999255",
         null,
         null,
         null,
         "evid",
         "2023-09-11T10:05:18.199999Z",
         null,
         "34.9565",
         "-97.56666667",
         null,
         null,
         null,
         "5.9",
         "0.5",
         "1.851274234",
         "ML",
         "ogs",
         null,
         "0.3721139183193918",
         "41.37717985094409",
         "146.8185031344373",
         null,
         null,
         "2023-09-11T10:04:26.195000Z",
         "earthquake_local",
         "bucket0$53,:3,:12001",
         "train",
         "2V.TG11.EHE.EHN.EHZ.2023-09-11T1004262023-09-11T100426",
         "",
         "100",
         "ZNE"
        ],
        [
         "128",
         "128",
         "2V",
         "TG11",
         "EHE",
         "35.2689",
         "-97.8146",
         "407.0",
         "6000.0",
         "manual",
         "1.0",
         "15.279521",
         null,
         null,
         null,
         "evid",
         "2023-10-15T03:02:56.189999Z",
         null,
         "34.49633333",
         "-97.7695",
         null,
         null,
         null,
         "5.86",
         "1.1",
         "2.138134913",
         "ML",
         "ogs",
         null,
         "0.7716758775082444",
         "85.80644259290473",
         "177.23298195135266",
         null,
         null,
         "2023-10-15T03:02:11.464999Z",
         "earthquake_local",
         "bucket0$97,:3,:12001",
         "train",
         "2V.TG11.EHE.EHN.EHZ.2023-10-15T0302112023-10-15T030211",
         "",
         "100",
         "ZNE"
        ],
        [
         "171",
         "171",
         "2V",
         "TG11",
         "EHE",
         "35.2689",
         "-97.8146",
         "407.0",
         "6000.0",
         "manual",
         "1.0",
         "3.686201",
         "6337.0",
         "manual",
         "1.0",
         "evid",
         "2023-11-02T09:09:27.600000Z",
         null,
         "35.27116667",
         "-98.009",
         null,
         null,
         null,
         "6.06",
         "0.9",
         "1.366909811",
         "ML",
         "ogs",
         null,
         "0.159087357802506",
         "17.689707080926333",
         "270.8706696998904",
         null,
         null,
         "2023-11-02T09:08:31.285000Z",
         "earthquake_local",
         "bucket0$124,:3,:12001",
         "train",
         "2V.TG11.EHE.EHN.EHZ.2023-11-02T0908312023-11-02T090831",
         "",
         "100",
         "ZNE"
        ],
        [
         "205",
         "205",
         "2V",
         "TG11",
         "EHE",
         "35.2689",
         "-97.8146",
         "407.0",
         "6000.0",
         "manual",
         "1.0",
         "5.895036",
         "6398.0",
         "manual",
         "1.0",
         "evid",
         "2023-11-29T04:46:12.179999Z",
         null,
         "35.1235",
         "-97.5595",
         null,
         null,
         null,
         "5.82",
         "0.6",
         "1.938046937",
         "ML",
         "ogs",
         null,
         "0.2543566934277529",
         "28.2831738672515",
         "124.70097872538592",
         null,
         null,
         "2023-11-29T04:45:18.075000Z",
         "earthquake_local",
         "bucket5$28,:3,:12001",
         "test",
         "2V.TG11.EHE.EHN.EHZ.2023-11-29T0445182023-11-29T044518",
         "",
         "100",
         "ZNE"
        ],
        [
         "208",
         "208",
         "2V",
         "TG11",
         "EHE",
         "35.2689",
         "-97.8146",
         "407.0",
         "5999.0",
         "manual",
         "1.0",
         "5.743603",
         "6316.0",
         "manual",
         "1.0",
         "evid",
         "2023-11-30T00:59:39.189999Z",
         null,
         "35.11833333",
         "-97.56483333",
         null,
         null,
         null,
         "5.23",
         "0.7",
         "1.275523264",
         "ML",
         "ogs",
         null,
         "0.2538032369602606",
         "28.221632315947737",
         "126.22016071899846",
         null,
         null,
         "2023-11-30T00:58:44.934999Z",
         "earthquake_local",
         "bucket0$153,:3,:12001",
         "train",
         "2V.TG11.EHE.EHN.EHZ.2023-11-30T0058442023-11-30T005844",
         "",
         "100",
         "ZNE"
        ],
        [
         "244",
         "244",
         "2V",
         "TG11",
         "EHE",
         "35.2689",
         "-97.8146",
         "407.0",
         "5999.0",
         "manual",
         "1.0",
         "7.131776",
         "7121.0",
         "manual",
         "1.0",
         "evid",
         "2023-12-13T15:06:05.000000Z",
         null,
         "36.36666667",
         "-98.17183333",
         null,
         null,
         null,
         "6.36",
         "0.7",
         "1.300762483",
         "ML",
         "ogs",
         null,
         "1.1332238714270026",
         "126.00874525518842",
         "345.2596281640694",
         null,
         null,
         "2023-12-13T15:05:12.134999Z",
         "earthquake_local",
         "bucket0$180,:3,:12001",
         "train",
         "2V.TG11.EHE.EHN.EHZ.2023-12-13T1505122023-12-13T150512",
         "",
         "100",
         "ZNE"
        ],
        [
         "332",
         "332",
         "2V",
         "TG11",
         "EHE",
         "35.2689",
         "-97.8146",
         "407.0",
         "6000.0",
         "manual",
         "1.0",
         "3.458511",
         "6280.0",
         "manual",
         "1.0",
         "evid",
         "2024-01-20T00:12:33.939999Z",
         null,
         "35.11933333",
         "-97.794",
         null,
         null,
         null,
         "6.79",
         "0.8",
         "1.177457872",
         "ML",
         "ogs",
         null,
         "0.150180087243014",
         "16.699263784460378",
         "173.54353017240646",
         null,
         null,
         "2024-01-20T00:11:37.395000Z",
         "earthquake_local",
         "bucket0$239,:3,:12001",
         "train",
         "2V.TG11.EHE.EHN.EHZ.2024-01-20T0011372024-01-20T001137",
         "",
         "100",
         "ZNE"
        ],
        [
         "371",
         "371",
         "2V",
         "TG11",
         "EHE",
         "35.2689",
         "-97.8146",
         "407.0",
         "5999.0",
         "manual",
         "1.0",
         "21.813191",
         "7556.0",
         "manual",
         "1.0",
         "evid",
         "2024-01-24T07:05:28.589999Z",
         null,
         "36.361",
         "-97.3535",
         null,
         null,
         null,
         "5.38",
         "0.5",
         "1.525009882",
         "ML",
         "ogs",
         null,
         "1.1523833054038244",
         "128.1391771107924",
         "18.84329635437248",
         null,
         null,
         "2024-01-24T07:04:50.404999Z",
         "earthquake_local",
         "bucket4$46,:3,:12001",
         "dev",
         "2V.TG11.EHE.EHN.EHZ.2024-01-24T0704502024-01-24T070450",
         "",
         "100",
         "ZNE"
        ],
        [
         "407",
         "407",
         "2V",
         "TG11",
         "EHE",
         "35.2689",
         "-97.8146",
         "407.0",
         "5999.0",
         "manual",
         "1.0",
         "16.81462",
         "7217.0",
         "manual",
         "1.0",
         "evid",
         "2024-02-03T09:45:12.320000Z",
         null,
         "35.52716667",
         "-96.772",
         null,
         null,
         null,
         "7.23",
         "0.4",
         "1.889505729",
         "ML",
         "ogs",
         null,
         "0.8899037688811747",
         "98.95278430145858",
         "72.86614337678692",
         null,
         null,
         "2024-02-03T09:44:29.134999Z",
         "earthquake_local",
         "bucket0$294,:3,:12001",
         "train",
         "2V.TG11.EHE.EHN.EHZ.2024-02-03T0944292024-02-03T094429",
         "",
         "100",
         "ZNE"
        ],
        [
         "456",
         "456",
         "2V",
         "TG11",
         "EHE",
         "35.2689",
         "-97.8146",
         "407.0",
         "6000.0",
         "manual",
         "1.0",
         "3.235955",
         "6244.0",
         "manual",
         "1.0",
         "evid",
         "2024-02-12T03:22:05.450000Z",
         null,
         "35.13433333",
         "-97.7965",
         null,
         null,
         null,
         "0.69",
         "0.3",
         "0.4125726209",
         "ML",
         "ogs",
         null,
         "0.13507910885247",
         "15.020111600062766",
         "173.69466213666294",
         null,
         null,
         "2024-02-12T03:21:08.685000Z",
         "earthquake_local",
         "bucket0$328,:3,:12001",
         "train",
         "2V.TG11.EHE.EHN.EHZ.2024-02-12T0321082024-02-12T032108",
         "",
         "100",
         "ZNE"
        ],
        [
         "470",
         "470",
         "2V",
         "TG11",
         "EHE",
         "35.2689",
         "-97.8146",
         "407.0",
         "6000.0",
         "manual",
         "1.0",
         "17.218245",
         "7249.0",
         "manual",
         "1.0",
         "evid",
         "2024-02-22T10:36:14.640000Z",
         null,
         "35.53066667",
         "-96.75683333",
         null,
         null,
         null,
         "6.0",
         "0.3",
         "1.915578795",
         "ML",
         "ogs",
         null,
         "0.9027569372466572",
         "100.38199141500856",
         "72.8769797162021",
         null,
         null,
         "2024-02-22T10:35:31.855000Z",
         "earthquake_local",
         "bucket4$57,:3,:12001",
         "dev",
         "2V.TG11.EHE.EHN.EHZ.2024-02-22T1035312024-02-22T103531",
         "",
         "100",
         "ZNE"
        ],
        [
         "563",
         "563",
         "2V",
         "TG11",
         "EHE",
         "35.2689",
         "-97.8146",
         "407.0",
         "5999.0",
         "manual",
         "1.0",
         "1.65928",
         "6126.0",
         "manual",
         "1.0",
         "evid",
         "2024-04-17T08:50:12.720000Z",
         null,
         "35.24383333",
         "-97.76433333",
         null,
         null,
         null,
         "5.29",
         "0.5",
         "0.5469062176",
         "ML",
         "ogs",
         null,
         "0.0481445437793324",
         "5.35342901387862",
         "121.28323430641262",
         null,
         null,
         "2024-04-17T08:49:14.380000Z",
         "earthquake_local",
         "bucket4$64,:3,:12001",
         "dev",
         "2V.TG11.EHE.EHN.EHZ.2024-04-17T0849142024-04-17T084914",
         "",
         "100",
         "ZNE"
        ],
        [
         "794",
         "794",
         "2V",
         "TG11",
         "EHE",
         "35.2689",
         "-97.8146",
         "407.0",
         "6000.0",
         "manual",
         "1.0",
         "3.732982",
         "6303.0",
         "manual",
         "1.0",
         "evid",
         "2024-07-28T00:02:26.829999Z",
         null,
         "35.35566667",
         "-97.98083333",
         null,
         null,
         null,
         "8.06",
         "1.2",
         "0.7594600563",
         "ML",
         "ogs",
         null,
         "0.1611768182590494",
         "17.922044483118373",
         "302.53639264065697",
         null,
         null,
         "2024-07-28T00:01:30.560000Z",
         "earthquake_local",
         "bucket0$574,:3,:12001",
         "train",
         "2V.TG11.EHE.EHN.EHZ.2024-07-28T0001302024-07-28T000130",
         "",
         "100",
         "ZNE"
        ],
        [
         "821",
         "821",
         "2V",
         "TG11",
         "EHE",
         "35.2689",
         "-97.8146",
         "407.0",
         "5999.0",
         "manual",
         "1.0",
         "3.638988",
         "6282.0",
         "manual",
         "1.0",
         "evid",
         "2024-08-03T03:23:25.059999Z",
         null,
         "35.3535",
         "-97.97916667",
         null,
         null,
         null,
         "7.36",
         "0.5",
         "0.7711076664",
         "ML",
         "ogs",
         null,
         "0.1588711561011473",
         "17.665666548603316",
         "302.1419638747849",
         null,
         null,
         "2024-08-03T03:22:28.699999Z",
         "earthquake_local",
         "bucket0$593,:3,:12001",
         "train",
         "2V.TG11.EHE.EHN.EHZ.2024-08-03T0322282024-08-03T032228",
         "",
         "100",
         "ZNE"
        ],
        [
         "840",
         "840",
         "2V",
         "TG11",
         "EHE",
         "35.2689",
         "-97.8146",
         "407.0",
         "6000.0",
         "manual",
         "1.0",
         "3.534527",
         "6255.0",
         "manual",
         "1.0",
         "evid",
         "2024-08-09T00:59:57.619999Z",
         null,
         "35.36333333",
         "-97.95566667",
         null,
         null,
         null,
         "7.33",
         "0.6",
         "1.219516432",
         "ML",
         "ogs",
         null,
         "0.148952648087142",
         "16.562778777562528",
         "309.2803714577832",
         null,
         null,
         "2024-08-09T00:59:01.149999Z",
         "earthquake_local",
         "bucket5$137,:3,:12001",
         "test",
         "2V.TG11.EHE.EHN.EHZ.2024-08-09T0059012024-08-09T005901",
         "",
         "100",
         "ZNE"
        ],
        [
         "882",
         "882",
         "2V",
         "TG11",
         "EHE",
         "35.2689",
         "-97.8146",
         "407.0",
         "6000.0",
         "manual",
         "1.0",
         "3.621023",
         "6278.0",
         "manual",
         "1.0",
         "evid",
         "2024-08-11T23:22:46.380000Z",
         null,
         "35.358",
         "-97.97383333",
         null,
         null,
         null,
         "7.72",
         "0.4",
         "1.334700014",
         "ML",
         "ogs",
         null,
         "0.1576773542865499",
         "17.532921843401013",
         "304.3660095908959",
         null,
         null,
         "2024-08-11T23:21:50.000000Z",
         "earthquake_local",
         "bucket4$105,:3,:12001",
         "dev",
         "2V.TG11.EHE.EHN.EHZ.2024-08-11T2321502024-08-11T232150",
         "",
         "100",
         "ZNE"
        ],
        [
         "898",
         "898",
         "2V",
         "TG11",
         "EHE",
         "35.2689",
         "-97.8146",
         "407.0",
         "5999.0",
         "manual",
         "1.0",
         "3.268471",
         "6277.0",
         "manual",
         "1.0",
         "evid",
         "2024-08-14T02:19:26.149999Z",
         null,
         "35.34583333",
         "-97.96716667",
         null,
         null,
         null,
         "7.23",
         "0.5",
         "1.425536336",
         "ML",
         "ogs",
         null,
         "0.1465029355564055",
         "16.290383172407026",
         "301.6421258196797",
         null,
         null,
         "2024-08-14T02:18:29.419999Z",
         "earthquake_local",
         "bucket0$642,:3,:12001",
         "train",
         "2V.TG11.EHE.EHN.EHZ.2024-08-14T0218292024-08-14T021829",
         "",
         "100",
         "ZNE"
        ],
        [
         "936",
         "936",
         "2V",
         "TG11",
         "EHE",
         "35.2689",
         "-97.8146",
         "407.0",
         "5999.0",
         "manual",
         "1.0",
         "6.255804",
         "6493.0",
         "manual",
         "1.0",
         "evid",
         "2024-08-21T11:02:35.619999Z",
         null,
         "35.14533333",
         "-97.46383333",
         null,
         null,
         null,
         "6.56",
         "0.4",
         "1.531052455",
         "ML",
         "ogs",
         null,
         "0.3125832787697678",
         "34.757674753119986",
         "113.12843014973286",
         null,
         null,
         "2024-08-21T11:01:41.879999Z",
         "earthquake_local",
         "bucket0$667,:3,:12001",
         "train",
         "2V.TG11.EHE.EHN.EHZ.2024-08-21T1101412024-08-21T110141",
         "",
         "100",
         "ZNE"
        ],
        [
         "945",
         "945",
         "2V",
         "TG11",
         "EHE",
         "35.2689",
         "-97.8146",
         "407.0",
         "6000.0",
         "manual",
         "1.0",
         "5.911129",
         null,
         null,
         null,
         "evid",
         "2024-08-25T18:59:15.900000Z",
         null,
         "35.01183333",
         "-97.79383333",
         null,
         null,
         null,
         "10.91",
         "1.4",
         "0.7744678188",
         "ML",
         "ogs",
         null,
         "0.2570486662890843",
         "28.582507592096384",
         "176.19756833151112",
         null,
         null,
         "2024-08-25T18:58:21.809999Z",
         "earthquake_local",
         "bucket0$672,:3,:12001",
         "train",
         "2V.TG11.EHE.EHN.EHZ.2024-08-25T1858212024-08-25T185821",
         "",
         "100",
         "ZNE"
        ],
        [
         "1073",
         "1073",
         "2V",
         "TG11",
         "EHE",
         "35.2689",
         "-97.8146",
         "407.0",
         "5999.0",
         "manual",
         "1.0",
         "13.356682",
         "7047.0",
         "manual",
         "1.0",
         "evid",
         "2024-12-07T07:54:46.119999Z",
         null,
         "35.98",
         "-97.96933333",
         null,
         null,
         null,
         "5.6",
         "0.4",
         "1.588577144",
         "ML",
         "ogs",
         null,
         "0.720657471198957",
         "80.13345464582122",
         "349.97083240657616",
         null,
         null,
         "2024-12-07T07:53:59.479999Z",
         "earthquake_local",
         "bucket0$761,:3,:12001",
         "train",
         "2V.TG11.EHE.EHN.EHZ.2024-12-07T0753592024-12-07T075359",
         "",
         "100",
         "ZNE"
        ]
       ],
       "shape": {
        "columns": 41,
        "rows": 20
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>station_network_code</th>\n",
       "      <th>station_code</th>\n",
       "      <th>trace_channel</th>\n",
       "      <th>station_latitude_deg</th>\n",
       "      <th>station_longitude_deg</th>\n",
       "      <th>station_elevation_m</th>\n",
       "      <th>trace_p_arrival_sample</th>\n",
       "      <th>trace_p_status</th>\n",
       "      <th>trace_p_weight</th>\n",
       "      <th>...</th>\n",
       "      <th>trace_snr_db</th>\n",
       "      <th>trace_coda_end_sample</th>\n",
       "      <th>trace_start_time</th>\n",
       "      <th>trace_category</th>\n",
       "      <th>trace_name</th>\n",
       "      <th>split</th>\n",
       "      <th>trace_name_original</th>\n",
       "      <th>trace_chunk</th>\n",
       "      <th>trace_sampling_rate_hz</th>\n",
       "      <th>trace_component_order</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>72</td>\n",
       "      <td>2V</td>\n",
       "      <td>TG11</td>\n",
       "      <td>EHE</td>\n",
       "      <td>35.2689</td>\n",
       "      <td>-97.8146</td>\n",
       "      <td>407.0</td>\n",
       "      <td>6000.0</td>\n",
       "      <td>manual</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2023-09-11T10:04:26.195000Z</td>\n",
       "      <td>earthquake_local</td>\n",
       "      <td>bucket0$53,:3,:12001</td>\n",
       "      <td>train</td>\n",
       "      <td>2V.TG11.EHE.EHN.EHZ.2023-09-11T1004262023-09-1...</td>\n",
       "      <td></td>\n",
       "      <td>100</td>\n",
       "      <td>ZNE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128</th>\n",
       "      <td>128</td>\n",
       "      <td>2V</td>\n",
       "      <td>TG11</td>\n",
       "      <td>EHE</td>\n",
       "      <td>35.2689</td>\n",
       "      <td>-97.8146</td>\n",
       "      <td>407.0</td>\n",
       "      <td>6000.0</td>\n",
       "      <td>manual</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2023-10-15T03:02:11.464999Z</td>\n",
       "      <td>earthquake_local</td>\n",
       "      <td>bucket0$97,:3,:12001</td>\n",
       "      <td>train</td>\n",
       "      <td>2V.TG11.EHE.EHN.EHZ.2023-10-15T0302112023-10-1...</td>\n",
       "      <td></td>\n",
       "      <td>100</td>\n",
       "      <td>ZNE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>171</th>\n",
       "      <td>171</td>\n",
       "      <td>2V</td>\n",
       "      <td>TG11</td>\n",
       "      <td>EHE</td>\n",
       "      <td>35.2689</td>\n",
       "      <td>-97.8146</td>\n",
       "      <td>407.0</td>\n",
       "      <td>6000.0</td>\n",
       "      <td>manual</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2023-11-02T09:08:31.285000Z</td>\n",
       "      <td>earthquake_local</td>\n",
       "      <td>bucket0$124,:3,:12001</td>\n",
       "      <td>train</td>\n",
       "      <td>2V.TG11.EHE.EHN.EHZ.2023-11-02T0908312023-11-0...</td>\n",
       "      <td></td>\n",
       "      <td>100</td>\n",
       "      <td>ZNE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>205</th>\n",
       "      <td>205</td>\n",
       "      <td>2V</td>\n",
       "      <td>TG11</td>\n",
       "      <td>EHE</td>\n",
       "      <td>35.2689</td>\n",
       "      <td>-97.8146</td>\n",
       "      <td>407.0</td>\n",
       "      <td>6000.0</td>\n",
       "      <td>manual</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2023-11-29T04:45:18.075000Z</td>\n",
       "      <td>earthquake_local</td>\n",
       "      <td>bucket5$28,:3,:12001</td>\n",
       "      <td>test</td>\n",
       "      <td>2V.TG11.EHE.EHN.EHZ.2023-11-29T0445182023-11-2...</td>\n",
       "      <td></td>\n",
       "      <td>100</td>\n",
       "      <td>ZNE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>208</th>\n",
       "      <td>208</td>\n",
       "      <td>2V</td>\n",
       "      <td>TG11</td>\n",
       "      <td>EHE</td>\n",
       "      <td>35.2689</td>\n",
       "      <td>-97.8146</td>\n",
       "      <td>407.0</td>\n",
       "      <td>5999.0</td>\n",
       "      <td>manual</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2023-11-30T00:58:44.934999Z</td>\n",
       "      <td>earthquake_local</td>\n",
       "      <td>bucket0$153,:3,:12001</td>\n",
       "      <td>train</td>\n",
       "      <td>2V.TG11.EHE.EHN.EHZ.2023-11-30T0058442023-11-3...</td>\n",
       "      <td></td>\n",
       "      <td>100</td>\n",
       "      <td>ZNE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>244</th>\n",
       "      <td>244</td>\n",
       "      <td>2V</td>\n",
       "      <td>TG11</td>\n",
       "      <td>EHE</td>\n",
       "      <td>35.2689</td>\n",
       "      <td>-97.8146</td>\n",
       "      <td>407.0</td>\n",
       "      <td>5999.0</td>\n",
       "      <td>manual</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2023-12-13T15:05:12.134999Z</td>\n",
       "      <td>earthquake_local</td>\n",
       "      <td>bucket0$180,:3,:12001</td>\n",
       "      <td>train</td>\n",
       "      <td>2V.TG11.EHE.EHN.EHZ.2023-12-13T1505122023-12-1...</td>\n",
       "      <td></td>\n",
       "      <td>100</td>\n",
       "      <td>ZNE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>332</th>\n",
       "      <td>332</td>\n",
       "      <td>2V</td>\n",
       "      <td>TG11</td>\n",
       "      <td>EHE</td>\n",
       "      <td>35.2689</td>\n",
       "      <td>-97.8146</td>\n",
       "      <td>407.0</td>\n",
       "      <td>6000.0</td>\n",
       "      <td>manual</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2024-01-20T00:11:37.395000Z</td>\n",
       "      <td>earthquake_local</td>\n",
       "      <td>bucket0$239,:3,:12001</td>\n",
       "      <td>train</td>\n",
       "      <td>2V.TG11.EHE.EHN.EHZ.2024-01-20T0011372024-01-2...</td>\n",
       "      <td></td>\n",
       "      <td>100</td>\n",
       "      <td>ZNE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>371</th>\n",
       "      <td>371</td>\n",
       "      <td>2V</td>\n",
       "      <td>TG11</td>\n",
       "      <td>EHE</td>\n",
       "      <td>35.2689</td>\n",
       "      <td>-97.8146</td>\n",
       "      <td>407.0</td>\n",
       "      <td>5999.0</td>\n",
       "      <td>manual</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2024-01-24T07:04:50.404999Z</td>\n",
       "      <td>earthquake_local</td>\n",
       "      <td>bucket4$46,:3,:12001</td>\n",
       "      <td>dev</td>\n",
       "      <td>2V.TG11.EHE.EHN.EHZ.2024-01-24T0704502024-01-2...</td>\n",
       "      <td></td>\n",
       "      <td>100</td>\n",
       "      <td>ZNE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>407</th>\n",
       "      <td>407</td>\n",
       "      <td>2V</td>\n",
       "      <td>TG11</td>\n",
       "      <td>EHE</td>\n",
       "      <td>35.2689</td>\n",
       "      <td>-97.8146</td>\n",
       "      <td>407.0</td>\n",
       "      <td>5999.0</td>\n",
       "      <td>manual</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2024-02-03T09:44:29.134999Z</td>\n",
       "      <td>earthquake_local</td>\n",
       "      <td>bucket0$294,:3,:12001</td>\n",
       "      <td>train</td>\n",
       "      <td>2V.TG11.EHE.EHN.EHZ.2024-02-03T0944292024-02-0...</td>\n",
       "      <td></td>\n",
       "      <td>100</td>\n",
       "      <td>ZNE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>456</th>\n",
       "      <td>456</td>\n",
       "      <td>2V</td>\n",
       "      <td>TG11</td>\n",
       "      <td>EHE</td>\n",
       "      <td>35.2689</td>\n",
       "      <td>-97.8146</td>\n",
       "      <td>407.0</td>\n",
       "      <td>6000.0</td>\n",
       "      <td>manual</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2024-02-12T03:21:08.685000Z</td>\n",
       "      <td>earthquake_local</td>\n",
       "      <td>bucket0$328,:3,:12001</td>\n",
       "      <td>train</td>\n",
       "      <td>2V.TG11.EHE.EHN.EHZ.2024-02-12T0321082024-02-1...</td>\n",
       "      <td></td>\n",
       "      <td>100</td>\n",
       "      <td>ZNE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>470</th>\n",
       "      <td>470</td>\n",
       "      <td>2V</td>\n",
       "      <td>TG11</td>\n",
       "      <td>EHE</td>\n",
       "      <td>35.2689</td>\n",
       "      <td>-97.8146</td>\n",
       "      <td>407.0</td>\n",
       "      <td>6000.0</td>\n",
       "      <td>manual</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2024-02-22T10:35:31.855000Z</td>\n",
       "      <td>earthquake_local</td>\n",
       "      <td>bucket4$57,:3,:12001</td>\n",
       "      <td>dev</td>\n",
       "      <td>2V.TG11.EHE.EHN.EHZ.2024-02-22T1035312024-02-2...</td>\n",
       "      <td></td>\n",
       "      <td>100</td>\n",
       "      <td>ZNE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>563</th>\n",
       "      <td>563</td>\n",
       "      <td>2V</td>\n",
       "      <td>TG11</td>\n",
       "      <td>EHE</td>\n",
       "      <td>35.2689</td>\n",
       "      <td>-97.8146</td>\n",
       "      <td>407.0</td>\n",
       "      <td>5999.0</td>\n",
       "      <td>manual</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2024-04-17T08:49:14.380000Z</td>\n",
       "      <td>earthquake_local</td>\n",
       "      <td>bucket4$64,:3,:12001</td>\n",
       "      <td>dev</td>\n",
       "      <td>2V.TG11.EHE.EHN.EHZ.2024-04-17T0849142024-04-1...</td>\n",
       "      <td></td>\n",
       "      <td>100</td>\n",
       "      <td>ZNE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>794</th>\n",
       "      <td>794</td>\n",
       "      <td>2V</td>\n",
       "      <td>TG11</td>\n",
       "      <td>EHE</td>\n",
       "      <td>35.2689</td>\n",
       "      <td>-97.8146</td>\n",
       "      <td>407.0</td>\n",
       "      <td>6000.0</td>\n",
       "      <td>manual</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2024-07-28T00:01:30.560000Z</td>\n",
       "      <td>earthquake_local</td>\n",
       "      <td>bucket0$574,:3,:12001</td>\n",
       "      <td>train</td>\n",
       "      <td>2V.TG11.EHE.EHN.EHZ.2024-07-28T0001302024-07-2...</td>\n",
       "      <td></td>\n",
       "      <td>100</td>\n",
       "      <td>ZNE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>821</th>\n",
       "      <td>821</td>\n",
       "      <td>2V</td>\n",
       "      <td>TG11</td>\n",
       "      <td>EHE</td>\n",
       "      <td>35.2689</td>\n",
       "      <td>-97.8146</td>\n",
       "      <td>407.0</td>\n",
       "      <td>5999.0</td>\n",
       "      <td>manual</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2024-08-03T03:22:28.699999Z</td>\n",
       "      <td>earthquake_local</td>\n",
       "      <td>bucket0$593,:3,:12001</td>\n",
       "      <td>train</td>\n",
       "      <td>2V.TG11.EHE.EHN.EHZ.2024-08-03T0322282024-08-0...</td>\n",
       "      <td></td>\n",
       "      <td>100</td>\n",
       "      <td>ZNE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>840</th>\n",
       "      <td>840</td>\n",
       "      <td>2V</td>\n",
       "      <td>TG11</td>\n",
       "      <td>EHE</td>\n",
       "      <td>35.2689</td>\n",
       "      <td>-97.8146</td>\n",
       "      <td>407.0</td>\n",
       "      <td>6000.0</td>\n",
       "      <td>manual</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2024-08-09T00:59:01.149999Z</td>\n",
       "      <td>earthquake_local</td>\n",
       "      <td>bucket5$137,:3,:12001</td>\n",
       "      <td>test</td>\n",
       "      <td>2V.TG11.EHE.EHN.EHZ.2024-08-09T0059012024-08-0...</td>\n",
       "      <td></td>\n",
       "      <td>100</td>\n",
       "      <td>ZNE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>882</th>\n",
       "      <td>882</td>\n",
       "      <td>2V</td>\n",
       "      <td>TG11</td>\n",
       "      <td>EHE</td>\n",
       "      <td>35.2689</td>\n",
       "      <td>-97.8146</td>\n",
       "      <td>407.0</td>\n",
       "      <td>6000.0</td>\n",
       "      <td>manual</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2024-08-11T23:21:50.000000Z</td>\n",
       "      <td>earthquake_local</td>\n",
       "      <td>bucket4$105,:3,:12001</td>\n",
       "      <td>dev</td>\n",
       "      <td>2V.TG11.EHE.EHN.EHZ.2024-08-11T2321502024-08-1...</td>\n",
       "      <td></td>\n",
       "      <td>100</td>\n",
       "      <td>ZNE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>898</th>\n",
       "      <td>898</td>\n",
       "      <td>2V</td>\n",
       "      <td>TG11</td>\n",
       "      <td>EHE</td>\n",
       "      <td>35.2689</td>\n",
       "      <td>-97.8146</td>\n",
       "      <td>407.0</td>\n",
       "      <td>5999.0</td>\n",
       "      <td>manual</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2024-08-14T02:18:29.419999Z</td>\n",
       "      <td>earthquake_local</td>\n",
       "      <td>bucket0$642,:3,:12001</td>\n",
       "      <td>train</td>\n",
       "      <td>2V.TG11.EHE.EHN.EHZ.2024-08-14T0218292024-08-1...</td>\n",
       "      <td></td>\n",
       "      <td>100</td>\n",
       "      <td>ZNE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>936</th>\n",
       "      <td>936</td>\n",
       "      <td>2V</td>\n",
       "      <td>TG11</td>\n",
       "      <td>EHE</td>\n",
       "      <td>35.2689</td>\n",
       "      <td>-97.8146</td>\n",
       "      <td>407.0</td>\n",
       "      <td>5999.0</td>\n",
       "      <td>manual</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2024-08-21T11:01:41.879999Z</td>\n",
       "      <td>earthquake_local</td>\n",
       "      <td>bucket0$667,:3,:12001</td>\n",
       "      <td>train</td>\n",
       "      <td>2V.TG11.EHE.EHN.EHZ.2024-08-21T1101412024-08-2...</td>\n",
       "      <td></td>\n",
       "      <td>100</td>\n",
       "      <td>ZNE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>945</th>\n",
       "      <td>945</td>\n",
       "      <td>2V</td>\n",
       "      <td>TG11</td>\n",
       "      <td>EHE</td>\n",
       "      <td>35.2689</td>\n",
       "      <td>-97.8146</td>\n",
       "      <td>407.0</td>\n",
       "      <td>6000.0</td>\n",
       "      <td>manual</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2024-08-25T18:58:21.809999Z</td>\n",
       "      <td>earthquake_local</td>\n",
       "      <td>bucket0$672,:3,:12001</td>\n",
       "      <td>train</td>\n",
       "      <td>2V.TG11.EHE.EHN.EHZ.2024-08-25T1858212024-08-2...</td>\n",
       "      <td></td>\n",
       "      <td>100</td>\n",
       "      <td>ZNE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1073</th>\n",
       "      <td>1073</td>\n",
       "      <td>2V</td>\n",
       "      <td>TG11</td>\n",
       "      <td>EHE</td>\n",
       "      <td>35.2689</td>\n",
       "      <td>-97.8146</td>\n",
       "      <td>407.0</td>\n",
       "      <td>5999.0</td>\n",
       "      <td>manual</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2024-12-07T07:53:59.479999Z</td>\n",
       "      <td>earthquake_local</td>\n",
       "      <td>bucket0$761,:3,:12001</td>\n",
       "      <td>train</td>\n",
       "      <td>2V.TG11.EHE.EHN.EHZ.2024-12-07T0753592024-12-0...</td>\n",
       "      <td></td>\n",
       "      <td>100</td>\n",
       "      <td>ZNE</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>20 rows × 41 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      index station_network_code station_code trace_channel  \\\n",
       "72       72                   2V         TG11           EHE   \n",
       "128     128                   2V         TG11           EHE   \n",
       "171     171                   2V         TG11           EHE   \n",
       "205     205                   2V         TG11           EHE   \n",
       "208     208                   2V         TG11           EHE   \n",
       "244     244                   2V         TG11           EHE   \n",
       "332     332                   2V         TG11           EHE   \n",
       "371     371                   2V         TG11           EHE   \n",
       "407     407                   2V         TG11           EHE   \n",
       "456     456                   2V         TG11           EHE   \n",
       "470     470                   2V         TG11           EHE   \n",
       "563     563                   2V         TG11           EHE   \n",
       "794     794                   2V         TG11           EHE   \n",
       "821     821                   2V         TG11           EHE   \n",
       "840     840                   2V         TG11           EHE   \n",
       "882     882                   2V         TG11           EHE   \n",
       "898     898                   2V         TG11           EHE   \n",
       "936     936                   2V         TG11           EHE   \n",
       "945     945                   2V         TG11           EHE   \n",
       "1073   1073                   2V         TG11           EHE   \n",
       "\n",
       "      station_latitude_deg  station_longitude_deg  station_elevation_m  \\\n",
       "72                 35.2689               -97.8146                407.0   \n",
       "128                35.2689               -97.8146                407.0   \n",
       "171                35.2689               -97.8146                407.0   \n",
       "205                35.2689               -97.8146                407.0   \n",
       "208                35.2689               -97.8146                407.0   \n",
       "244                35.2689               -97.8146                407.0   \n",
       "332                35.2689               -97.8146                407.0   \n",
       "371                35.2689               -97.8146                407.0   \n",
       "407                35.2689               -97.8146                407.0   \n",
       "456                35.2689               -97.8146                407.0   \n",
       "470                35.2689               -97.8146                407.0   \n",
       "563                35.2689               -97.8146                407.0   \n",
       "794                35.2689               -97.8146                407.0   \n",
       "821                35.2689               -97.8146                407.0   \n",
       "840                35.2689               -97.8146                407.0   \n",
       "882                35.2689               -97.8146                407.0   \n",
       "898                35.2689               -97.8146                407.0   \n",
       "936                35.2689               -97.8146                407.0   \n",
       "945                35.2689               -97.8146                407.0   \n",
       "1073               35.2689               -97.8146                407.0   \n",
       "\n",
       "      trace_p_arrival_sample trace_p_status  trace_p_weight  ...  \\\n",
       "72                    6000.0         manual             1.0  ...   \n",
       "128                   6000.0         manual             1.0  ...   \n",
       "171                   6000.0         manual             1.0  ...   \n",
       "205                   6000.0         manual             1.0  ...   \n",
       "208                   5999.0         manual             1.0  ...   \n",
       "244                   5999.0         manual             1.0  ...   \n",
       "332                   6000.0         manual             1.0  ...   \n",
       "371                   5999.0         manual             1.0  ...   \n",
       "407                   5999.0         manual             1.0  ...   \n",
       "456                   6000.0         manual             1.0  ...   \n",
       "470                   6000.0         manual             1.0  ...   \n",
       "563                   5999.0         manual             1.0  ...   \n",
       "794                   6000.0         manual             1.0  ...   \n",
       "821                   5999.0         manual             1.0  ...   \n",
       "840                   6000.0         manual             1.0  ...   \n",
       "882                   6000.0         manual             1.0  ...   \n",
       "898                   5999.0         manual             1.0  ...   \n",
       "936                   5999.0         manual             1.0  ...   \n",
       "945                   6000.0         manual             1.0  ...   \n",
       "1073                  5999.0         manual             1.0  ...   \n",
       "\n",
       "      trace_snr_db  trace_coda_end_sample             trace_start_time  \\\n",
       "72             NaN                    NaN  2023-09-11T10:04:26.195000Z   \n",
       "128            NaN                    NaN  2023-10-15T03:02:11.464999Z   \n",
       "171            NaN                    NaN  2023-11-02T09:08:31.285000Z   \n",
       "205            NaN                    NaN  2023-11-29T04:45:18.075000Z   \n",
       "208            NaN                    NaN  2023-11-30T00:58:44.934999Z   \n",
       "244            NaN                    NaN  2023-12-13T15:05:12.134999Z   \n",
       "332            NaN                    NaN  2024-01-20T00:11:37.395000Z   \n",
       "371            NaN                    NaN  2024-01-24T07:04:50.404999Z   \n",
       "407            NaN                    NaN  2024-02-03T09:44:29.134999Z   \n",
       "456            NaN                    NaN  2024-02-12T03:21:08.685000Z   \n",
       "470            NaN                    NaN  2024-02-22T10:35:31.855000Z   \n",
       "563            NaN                    NaN  2024-04-17T08:49:14.380000Z   \n",
       "794            NaN                    NaN  2024-07-28T00:01:30.560000Z   \n",
       "821            NaN                    NaN  2024-08-03T03:22:28.699999Z   \n",
       "840            NaN                    NaN  2024-08-09T00:59:01.149999Z   \n",
       "882            NaN                    NaN  2024-08-11T23:21:50.000000Z   \n",
       "898            NaN                    NaN  2024-08-14T02:18:29.419999Z   \n",
       "936            NaN                    NaN  2024-08-21T11:01:41.879999Z   \n",
       "945            NaN                    NaN  2024-08-25T18:58:21.809999Z   \n",
       "1073           NaN                    NaN  2024-12-07T07:53:59.479999Z   \n",
       "\n",
       "        trace_category             trace_name  split  \\\n",
       "72    earthquake_local   bucket0$53,:3,:12001  train   \n",
       "128   earthquake_local   bucket0$97,:3,:12001  train   \n",
       "171   earthquake_local  bucket0$124,:3,:12001  train   \n",
       "205   earthquake_local   bucket5$28,:3,:12001   test   \n",
       "208   earthquake_local  bucket0$153,:3,:12001  train   \n",
       "244   earthquake_local  bucket0$180,:3,:12001  train   \n",
       "332   earthquake_local  bucket0$239,:3,:12001  train   \n",
       "371   earthquake_local   bucket4$46,:3,:12001    dev   \n",
       "407   earthquake_local  bucket0$294,:3,:12001  train   \n",
       "456   earthquake_local  bucket0$328,:3,:12001  train   \n",
       "470   earthquake_local   bucket4$57,:3,:12001    dev   \n",
       "563   earthquake_local   bucket4$64,:3,:12001    dev   \n",
       "794   earthquake_local  bucket0$574,:3,:12001  train   \n",
       "821   earthquake_local  bucket0$593,:3,:12001  train   \n",
       "840   earthquake_local  bucket5$137,:3,:12001   test   \n",
       "882   earthquake_local  bucket4$105,:3,:12001    dev   \n",
       "898   earthquake_local  bucket0$642,:3,:12001  train   \n",
       "936   earthquake_local  bucket0$667,:3,:12001  train   \n",
       "945   earthquake_local  bucket0$672,:3,:12001  train   \n",
       "1073  earthquake_local  bucket0$761,:3,:12001  train   \n",
       "\n",
       "                                    trace_name_original  trace_chunk  \\\n",
       "72    2V.TG11.EHE.EHN.EHZ.2023-09-11T1004262023-09-1...                \n",
       "128   2V.TG11.EHE.EHN.EHZ.2023-10-15T0302112023-10-1...                \n",
       "171   2V.TG11.EHE.EHN.EHZ.2023-11-02T0908312023-11-0...                \n",
       "205   2V.TG11.EHE.EHN.EHZ.2023-11-29T0445182023-11-2...                \n",
       "208   2V.TG11.EHE.EHN.EHZ.2023-11-30T0058442023-11-3...                \n",
       "244   2V.TG11.EHE.EHN.EHZ.2023-12-13T1505122023-12-1...                \n",
       "332   2V.TG11.EHE.EHN.EHZ.2024-01-20T0011372024-01-2...                \n",
       "371   2V.TG11.EHE.EHN.EHZ.2024-01-24T0704502024-01-2...                \n",
       "407   2V.TG11.EHE.EHN.EHZ.2024-02-03T0944292024-02-0...                \n",
       "456   2V.TG11.EHE.EHN.EHZ.2024-02-12T0321082024-02-1...                \n",
       "470   2V.TG11.EHE.EHN.EHZ.2024-02-22T1035312024-02-2...                \n",
       "563   2V.TG11.EHE.EHN.EHZ.2024-04-17T0849142024-04-1...                \n",
       "794   2V.TG11.EHE.EHN.EHZ.2024-07-28T0001302024-07-2...                \n",
       "821   2V.TG11.EHE.EHN.EHZ.2024-08-03T0322282024-08-0...                \n",
       "840   2V.TG11.EHE.EHN.EHZ.2024-08-09T0059012024-08-0...                \n",
       "882   2V.TG11.EHE.EHN.EHZ.2024-08-11T2321502024-08-1...                \n",
       "898   2V.TG11.EHE.EHN.EHZ.2024-08-14T0218292024-08-1...                \n",
       "936   2V.TG11.EHE.EHN.EHZ.2024-08-21T1101412024-08-2...                \n",
       "945   2V.TG11.EHE.EHN.EHZ.2024-08-25T1858212024-08-2...                \n",
       "1073  2V.TG11.EHE.EHN.EHZ.2024-12-07T0753592024-12-0...                \n",
       "\n",
       "      trace_sampling_rate_hz  trace_component_order  \n",
       "72                       100                    ZNE  \n",
       "128                      100                    ZNE  \n",
       "171                      100                    ZNE  \n",
       "205                      100                    ZNE  \n",
       "208                      100                    ZNE  \n",
       "244                      100                    ZNE  \n",
       "332                      100                    ZNE  \n",
       "371                      100                    ZNE  \n",
       "407                      100                    ZNE  \n",
       "456                      100                    ZNE  \n",
       "470                      100                    ZNE  \n",
       "563                      100                    ZNE  \n",
       "794                      100                    ZNE  \n",
       "821                      100                    ZNE  \n",
       "840                      100                    ZNE  \n",
       "882                      100                    ZNE  \n",
       "898                      100                    ZNE  \n",
       "936                      100                    ZNE  \n",
       "945                      100                    ZNE  \n",
       "1073                     100                    ZNE  \n",
       "\n",
       "[20 rows x 41 columns]"
      ]
     },
     "execution_count": 199,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Sample metadata:\")\n",
    "data.metadata.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "id": "935662b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data\n",
    "train, dev, test = data.train_dev_test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "id": "0d00a4a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: OKLA_1Mil_120s_Ver_3 - 15909 traces\n",
      "Dev: OKLA_1Mil_120s_Ver_3 - 3429 traces\n",
      "Test: OKLA_1Mil_120s_Ver_3 - 3444 traces\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(\"Train:\", train)\n",
    "print(\"Dev:\", dev)\n",
    "print(\"Test:\", test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "id": "7b87844d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up data augmentation\n",
    "\n",
    "phase_dict = {\n",
    "    \"trace_p_arrival_sample\": \"P\",\n",
    "    \"trace_pP_arrival_sample\": \"P\",\n",
    "    \"trace_P_arrival_sample\": \"P\",\n",
    "    \"trace_P1_arrival_sample\": \"P\",\n",
    "    \"trace_Pg_arrival_sample\": \"P\",\n",
    "    \"trace_Pn_arrival_sample\": \"P\",\n",
    "    \"trace_PmP_arrival_sample\": \"P\",\n",
    "    \"trace_pwP_arrival_sample\": \"P\",\n",
    "    \"trace_pwPm_arrival_sample\": \"P\",\n",
    "    \"trace_s_arrival_sample\": \"S\",\n",
    "    \"trace_S_arrival_sample\": \"S\",\n",
    "    \"trace_S1_arrival_sample\": \"S\",\n",
    "    \"trace_Sg_arrival_sample\": \"S\",\n",
    "    \"trace_SmS_arrival_sample\": \"S\",\n",
    "    \"trace_Sn_arrival_sample\": \"S\",\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "id": "6caeb986",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the data generators for training and validation\n",
    "train_generator = sbg.GenericGenerator(train)\n",
    "dev_generator = sbg.GenericGenerator(dev)\n",
    "test_generator = sbg.GenericGenerator(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "id": "5bce0e53",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define phase lists for labeling\n",
    "p_phases = [key for key, val in phase_dict.items() if val == \"P\"]\n",
    "s_phases = [key for key, val in phase_dict.items() if val == \"S\"]\n",
    "\n",
    "train_generator = sbg.GenericGenerator(train)\n",
    "dev_generator = sbg.GenericGenerator(dev)\n",
    "test_generator = sbg.GenericGenerator(test)\n",
    "\n",
    "augmentations = [\n",
    "    sbg.WindowAroundSample(list(phase_dict.keys()), samples_before=3000, windowlen=6000, selection=\"random\", strategy=\"variable\"),\n",
    "    sbg.RandomWindow(windowlen=3001, strategy=\"pad\"),\n",
    "    sbg.Normalize(demean_axis=-1, detrend_axis=-1, amp_norm_axis=-1, amp_norm_type=\"peak\"),\n",
    "    sbg.ChangeDtype(np.float32),\n",
    "    sbg.ProbabilisticLabeller(sigma=30, dim=0),\n",
    "]\n",
    "\n",
    "train_generator.add_augmentations(augmentations)\n",
    "dev_generator.add_augmentations(augmentations)\n",
    "test_generator.add_augmentations(augmentations)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "id": "45694b35",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters for peak detection\n",
    "sampling_rate = config['peak_detection']['sampling_rate']\n",
    "height = config['peak_detection']['height']\n",
    "distance = config['peak_detection']['distance']\n",
    "\n",
    "batch_size = config['training']['batch_size']\n",
    "num_workers = config['training']['num_workers']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "id": "7d542203",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "TRAINING CONFIGURATION SANITY CHECK\n",
      "============================================================\n",
      "\n",
      "📊 Dataset Information:\n",
      "  Total dataset size: 22,782 samples\n",
      "  Training set: 15,909 samples\n",
      "  Validation set: 3,429 samples\n",
      "  Test set: 3,444 samples\n",
      "  Sample fraction used: 2.0%\n",
      "\n",
      "🔧 Data Augmentation Pipeline:\n",
      "  1. WindowAroundSample\n",
      "     - metadata_keys: ['trace_p_arrival_sample', 'trace_pP_arrival_sample', 'trace_P_arrival_sample', 'trace_P1_arrival_sample', 'trace_Pg_arrival_sample', 'trace_Pn_arrival_sample', 'trace_PmP_arrival_sample', 'trace_pwP_arrival_sample', 'trace_pwPm_arrival_sample', 'trace_s_arrival_sample', 'trace_S_arrival_sample', 'trace_S1_arrival_sample', 'trace_Sg_arrival_sample', 'trace_SmS_arrival_sample', 'trace_Sn_arrival_sample']\n",
      "     - samples_before: 3000\n",
      "     - selection: random\n",
      "     - p0: None\n",
      "     - windowlen: 6000\n",
      "     - strategy: variable\n",
      "     - axis: -1\n",
      "     - key: ('X', 'X')\n",
      "  2. RandomWindow\n",
      "     - p0: None\n",
      "     - windowlen: 3001\n",
      "     - strategy: pad\n",
      "     - axis: -1\n",
      "     - key: ('X', 'X')\n",
      "     - low: None\n",
      "     - high: None\n",
      "  3. Normalize\n",
      "     - demean_axis: -1\n",
      "     - detrend_axis: -1\n",
      "     - amp_norm_axis: -1\n",
      "     - amp_norm_type: peak\n",
      "     - eps: 1e-10\n",
      "     - key: ('X', 'X')\n",
      "  4. ChangeDtype\n",
      "     - key: ('X', 'X')\n",
      "     - dtype: <class 'numpy.float32'>\n",
      "  5. ProbabilisticLabeller\n",
      "     - label_method: probabilistic\n",
      "     - sigma: 30\n",
      "     - shape: gaussian\n",
      "     - label_columns: None\n",
      "     - noise_column: True\n",
      "     - model_labels: None\n",
      "     - labels: None\n",
      "     - label_ids: None\n",
      "     - label_type: multi_class\n",
      "     - dim: 0\n",
      "     - key: ('X', 'y')\n",
      "\n",
      "🎯 Model Information:\n",
      "  Model type: PhaseNet\n",
      "  Total parameters: 268,443\n",
      "  Trainable parameters: 268,443\n",
      "  Model size: 1.02 MB\n",
      "  Device: cpu\n",
      "\n",
      "⚙️ Training Hyperparameters:\n",
      "  Batch size: 64\n",
      "  Number of workers: 4\n",
      "  Learning rate: 0.01\n",
      "  Number of epochs: 50\n",
      "  Patience (early stopping): 5\n",
      "\n",
      "📈 Peak Detection Parameters:\n",
      "  Sampling rate: 100 Hz\n",
      "  Height threshold: 0.5\n",
      "  Distance: 100 samples\n",
      "\n",
      "🔬 Phase Dictionary:\n",
      "  P-phases: 9 types\n",
      "  S-phases: 6 types\n",
      "\n",
      "💾 Data Loader Configuration:\n",
      "  Pin memory: True\n",
      "  Prefetch factor: 4\n",
      "  Persistent workers: True\n",
      "\n",
      "============================================================\n",
      "Ready to start training!\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "print(\"=\" * 60)\n",
    "print(\"TRAINING CONFIGURATION SANITY CHECK\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "print(\"\\n📊 Dataset Information:\")\n",
    "print(f\"  Total dataset size: {len(data):,} samples\")\n",
    "print(f\"  Training set: {len(train):,} samples\")\n",
    "print(f\"  Validation set: {len(dev):,} samples\")\n",
    "print(f\"  Test set: {len(test):,} samples\")\n",
    "print(f\"  Sample fraction used: {sample_fraction*100}%\")\n",
    "\n",
    "print(\"\\n🔧 Data Augmentation Pipeline:\")\n",
    "for i, aug in enumerate(augmentations, 1):\n",
    "    print(f\"  {i}. {aug.__class__.__name__}\")\n",
    "    if hasattr(aug, '__dict__'):\n",
    "        relevant_attrs = {k: v for k, v in aug.__dict__.items() if not k.startswith('_')}\n",
    "        for key, val in relevant_attrs.items():\n",
    "            print(f\"     - {key}: {val}\")\n",
    "\n",
    "print(\"\\n🎯 Model Information:\")\n",
    "print(f\"  Model type: {model.__class__.__name__}\")\n",
    "print(f\"  Total parameters: {phasenet_total_params:,}\")\n",
    "print(f\"  Trainable parameters: {phasenet_trainable_params:,}\")\n",
    "print(f\"  Model size: {phasenet_total_params * 4 / (1024**2):.2f} MB\")\n",
    "print(f\"  Device: {device}\")\n",
    "\n",
    "print(\"\\n⚙️ Training Hyperparameters:\")\n",
    "print(f\"  Batch size: {batch_size}\")\n",
    "print(f\"  Number of workers: {num_workers}\")\n",
    "print(f\"  Learning rate: {config['training']['learning_rate']}\")\n",
    "print(f\"  Number of epochs: {config['training']['epochs']}\")\n",
    "print(f\"  Patience (early stopping): {config['training']['patience']}\")\n",
    "\n",
    "print(\"\\n📈 Peak Detection Parameters:\")\n",
    "print(f\"  Sampling rate: {sampling_rate} Hz\")\n",
    "print(f\"  Height threshold: {height}\")\n",
    "print(f\"  Distance: {distance} samples\")\n",
    "\n",
    "print(\"\\n🔬 Phase Dictionary:\")\n",
    "print(f\"  P-phases: {len(p_phases)} types\")\n",
    "print(f\"  S-phases: {len(s_phases)} types\")\n",
    "\n",
    "print(\"\\n💾 Data Loader Configuration:\")\n",
    "print(f\"  Pin memory: True\")\n",
    "print(f\"  Prefetch factor: 4\")\n",
    "print(f\"  Persistent workers: True\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"Ready to start training!\")\n",
    "print(\"=\" * 60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "id": "17af6672",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the data for machine learning\n",
    "\n",
    "train_loader = DataLoader(train_generator,batch_size=batch_size, shuffle=True, num_workers=num_workers, worker_init_fn=worker_seeding,pin_memory=True,prefetch_factor=4,persistent_workers=True)\n",
    "test_loader = DataLoader(test_generator, batch_size=batch_size, shuffle=False, num_workers=num_workers, worker_init_fn=worker_seeding,pin_memory=True,prefetch_factor=4,persistent_workers=True)\n",
    "val_loader = DataLoader(dev_generator, batch_size=batch_size, shuffle=False, num_workers=num_workers, worker_init_fn=worker_seeding,pin_memory=True,prefetch_factor=4,persistent_workers=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "id": "dd3ceba8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define loss function\n",
    "def loss_fn(y_pred, y_true, eps=1e-5):\n",
    "    h = y_true * torch.log(y_pred + eps)\n",
    "    h = h.mean(-1).sum(-1)\n",
    "    h = h.mean()\n",
    "    return -h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "id": "1dc7c855",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Knowledge distillation loss function defined!\n",
      "  - Temperature: Controls softness of probability distributions\n",
      "  - Alpha: Balances learning from teacher vs ground truth\n"
     ]
    }
   ],
   "source": [
    "# Knowledge Distillation Loss Function\n",
    "def distillation_loss_fn(student_pred, teacher_pred, y_true, temperature=3.0, alpha=0.5, eps=1e-5):\n",
    "    \"\"\"\n",
    "    Combined loss for knowledge distillation.\n",
    "    \n",
    "    Args:\n",
    "        student_pred: Student model predictions (after softmax)\n",
    "        teacher_pred: Teacher model predictions (after softmax)\n",
    "        y_true: Ground truth labels\n",
    "        temperature: Temperature for softening probability distributions (higher = softer)\n",
    "        alpha: Weight between distillation loss and task loss (0-1)\n",
    "               alpha=1.0: only learn from teacher\n",
    "               alpha=0.0: only learn from ground truth\n",
    "        eps: Small epsilon for numerical stability\n",
    "    \n",
    "    Returns:\n",
    "        Combined distillation loss\n",
    "    \"\"\"\n",
    "    # Task loss: student vs ground truth (standard cross-entropy)\n",
    "    task_loss = -(y_true * torch.log(student_pred + eps)).mean(-1).sum(-1).mean()\n",
    "    \n",
    "    # Distillation loss: student vs teacher (KL divergence with temperature scaling)\n",
    "    # Apply temperature scaling to soften the distributions\n",
    "    student_log_soft = torch.log((student_pred ** (1.0/temperature)) + eps)\n",
    "    teacher_soft = teacher_pred ** (1.0/temperature)\n",
    "    \n",
    "    # Normalize after temperature scaling\n",
    "    student_log_soft = student_log_soft - torch.logsumexp(student_log_soft, dim=1, keepdim=True)\n",
    "    teacher_soft = teacher_soft / teacher_soft.sum(dim=1, keepdim=True)\n",
    "    \n",
    "    # KL divergence\n",
    "    distill_loss = -(teacher_soft * student_log_soft).mean(-1).sum(-1).mean()\n",
    "    \n",
    "    # Scale distillation loss by T^2 (common practice in knowledge distillation)\n",
    "    distill_loss = distill_loss * (temperature ** 2)\n",
    "    \n",
    "    # Combine losses\n",
    "    total_loss = alpha * distill_loss + (1 - alpha) * task_loss\n",
    "    \n",
    "    return total_loss\n",
    "\n",
    "print(\"✓ Knowledge distillation loss function defined!\")\n",
    "print(f\"  - Temperature: Controls softness of probability distributions\")\n",
    "print(f\"  - Alpha: Balances learning from teacher vs ground truth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "id": "5f750d82",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "KNOWLEDGE DISTILLATION SETUP\n",
      "============================================================\n",
      "\n",
      "👨‍🏫 Teacher Model (PhaseNet):\n",
      "  Total parameters: 268,443\n",
      "  Trainable parameters: 0 (frozen ✓)\n",
      "  Model size: 1.02 MB\n",
      "\n",
      "👨‍🎓 Student Model (XiaoNet):\n",
      "  Total parameters: 164,355\n",
      "  Trainable parameters: 164,355\n",
      "  Model size: 0.63 MB\n",
      "\n",
      "📊 Model Comparison:\n",
      "  Parameter reduction: 38.8%\n",
      "  Size reduction: 38.8%\n",
      "\n",
      "============================================================\n",
      "✓ Teacher-Student configuration complete!\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "# Configure Teacher and Student Models for Knowledge Distillation\n",
    "print(\"=\" * 60)\n",
    "print(\"KNOWLEDGE DISTILLATION SETUP\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Teacher model: PhaseNet (pretrained, frozen)\n",
    "teacher_model = model  # PhaseNet loaded earlier\n",
    "teacher_model.eval()   # Set to evaluation mode\n",
    "\n",
    "# Freeze all teacher parameters - no training\n",
    "for param in teacher_model.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "teacher_params = sum(p.numel() for p in teacher_model.parameters())\n",
    "teacher_trainable = sum(p.numel() for p in teacher_model.parameters() if p.requires_grad)\n",
    "\n",
    "print(\"\\n👨‍🏫 Teacher Model (PhaseNet):\")\n",
    "print(f\"  Total parameters: {teacher_params:,}\")\n",
    "print(f\"  Trainable parameters: {teacher_trainable:,} (frozen ✓)\")\n",
    "print(f\"  Model size: {teacher_params * 4 / (1024**2):.2f} MB\")\n",
    "\n",
    "# Student model: XiaoNet (will be trained)\n",
    "student_model = xiao_net  # XiaoNet created earlier\n",
    "student_model.train()      # Set to training mode\n",
    "\n",
    "student_params = sum(p.numel() for p in student_model.parameters())\n",
    "student_trainable = sum(p.numel() for p in student_model.parameters() if p.requires_grad)\n",
    "\n",
    "print(\"\\n👨‍🎓 Student Model (XiaoNet):\")\n",
    "print(f\"  Total parameters: {student_params:,}\")\n",
    "print(f\"  Trainable parameters: {student_trainable:,}\")\n",
    "print(f\"  Model size: {student_params * 4 / (1024**2):.2f} MB\")\n",
    "\n",
    "print(\"\\n📊 Model Comparison:\")\n",
    "print(f\"  Parameter reduction: {(1 - student_params/teacher_params)*100:.1f}%\")\n",
    "print(f\"  Size reduction: {(1 - (student_params * 4 / (1024**2)) / (teacher_params * 4 / (1024**2)))*100:.1f}%\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"✓ Teacher-Student configuration complete!\")\n",
    "print(\"=\" * 60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "id": "46a133ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Learning rate and number of epochs\n",
    "learning_rate = config['training']['learning_rate']\n",
    "epochs = config['training']['epochs']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "id": "8121db73",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Optimizer configured for student model\n",
      "  Learning rate: 0.01\n",
      "  Optimizing 164,355 parameters\n"
     ]
    }
   ],
   "source": [
    "# Setup optimizer for STUDENT model only (teacher is frozen)\n",
    "optimizer = torch.optim.Adam(student_model.parameters(), lr=learning_rate)\n",
    "\n",
    "print(f\"✓ Optimizer configured for student model\")\n",
    "print(f\"  Learning rate: {learning_rate}\")\n",
    "print(f\"  Optimizing {student_trainable:,} parameters\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "id": "1146f315",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Distillation training functions defined!\n",
      "  - train_one_epoch_distillation: Trains student with teacher guidance\n",
      "  - evaluate_student_model: Evaluates student independently\n"
     ]
    }
   ],
   "source": [
    "# Training function with knowledge distillation\n",
    "def train_one_epoch_distillation(dataloader, student_model, teacher_model, optimizer, device, \n",
    "                                   temperature=3.0, alpha=0.5):\n",
    "    \"\"\"\n",
    "    Train student model for one epoch using knowledge distillation.\n",
    "    \n",
    "    Args:\n",
    "        dataloader: Training data loader\n",
    "        student_model: Student model to train\n",
    "        teacher_model: Teacher model (frozen)\n",
    "        optimizer: Optimizer for student model\n",
    "        device: Device to train on\n",
    "        temperature: Temperature for distillation\n",
    "        alpha: Weight between distillation and task loss\n",
    "    \"\"\"\n",
    "    student_model.train()\n",
    "    teacher_model.eval()  # Teacher always in eval mode\n",
    "    \n",
    "    total_loss = 0\n",
    "    task_loss_total = 0\n",
    "    distill_loss_total = 0\n",
    "    size = len(dataloader.dataset)\n",
    "\n",
    "    for batch_id, batch in enumerate(dataloader):\n",
    "        X = batch[\"X\"].to(device)\n",
    "        y_true = batch[\"y\"].to(device)\n",
    "        \n",
    "        # Get predictions from both models\n",
    "        student_pred = student_model(X)\n",
    "        \n",
    "        with torch.no_grad():  # No gradients for teacher\n",
    "            teacher_pred = teacher_model(X)\n",
    "        \n",
    "        # Calculate combined loss\n",
    "        loss = distillation_loss_fn(student_pred, teacher_pred, y_true, \n",
    "                                     temperature=temperature, alpha=alpha)\n",
    "        \n",
    "        # Also calculate individual losses for monitoring\n",
    "        eps = 1e-5\n",
    "        task_loss = -(y_true * torch.log(student_pred + eps)).mean(-1).sum(-1).mean()\n",
    "        \n",
    "        # Backward pass and optimization\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if batch_id % 5 == 0:\n",
    "            print(f\"loss: {loss.item():>7f}  [{batch_id * len(batch['X']):>5d}/{size:>5d}]\")\n",
    "\n",
    "        total_loss += loss.item()\n",
    "        task_loss_total += task_loss.item()\n",
    "\n",
    "    avg_loss = total_loss / len(dataloader)\n",
    "    avg_task_loss = task_loss_total / len(dataloader)\n",
    "    \n",
    "    return avg_loss, avg_task_loss\n",
    "\n",
    "\n",
    "# Evaluation function for student model\n",
    "def evaluate_student_model(dataloader, student_model, device):\n",
    "    \"\"\"\n",
    "    Evaluate student model on validation/test set.\n",
    "    Uses standard cross-entropy loss (no teacher involved).\n",
    "    \"\"\"\n",
    "    student_model.eval()\n",
    "    val_loss = 0\n",
    "    eps = 1e-5\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in dataloader:\n",
    "            X = batch[\"X\"].to(device)\n",
    "            y_true = batch[\"y\"].to(device)\n",
    "            \n",
    "            student_pred = student_model(X)\n",
    "            loss = -(y_true * torch.log(student_pred + eps)).mean(-1).sum(-1).mean()\n",
    "            val_loss += loss.item()\n",
    "\n",
    "    return val_loss / len(dataloader)\n",
    "\n",
    "\n",
    "print(\"✓ Distillation training functions defined!\")\n",
    "print(\"  - train_one_epoch_distillation: Trains student with teacher guidance\")\n",
    "print(\"  - evaluate_student_model: Evaluates student independently\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "id": "f0b00d7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# EarlyStopping class\n",
    "class EarlyStopping:\n",
    "    def __init__(self, patience=7, verbose=False, delta=0, checkpoint_path='checkpoint.pt', \n",
    "                 best_model_path='best_model.pth', final_model_path='final_model.pth'):\n",
    "        self.patience = patience\n",
    "        self.verbose = verbose\n",
    "        self.counter = 0\n",
    "        self.best_score = None\n",
    "        self.early_stop = False\n",
    "        self.val_loss_min = float('inf')\n",
    "        self.delta = delta\n",
    "        self.checkpoint_path = checkpoint_path\n",
    "        self.best_model_path = best_model_path\n",
    "        self.final_model_path = final_model_path\n",
    "\n",
    "    def __call__(self, val_loss, model):\n",
    "        score = -val_loss\n",
    "        if self.best_score is None:\n",
    "            self.best_score = score\n",
    "            self.save_checkpoint(val_loss, model)\n",
    "            self.save_best_model(model)\n",
    "        elif score < self.best_score + self.delta:\n",
    "            self.counter += 1\n",
    "            if self.verbose:\n",
    "                print(f'EarlyStopping counter: {self.counter} out of {self.patience}')\n",
    "            if self.counter >= self.patience:\n",
    "                self.early_stop = True\n",
    "                self.save_final_model(model)\n",
    "        else:\n",
    "            self.best_score = score\n",
    "            self.save_checkpoint(val_loss, model)\n",
    "            self.save_best_model(model)\n",
    "            self.counter = 0\n",
    "\n",
    "    def save_checkpoint(self, val_loss, model):\n",
    "        if self.verbose:\n",
    "            print(f'Validation loss decreased ({self.val_loss_min:.6f} --> {val_loss:.6f}). Saving model...')\n",
    "        torch.save(model.state_dict(), self.checkpoint_path)\n",
    "        self.val_loss_min = val_loss\n",
    "\n",
    "    def save_best_model(self, model):\n",
    "        if self.verbose:\n",
    "            print(f'Saving best model to {self.best_model_path}')\n",
    "        torch.save(model.state_dict(), self.best_model_path)\n",
    "\n",
    "    def save_final_model(self, model):\n",
    "        if self.verbose:\n",
    "            print(f'Early stopping triggered. Saving final model to {self.final_model_path}')\n",
    "        torch.save(model.state_dict(), self.final_model_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "id": "f5e97a18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to train for one epoch\n",
    "def train_one_epoch(dataloader, model, loss_fn, optimizer, device):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    size = len(dataloader.dataset)\n",
    "\n",
    "    for batch_id, batch in enumerate(dataloader):\n",
    "        pred = model(batch[\"X\"].to(device))\n",
    "        loss = loss_fn(pred, batch[\"y\"].to(device))\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if batch_id % 5 == 0:\n",
    "            print(f\"loss: {loss.item():>7f}  [{batch_id * len(batch['X']):>5d}/{size:>5d}]\")\n",
    "\n",
    "        total_loss += loss.item()\n",
    "\n",
    "    return total_loss / len(dataloader)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "id": "bd322460",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to evaluate the model\n",
    "def evaluate_model(dataloader, model, loss_fn, device):\n",
    "    model.eval()\n",
    "    val_loss = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in dataloader:\n",
    "            pred = model(batch[\"X\"].to(device))\n",
    "            val_loss += loss_fn(pred, batch[\"y\"].to(device)).item()\n",
    "\n",
    "    return val_loss / len(dataloader)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "id": "ef876741",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to plot training history\n",
    "def plot_training_history(history):\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.plot(history['train_loss'], label='Training Loss')\n",
    "    plt.plot(history['val_loss'], label='Validation Loss')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.title('Training and Validation Loss Over Time')\n",
    "    plt.legend()\n",
    "    plt.grid(True, linestyle='--', alpha=0.6)\n",
    "    plt.fill_between(range(len(history['train_loss'])), \n",
    "                     history['train_loss'], history['val_loss'],\n",
    "                     alpha=0.3, color='red', \n",
    "                     where=(np.array(history['val_loss']) > np.array(history['train_loss'])),\n",
    "                     label='Potential Overfitting Gap')\n",
    "    plt.savefig('training_history.png')\n",
    "    plt.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41ead9eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1/50\n",
      "============================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/ML/lib/python3.12/site-packages/torch/optim/lr_scheduler.py:28: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
      "  warnings.warn(\"The verbose parameter is deprecated. Please use get_last_lr() \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 6.131898  [    0/15909]\n",
      "loss: 4.966187  [  320/15909]\n",
      "loss: 4.228575  [  640/15909]\n",
      "loss: 3.522102  [  960/15909]\n",
      "loss: 2.851644  [ 1280/15909]\n",
      "loss: 2.246575  [ 1600/15909]\n",
      "loss: 1.879482  [ 1920/15909]\n",
      "loss: 1.530304  [ 2240/15909]\n",
      "loss: 1.407449  [ 2560/15909]\n",
      "loss: 1.323392  [ 2880/15909]\n",
      "loss: 1.295061  [ 3200/15909]\n",
      "loss: 1.224062  [ 3520/15909]\n",
      "loss: 1.192209  [ 3840/15909]\n",
      "loss: 1.254235  [ 4160/15909]\n",
      "loss: 1.225917  [ 4480/15909]\n",
      "loss: 1.239346  [ 4800/15909]\n",
      "loss: 1.247718  [ 5120/15909]\n",
      "loss: 1.253661  [ 5440/15909]\n",
      "loss: 1.204089  [ 5760/15909]\n",
      "loss: 1.220528  [ 6080/15909]\n",
      "loss: 1.209281  [ 6400/15909]\n",
      "loss: 1.196747  [ 6720/15909]\n",
      "loss: 1.142924  [ 7040/15909]\n",
      "loss: 1.160721  [ 7360/15909]\n",
      "loss: 1.197099  [ 7680/15909]\n",
      "loss: 1.153111  [ 8000/15909]\n",
      "loss: 1.172551  [ 8320/15909]\n",
      "loss: 1.117908  [ 8640/15909]\n",
      "loss: 1.065643  [ 8960/15909]\n",
      "loss: 1.108493  [ 9280/15909]\n",
      "loss: 1.104210  [ 9600/15909]\n",
      "loss: 1.224569  [ 9920/15909]\n",
      "loss: 1.043436  [10240/15909]\n",
      "loss: 1.069295  [10560/15909]\n",
      "loss: 0.992139  [10880/15909]\n",
      "loss: 1.018232  [11200/15909]\n",
      "loss: 1.196805  [11520/15909]\n",
      "loss: 1.124195  [11840/15909]\n",
      "loss: 0.946455  [12160/15909]\n",
      "loss: 0.974720  [12480/15909]\n",
      "loss: 1.103426  [12800/15909]\n",
      "loss: 0.995996  [13120/15909]\n",
      "loss: 1.068359  [13440/15909]\n",
      "loss: 1.009817  [13760/15909]\n",
      "loss: 1.128592  [14080/15909]\n",
      "loss: 1.053221  [14400/15909]\n",
      "loss: 1.014920  [14720/15909]\n",
      "loss: 1.069621  [15040/15909]\n",
      "loss: 1.039794  [15360/15909]\n",
      "loss: 1.075911  [15680/15909]\n",
      "\n",
      "Epoch 1 Summary:\n",
      "  Train Loss: 1.454227\n",
      "  Train Task Loss: 0.331208\n",
      "  Val Loss: 0.238141\n",
      "Validation loss decreased (inf --> 0.238141). Saving model...\n",
      "Saving best model to best_model.pth\n",
      "\n",
      "Epoch 2/50\n",
      "============================================================\n",
      "loss: 1.015753  [    0/15909]\n",
      "loss: 1.039211  [  320/15909]\n",
      "loss: 1.074591  [  640/15909]\n",
      "loss: 1.036977  [  960/15909]\n",
      "loss: 0.935933  [ 1280/15909]\n",
      "loss: 0.956083  [ 1600/15909]\n",
      "loss: 0.970333  [ 1920/15909]\n",
      "loss: 1.073234  [ 2240/15909]\n",
      "loss: 1.039660  [ 2560/15909]\n",
      "loss: 1.051716  [ 2880/15909]\n",
      "loss: 0.973062  [ 3200/15909]\n",
      "loss: 1.005348  [ 3520/15909]\n",
      "loss: 0.995580  [ 3840/15909]\n",
      "loss: 0.992779  [ 4160/15909]\n",
      "loss: 1.035650  [ 4480/15909]\n",
      "loss: 1.052997  [ 4800/15909]\n",
      "loss: 0.989781  [ 5120/15909]\n",
      "loss: 1.026381  [ 5440/15909]\n",
      "loss: 1.020936  [ 5760/15909]\n",
      "loss: 1.009593  [ 6080/15909]\n",
      "loss: 1.021304  [ 6400/15909]\n",
      "loss: 0.955375  [ 6720/15909]\n",
      "loss: 0.993254  [ 7040/15909]\n",
      "loss: 0.928960  [ 7360/15909]\n",
      "loss: 1.022736  [ 7680/15909]\n",
      "loss: 1.053007  [ 8000/15909]\n",
      "loss: 0.977531  [ 8320/15909]\n",
      "loss: 1.042894  [ 8640/15909]\n",
      "loss: 0.923270  [ 8960/15909]\n",
      "loss: 1.062898  [ 9280/15909]\n",
      "loss: 0.998940  [ 9600/15909]\n",
      "loss: 0.992569  [ 9920/15909]\n",
      "loss: 1.031604  [10240/15909]\n",
      "loss: 0.994624  [10560/15909]\n",
      "loss: 1.035397  [10880/15909]\n",
      "loss: 0.984973  [11200/15909]\n",
      "loss: 0.970026  [11520/15909]\n",
      "loss: 1.049830  [11840/15909]\n",
      "loss: 1.026550  [12160/15909]\n",
      "loss: 0.977003  [12480/15909]\n",
      "loss: 0.984420  [12800/15909]\n",
      "loss: 1.105322  [13120/15909]\n",
      "loss: 1.007508  [13440/15909]\n",
      "loss: 0.969437  [13760/15909]\n",
      "loss: 1.129673  [14080/15909]\n",
      "loss: 1.023666  [14400/15909]\n",
      "loss: 0.931976  [14720/15909]\n",
      "loss: 0.997103  [15040/15909]\n",
      "loss: 1.001018  [15360/15909]\n",
      "loss: 1.097872  [15680/15909]\n",
      "\n",
      "Epoch 2 Summary:\n",
      "  Train Loss: 1.009459\n",
      "  Train Task Loss: 0.224622\n",
      "  Val Loss: 0.213730\n",
      "Validation loss decreased (0.238141 --> 0.213730). Saving model...\n",
      "Saving best model to best_model.pth\n",
      "\n",
      "Epoch 3/50\n",
      "============================================================\n",
      "loss: 0.981961  [    0/15909]\n",
      "loss: 1.018448  [  320/15909]\n",
      "loss: 0.934631  [  640/15909]\n",
      "loss: 0.977045  [  960/15909]\n",
      "loss: 0.945226  [ 1280/15909]\n",
      "loss: 1.023851  [ 1600/15909]\n",
      "loss: 1.011358  [ 1920/15909]\n",
      "loss: 1.036801  [ 2240/15909]\n",
      "loss: 1.001703  [ 2560/15909]\n",
      "loss: 0.995484  [ 2880/15909]\n",
      "loss: 1.028436  [ 3200/15909]\n",
      "loss: 1.012641  [ 3520/15909]\n",
      "loss: 1.028486  [ 3840/15909]\n",
      "loss: 0.987452  [ 4160/15909]\n",
      "loss: 1.017728  [ 4480/15909]\n",
      "loss: 1.016972  [ 4800/15909]\n",
      "loss: 1.018503  [ 5120/15909]\n",
      "loss: 0.910745  [ 5440/15909]\n",
      "loss: 1.004805  [ 5760/15909]\n",
      "loss: 0.931825  [ 6080/15909]\n",
      "loss: 0.954023  [ 6400/15909]\n",
      "loss: 1.062742  [ 6720/15909]\n",
      "loss: 1.034553  [ 7040/15909]\n",
      "loss: 0.984150  [ 7360/15909]\n",
      "loss: 0.957848  [ 7680/15909]\n",
      "loss: 0.997604  [ 8000/15909]\n",
      "loss: 1.009410  [ 8320/15909]\n",
      "loss: 1.000045  [ 8640/15909]\n",
      "loss: 0.998967  [ 8960/15909]\n",
      "loss: 0.974532  [ 9280/15909]\n",
      "loss: 1.042793  [ 9600/15909]\n",
      "loss: 1.028753  [ 9920/15909]\n",
      "loss: 0.979641  [10240/15909]\n",
      "loss: 0.897223  [10560/15909]\n",
      "loss: 0.908824  [10880/15909]\n",
      "loss: 0.974861  [11200/15909]\n",
      "loss: 0.950359  [11520/15909]\n",
      "loss: 1.029849  [11840/15909]\n",
      "loss: 0.964114  [12160/15909]\n",
      "loss: 1.011766  [12480/15909]\n",
      "loss: 0.963847  [12800/15909]\n",
      "loss: 1.040658  [13120/15909]\n",
      "loss: 1.031808  [13440/15909]\n",
      "loss: 0.941381  [13760/15909]\n",
      "loss: 1.038722  [14080/15909]\n",
      "loss: 0.967245  [14400/15909]\n",
      "loss: 0.987428  [14720/15909]\n",
      "loss: 0.958822  [15040/15909]\n",
      "loss: 1.008085  [15360/15909]\n",
      "loss: 0.980202  [15680/15909]\n",
      "\n",
      "Epoch 3 Summary:\n",
      "  Train Loss: 0.990880\n",
      "  Train Task Loss: 0.211319\n",
      "  Val Loss: 0.225641\n",
      "EarlyStopping counter: 1 out of 5\n",
      "\n",
      "Epoch 4/50\n",
      "============================================================\n",
      "loss: 0.967788  [    0/15909]\n",
      "loss: 1.032661  [  320/15909]\n",
      "loss: 0.922627  [  640/15909]\n",
      "loss: 1.011594  [  960/15909]\n",
      "loss: 0.945942  [ 1280/15909]\n",
      "loss: 0.992154  [ 1600/15909]\n",
      "loss: 0.928544  [ 1920/15909]\n",
      "loss: 0.987829  [ 2240/15909]\n",
      "loss: 0.944708  [ 2560/15909]\n",
      "loss: 1.039728  [ 2880/15909]\n",
      "loss: 0.902224  [ 3200/15909]\n",
      "loss: 0.942581  [ 3520/15909]\n",
      "loss: 0.989607  [ 3840/15909]\n",
      "loss: 0.972476  [ 4160/15909]\n",
      "loss: 0.946650  [ 4480/15909]\n",
      "loss: 0.985528  [ 4800/15909]\n",
      "loss: 0.954762  [ 5120/15909]\n",
      "loss: 0.979614  [ 5440/15909]\n",
      "loss: 1.018781  [ 5760/15909]\n",
      "loss: 0.979387  [ 6080/15909]\n",
      "loss: 0.955892  [ 6400/15909]\n",
      "loss: 1.035248  [ 6720/15909]\n",
      "loss: 1.011222  [ 7040/15909]\n",
      "loss: 0.967984  [ 7360/15909]\n",
      "loss: 1.010589  [ 7680/15909]\n",
      "loss: 0.956608  [ 8000/15909]\n",
      "loss: 0.970836  [ 8320/15909]\n",
      "loss: 0.973968  [ 8640/15909]\n",
      "loss: 1.026385  [ 8960/15909]\n",
      "loss: 1.049949  [ 9280/15909]\n",
      "loss: 0.987087  [ 9600/15909]\n",
      "loss: 0.948164  [ 9920/15909]\n",
      "loss: 0.984346  [10240/15909]\n",
      "loss: 1.062051  [10560/15909]\n",
      "loss: 1.054314  [10880/15909]\n",
      "loss: 0.979507  [11200/15909]\n",
      "loss: 0.999997  [11520/15909]\n",
      "loss: 0.988117  [11840/15909]\n",
      "loss: 0.994056  [12160/15909]\n",
      "loss: 0.953662  [12480/15909]\n",
      "loss: 0.940785  [12800/15909]\n",
      "loss: 0.937149  [13120/15909]\n",
      "loss: 0.946663  [13440/15909]\n",
      "loss: 1.018749  [13760/15909]\n",
      "loss: 0.931523  [14080/15909]\n",
      "loss: 1.015515  [14400/15909]\n",
      "loss: 1.020725  [14720/15909]\n",
      "loss: 0.987670  [15040/15909]\n",
      "loss: 0.991481  [15360/15909]\n",
      "loss: 0.997247  [15680/15909]\n",
      "\n",
      "Epoch 4 Summary:\n",
      "  Train Loss: 0.983919\n",
      "  Train Task Loss: 0.205011\n",
      "  Val Loss: 0.226268\n",
      "EarlyStopping counter: 2 out of 5\n",
      "\n",
      "Epoch 5/50\n",
      "============================================================\n",
      "loss: 0.980379  [    0/15909]\n",
      "loss: 0.952139  [  320/15909]\n",
      "loss: 0.886693  [  640/15909]\n",
      "loss: 0.923337  [  960/15909]\n",
      "loss: 0.983791  [ 1280/15909]\n",
      "loss: 0.964085  [ 1600/15909]\n",
      "loss: 1.032418  [ 1920/15909]\n",
      "loss: 1.036774  [ 2240/15909]\n",
      "loss: 0.910344  [ 2560/15909]\n",
      "loss: 0.997915  [ 2880/15909]\n",
      "loss: 0.886139  [ 3200/15909]\n",
      "loss: 1.022291  [ 3520/15909]\n",
      "loss: 0.945750  [ 3840/15909]\n",
      "loss: 0.984652  [ 4160/15909]\n",
      "loss: 1.027294  [ 4480/15909]\n",
      "loss: 1.041450  [ 4800/15909]\n",
      "loss: 0.903259  [ 5120/15909]\n",
      "loss: 0.978401  [ 5440/15909]\n",
      "loss: 0.908226  [ 5760/15909]\n",
      "loss: 1.025614  [ 6080/15909]\n",
      "loss: 1.042760  [ 6400/15909]\n",
      "loss: 1.024685  [ 6720/15909]\n",
      "loss: 0.940387  [ 7040/15909]\n",
      "loss: 1.052718  [ 7360/15909]\n",
      "loss: 0.957168  [ 7680/15909]\n",
      "loss: 0.895275  [ 8000/15909]\n",
      "loss: 0.979866  [ 8320/15909]\n",
      "loss: 1.017482  [ 8640/15909]\n",
      "loss: 1.022074  [ 8960/15909]\n",
      "loss: 1.006045  [ 9280/15909]\n",
      "loss: 0.993648  [ 9600/15909]\n",
      "loss: 1.012560  [ 9920/15909]\n",
      "loss: 0.962083  [10240/15909]\n",
      "loss: 0.943445  [10560/15909]\n",
      "loss: 0.993951  [10880/15909]\n",
      "loss: 0.921836  [11200/15909]\n",
      "loss: 0.963795  [11520/15909]\n",
      "loss: 0.988656  [11840/15909]\n",
      "loss: 0.952087  [12160/15909]\n",
      "loss: 0.915433  [12480/15909]\n",
      "loss: 0.951387  [12800/15909]\n",
      "loss: 1.004134  [13120/15909]\n",
      "loss: 0.927342  [13440/15909]\n",
      "loss: 0.941628  [13760/15909]\n",
      "loss: 1.013446  [14080/15909]\n",
      "loss: 0.910293  [14400/15909]\n",
      "loss: 1.012518  [14720/15909]\n",
      "loss: 1.010399  [15040/15909]\n",
      "loss: 1.056440  [15360/15909]\n",
      "loss: 0.966605  [15680/15909]\n",
      "\n",
      "Epoch 5 Summary:\n",
      "  Train Loss: 0.978588\n",
      "  Train Task Loss: 0.200501\n",
      "  Val Loss: 0.193297\n",
      "Validation loss decreased (0.213730 --> 0.193297). Saving model...\n",
      "Saving best model to best_model.pth\n",
      "\n",
      "Epoch 6/50\n",
      "============================================================\n",
      "loss: 0.981779  [    0/15909]\n",
      "loss: 1.005441  [  320/15909]\n",
      "loss: 0.904695  [  640/15909]\n",
      "loss: 0.965989  [  960/15909]\n",
      "loss: 1.035556  [ 1280/15909]\n",
      "loss: 0.959593  [ 1600/15909]\n",
      "loss: 0.987737  [ 1920/15909]\n",
      "loss: 1.006250  [ 2240/15909]\n",
      "loss: 0.913806  [ 2560/15909]\n",
      "loss: 0.965965  [ 2880/15909]\n",
      "loss: 1.013397  [ 3200/15909]\n",
      "loss: 0.939900  [ 3520/15909]\n",
      "loss: 0.969365  [ 3840/15909]\n",
      "loss: 0.948075  [ 4160/15909]\n",
      "loss: 0.998302  [ 4480/15909]\n",
      "loss: 1.037215  [ 4800/15909]\n",
      "loss: 0.965577  [ 5120/15909]\n",
      "loss: 1.076460  [ 5440/15909]\n",
      "loss: 0.957978  [ 5760/15909]\n",
      "loss: 0.948365  [ 6080/15909]\n",
      "loss: 0.928197  [ 6400/15909]\n",
      "loss: 1.014458  [ 6720/15909]\n",
      "loss: 0.982384  [ 7040/15909]\n",
      "loss: 0.920678  [ 7360/15909]\n",
      "loss: 0.942251  [ 7680/15909]\n",
      "loss: 0.984461  [ 8000/15909]\n",
      "loss: 0.967449  [ 8320/15909]\n",
      "loss: 0.939921  [ 8640/15909]\n",
      "loss: 1.009916  [ 8960/15909]\n",
      "loss: 0.912449  [ 9280/15909]\n",
      "loss: 0.930772  [ 9600/15909]\n",
      "loss: 1.001845  [ 9920/15909]\n",
      "loss: 0.998646  [10240/15909]\n",
      "loss: 0.917083  [10560/15909]\n",
      "loss: 0.926279  [10880/15909]\n",
      "loss: 0.958528  [11200/15909]\n",
      "loss: 0.949514  [11520/15909]\n",
      "loss: 0.976504  [11840/15909]\n",
      "loss: 1.017883  [12160/15909]\n",
      "loss: 0.906406  [12480/15909]\n",
      "loss: 0.948051  [12800/15909]\n",
      "loss: 1.034725  [13120/15909]\n",
      "loss: 1.038848  [13440/15909]\n",
      "loss: 0.986391  [13760/15909]\n",
      "loss: 0.977137  [14080/15909]\n",
      "loss: 0.931671  [14400/15909]\n",
      "loss: 0.970364  [14720/15909]\n",
      "loss: 1.005220  [15040/15909]\n",
      "loss: 0.970009  [15360/15909]\n",
      "loss: 0.949094  [15680/15909]\n",
      "\n",
      "Epoch 6 Summary:\n",
      "  Train Loss: 0.973985\n",
      "  Train Task Loss: 0.197991\n",
      "  Val Loss: 0.212910\n",
      "EarlyStopping counter: 1 out of 5\n",
      "\n",
      "Epoch 7/50\n",
      "============================================================\n",
      "loss: 0.933750  [    0/15909]\n",
      "loss: 0.928836  [  320/15909]\n",
      "loss: 0.972265  [  640/15909]\n",
      "loss: 0.978518  [  960/15909]\n",
      "loss: 0.960179  [ 1280/15909]\n",
      "loss: 0.937867  [ 1600/15909]\n",
      "loss: 0.907539  [ 1920/15909]\n",
      "loss: 1.008313  [ 2240/15909]\n",
      "loss: 0.972534  [ 2560/15909]\n",
      "loss: 0.936635  [ 2880/15909]\n",
      "loss: 0.996307  [ 3200/15909]\n",
      "loss: 0.953259  [ 3520/15909]\n",
      "loss: 0.989985  [ 3840/15909]\n",
      "loss: 0.942452  [ 4160/15909]\n",
      "loss: 1.079972  [ 4480/15909]\n",
      "loss: 0.974322  [ 4800/15909]\n",
      "loss: 0.984646  [ 5120/15909]\n",
      "loss: 1.012643  [ 5440/15909]\n",
      "loss: 0.935587  [ 5760/15909]\n",
      "loss: 0.991958  [ 6080/15909]\n",
      "loss: 0.983338  [ 6400/15909]\n",
      "loss: 0.970172  [ 6720/15909]\n",
      "loss: 0.976068  [ 7040/15909]\n",
      "loss: 0.991427  [ 7360/15909]\n",
      "loss: 0.889233  [ 7680/15909]\n",
      "loss: 0.972434  [ 8000/15909]\n",
      "loss: 0.988110  [ 8320/15909]\n",
      "loss: 0.998309  [ 8640/15909]\n",
      "loss: 1.000443  [ 8960/15909]\n",
      "loss: 1.040049  [ 9280/15909]\n",
      "loss: 0.957214  [ 9600/15909]\n",
      "loss: 0.978083  [ 9920/15909]\n",
      "loss: 1.048290  [10240/15909]\n",
      "loss: 0.960115  [10560/15909]\n",
      "loss: 0.953291  [10880/15909]\n",
      "loss: 0.955303  [11200/15909]\n",
      "loss: 0.997359  [11520/15909]\n",
      "loss: 0.926835  [11840/15909]\n",
      "loss: 0.997004  [12160/15909]\n",
      "loss: 1.020692  [12480/15909]\n",
      "loss: 1.026743  [12800/15909]\n",
      "loss: 0.979229  [13120/15909]\n",
      "loss: 1.002274  [13440/15909]\n",
      "loss: 0.957732  [13760/15909]\n",
      "loss: 0.923843  [14080/15909]\n",
      "loss: 0.964238  [14400/15909]\n",
      "loss: 1.009489  [14720/15909]\n",
      "loss: 1.011288  [15040/15909]\n",
      "loss: 0.929046  [15360/15909]\n",
      "loss: 1.017663  [15680/15909]\n",
      "\n",
      "Epoch 7 Summary:\n",
      "  Train Loss: 0.974880\n",
      "  Train Task Loss: 0.194292\n",
      "  Val Loss: 0.212697\n",
      "EarlyStopping counter: 2 out of 5\n",
      "\n",
      "Epoch 8/50\n",
      "============================================================\n",
      "loss: 0.957597  [    0/15909]\n",
      "loss: 0.958369  [  320/15909]\n",
      "loss: 1.013285  [  640/15909]\n",
      "loss: 0.920619  [  960/15909]\n",
      "loss: 1.002596  [ 1280/15909]\n",
      "loss: 0.933949  [ 1600/15909]\n",
      "loss: 0.912219  [ 1920/15909]\n",
      "loss: 0.950952  [ 2240/15909]\n",
      "loss: 1.012838  [ 2560/15909]\n",
      "loss: 1.011995  [ 2880/15909]\n",
      "loss: 0.989252  [ 3200/15909]\n",
      "loss: 0.992005  [ 3520/15909]\n",
      "loss: 0.996664  [ 3840/15909]\n",
      "loss: 1.045187  [ 4160/15909]\n",
      "loss: 0.999794  [ 4480/15909]\n",
      "loss: 1.044208  [ 4800/15909]\n",
      "loss: 0.987204  [ 5120/15909]\n",
      "loss: 0.963131  [ 5440/15909]\n",
      "loss: 0.990647  [ 5760/15909]\n",
      "loss: 1.076144  [ 6080/15909]\n",
      "loss: 1.053211  [ 6400/15909]\n",
      "loss: 0.973526  [ 6720/15909]\n",
      "loss: 0.952602  [ 7040/15909]\n",
      "loss: 0.960403  [ 7360/15909]\n",
      "loss: 0.993197  [ 7680/15909]\n",
      "loss: 0.968012  [ 8000/15909]\n",
      "loss: 0.900757  [ 8320/15909]\n",
      "loss: 0.955104  [ 8640/15909]\n",
      "loss: 1.016943  [ 8960/15909]\n",
      "loss: 0.925153  [ 9280/15909]\n",
      "loss: 0.973442  [ 9600/15909]\n",
      "loss: 0.900512  [ 9920/15909]\n",
      "loss: 0.960285  [10240/15909]\n",
      "loss: 0.949550  [10560/15909]\n",
      "loss: 0.901997  [10880/15909]\n",
      "loss: 0.980448  [11200/15909]\n",
      "loss: 0.957893  [11520/15909]\n",
      "loss: 0.974203  [11840/15909]\n",
      "loss: 0.920040  [12160/15909]\n",
      "loss: 0.966939  [12480/15909]\n",
      "loss: 0.891296  [12800/15909]\n",
      "loss: 0.932917  [13120/15909]\n",
      "loss: 0.919607  [13440/15909]\n",
      "loss: 0.937145  [13760/15909]\n",
      "loss: 0.939290  [14080/15909]\n",
      "loss: 0.939827  [14400/15909]\n",
      "loss: 0.942943  [14720/15909]\n",
      "loss: 0.903971  [15040/15909]\n",
      "loss: 0.923732  [15360/15909]\n",
      "loss: 0.958927  [15680/15909]\n",
      "\n",
      "Epoch 8 Summary:\n",
      "  Train Loss: 0.971514\n",
      "  Train Task Loss: 0.192083\n",
      "  Val Loss: 0.180796\n",
      "Validation loss decreased (0.193297 --> 0.180796). Saving model...\n",
      "Saving best model to best_model.pth\n",
      "\n",
      "Epoch 9/50\n",
      "============================================================\n",
      "loss: 0.960394  [    0/15909]\n",
      "loss: 0.937994  [  320/15909]\n",
      "loss: 0.945547  [  640/15909]\n",
      "loss: 1.084353  [  960/15909]\n",
      "loss: 0.972549  [ 1280/15909]\n",
      "loss: 0.948043  [ 1600/15909]\n",
      "loss: 0.999224  [ 1920/15909]\n",
      "loss: 0.967453  [ 2240/15909]\n",
      "loss: 0.923773  [ 2560/15909]\n",
      "loss: 0.972137  [ 2880/15909]\n",
      "loss: 0.910309  [ 3200/15909]\n",
      "loss: 0.987968  [ 3520/15909]\n",
      "loss: 0.943222  [ 3840/15909]\n",
      "loss: 0.895755  [ 4160/15909]\n",
      "loss: 1.044286  [ 4480/15909]\n",
      "loss: 1.059306  [ 4800/15909]\n",
      "loss: 0.985945  [ 5120/15909]\n",
      "loss: 0.958972  [ 5440/15909]\n",
      "loss: 0.930255  [ 5760/15909]\n",
      "loss: 0.974809  [ 6080/15909]\n",
      "loss: 0.921679  [ 6400/15909]\n",
      "loss: 1.014330  [ 6720/15909]\n",
      "loss: 0.997724  [ 7040/15909]\n",
      "loss: 0.956792  [ 7360/15909]\n",
      "loss: 0.985223  [ 7680/15909]\n",
      "loss: 0.977625  [ 8000/15909]\n",
      "loss: 0.894348  [ 8320/15909]\n",
      "loss: 0.974927  [ 8640/15909]\n",
      "loss: 0.980818  [ 8960/15909]\n",
      "loss: 0.946445  [ 9280/15909]\n",
      "loss: 0.880891  [ 9600/15909]\n",
      "loss: 0.938828  [ 9920/15909]\n",
      "loss: 0.998895  [10240/15909]\n",
      "loss: 0.937862  [10560/15909]\n",
      "loss: 0.971667  [10880/15909]\n",
      "loss: 0.935749  [11200/15909]\n",
      "loss: 0.935601  [11520/15909]\n",
      "loss: 0.981363  [11840/15909]\n",
      "loss: 0.932617  [12160/15909]\n",
      "loss: 1.088927  [12480/15909]\n",
      "loss: 0.988416  [12800/15909]\n",
      "loss: 0.932348  [13120/15909]\n",
      "loss: 0.931073  [13440/15909]\n",
      "loss: 0.989247  [13760/15909]\n",
      "loss: 0.999775  [14080/15909]\n",
      "loss: 0.910522  [14400/15909]\n",
      "loss: 0.943326  [14720/15909]\n",
      "loss: 0.947389  [15040/15909]\n",
      "loss: 0.914928  [15360/15909]\n",
      "loss: 0.917388  [15680/15909]\n",
      "\n",
      "Epoch 9 Summary:\n",
      "  Train Loss: 0.965282\n",
      "  Train Task Loss: 0.190513\n",
      "  Val Loss: 0.193363\n",
      "EarlyStopping counter: 1 out of 5\n",
      "\n",
      "Epoch 10/50\n",
      "============================================================\n",
      "loss: 0.960906  [    0/15909]\n",
      "loss: 0.947942  [  320/15909]\n",
      "loss: 0.968559  [  640/15909]\n",
      "loss: 0.968785  [  960/15909]\n",
      "loss: 0.994799  [ 1280/15909]\n",
      "loss: 0.950345  [ 1600/15909]\n",
      "loss: 0.951212  [ 1920/15909]\n",
      "loss: 0.954227  [ 2240/15909]\n",
      "loss: 1.027903  [ 2560/15909]\n",
      "loss: 0.880963  [ 2880/15909]\n",
      "loss: 0.904225  [ 3200/15909]\n",
      "loss: 1.050196  [ 3520/15909]\n",
      "loss: 0.940346  [ 3840/15909]\n",
      "loss: 0.980464  [ 4160/15909]\n",
      "loss: 0.997482  [ 4480/15909]\n",
      "loss: 1.007839  [ 4800/15909]\n",
      "loss: 0.946588  [ 5120/15909]\n",
      "loss: 0.983811  [ 5440/15909]\n",
      "loss: 0.965919  [ 5760/15909]\n",
      "loss: 1.011951  [ 6080/15909]\n",
      "loss: 0.977358  [ 6400/15909]\n",
      "loss: 1.011537  [ 6720/15909]\n",
      "loss: 0.979254  [ 7040/15909]\n",
      "loss: 0.967353  [ 7360/15909]\n",
      "loss: 0.950674  [ 7680/15909]\n",
      "loss: 1.033752  [ 8000/15909]\n",
      "loss: 0.905517  [ 8320/15909]\n",
      "loss: 0.981390  [ 8640/15909]\n",
      "loss: 0.988098  [ 8960/15909]\n",
      "loss: 0.957117  [ 9280/15909]\n",
      "loss: 0.968127  [ 9600/15909]\n",
      "loss: 0.947976  [ 9920/15909]\n",
      "loss: 0.948378  [10240/15909]\n",
      "loss: 0.973003  [10560/15909]\n",
      "loss: 0.970506  [10880/15909]\n",
      "loss: 0.988620  [11200/15909]\n",
      "loss: 1.019434  [11520/15909]\n",
      "loss: 0.894559  [11840/15909]\n",
      "loss: 0.960203  [12160/15909]\n",
      "loss: 0.899780  [12480/15909]\n",
      "loss: 0.953253  [12800/15909]\n",
      "loss: 1.026994  [13120/15909]\n",
      "loss: 0.954471  [13440/15909]\n",
      "loss: 0.979416  [13760/15909]\n",
      "loss: 0.950528  [14080/15909]\n",
      "loss: 0.939667  [14400/15909]\n",
      "loss: 0.911943  [14720/15909]\n",
      "loss: 1.029237  [15040/15909]\n",
      "loss: 0.996263  [15360/15909]\n",
      "loss: 0.995577  [15680/15909]\n",
      "\n",
      "Epoch 10 Summary:\n",
      "  Train Loss: 0.968634\n",
      "  Train Task Loss: 0.189668\n",
      "  Val Loss: 0.189621\n",
      "EarlyStopping counter: 2 out of 5\n",
      "\n",
      "Epoch 11/50\n",
      "============================================================\n",
      "loss: 0.941771  [    0/15909]\n",
      "loss: 1.082323  [  320/15909]\n",
      "loss: 0.945314  [  640/15909]\n",
      "loss: 0.885742  [  960/15909]\n",
      "loss: 0.959827  [ 1280/15909]\n",
      "loss: 0.950331  [ 1600/15909]\n",
      "loss: 0.967518  [ 1920/15909]\n",
      "loss: 1.007200  [ 2240/15909]\n",
      "loss: 0.995357  [ 2560/15909]\n",
      "loss: 0.962654  [ 2880/15909]\n",
      "loss: 0.909272  [ 3200/15909]\n",
      "loss: 0.978673  [ 3520/15909]\n",
      "loss: 0.948939  [ 3840/15909]\n",
      "loss: 0.992347  [ 4160/15909]\n",
      "loss: 1.020761  [ 4480/15909]\n",
      "loss: 1.045197  [ 4800/15909]\n",
      "loss: 0.939270  [ 5120/15909]\n",
      "loss: 0.972974  [ 5440/15909]\n",
      "loss: 0.976983  [ 5760/15909]\n",
      "loss: 0.906639  [ 6080/15909]\n",
      "loss: 0.939732  [ 6400/15909]\n",
      "loss: 1.000339  [ 6720/15909]\n",
      "loss: 0.979889  [ 7040/15909]\n",
      "loss: 0.938305  [ 7360/15909]\n",
      "loss: 1.010910  [ 7680/15909]\n",
      "loss: 0.968065  [ 8000/15909]\n",
      "loss: 0.912892  [ 8320/15909]\n",
      "loss: 0.953222  [ 8640/15909]\n",
      "loss: 0.961138  [ 8960/15909]\n",
      "loss: 1.050445  [ 9280/15909]\n",
      "loss: 1.033128  [ 9600/15909]\n",
      "loss: 0.954111  [ 9920/15909]\n",
      "loss: 0.952918  [10240/15909]\n",
      "loss: 0.982647  [10560/15909]\n",
      "loss: 0.927594  [10880/15909]\n",
      "loss: 0.902587  [11200/15909]\n",
      "loss: 0.931425  [11520/15909]\n",
      "loss: 0.995178  [11840/15909]\n",
      "loss: 0.970707  [12160/15909]\n",
      "loss: 0.934200  [12480/15909]\n",
      "loss: 0.987803  [12800/15909]\n",
      "loss: 0.988889  [13120/15909]\n",
      "loss: 1.016145  [13440/15909]\n",
      "loss: 1.021984  [13760/15909]\n",
      "loss: 0.926178  [14080/15909]\n",
      "loss: 0.931585  [14400/15909]\n",
      "loss: 0.868020  [14720/15909]\n",
      "loss: 0.990571  [15040/15909]\n",
      "loss: 0.999093  [15360/15909]\n",
      "loss: 0.939839  [15680/15909]\n",
      "\n",
      "Epoch 11 Summary:\n",
      "  Train Loss: 0.967948\n",
      "  Train Task Loss: 0.187937\n",
      "  Val Loss: 0.189934\n",
      "EarlyStopping counter: 3 out of 5\n",
      "\n",
      "Epoch 12/50\n",
      "============================================================\n",
      "loss: 0.951254  [    0/15909]\n",
      "loss: 0.950275  [  320/15909]\n",
      "loss: 1.002371  [  640/15909]\n",
      "loss: 1.049147  [  960/15909]\n",
      "loss: 0.906223  [ 1280/15909]\n",
      "loss: 1.052445  [ 1600/15909]\n",
      "loss: 0.873192  [ 1920/15909]\n",
      "loss: 0.968165  [ 2240/15909]\n",
      "loss: 0.990577  [ 2560/15909]\n",
      "loss: 0.930883  [ 2880/15909]\n",
      "loss: 0.984057  [ 3200/15909]\n",
      "loss: 0.990908  [ 3520/15909]\n",
      "loss: 0.990758  [ 3840/15909]\n",
      "loss: 0.962543  [ 4160/15909]\n",
      "loss: 0.910886  [ 4480/15909]\n",
      "loss: 1.007914  [ 4800/15909]\n",
      "loss: 1.000434  [ 5120/15909]\n",
      "loss: 0.945764  [ 5440/15909]\n",
      "loss: 0.938059  [ 5760/15909]\n",
      "loss: 1.075727  [ 6080/15909]\n",
      "loss: 0.947174  [ 6400/15909]\n",
      "loss: 0.938307  [ 6720/15909]\n",
      "loss: 0.945545  [ 7040/15909]\n",
      "loss: 0.925452  [ 7360/15909]\n",
      "loss: 1.058135  [ 7680/15909]\n",
      "loss: 0.942320  [ 8000/15909]\n",
      "loss: 1.014830  [ 8320/15909]\n",
      "loss: 0.999412  [ 8640/15909]\n",
      "loss: 0.953395  [ 8960/15909]\n",
      "loss: 0.972910  [ 9280/15909]\n",
      "loss: 0.956414  [ 9600/15909]\n",
      "loss: 0.864675  [ 9920/15909]\n",
      "loss: 0.917055  [10240/15909]\n",
      "loss: 0.934308  [10560/15909]\n",
      "loss: 0.956075  [10880/15909]\n",
      "loss: 0.951117  [11200/15909]\n",
      "loss: 0.907433  [11520/15909]\n",
      "loss: 1.037554  [11840/15909]\n",
      "loss: 0.993645  [12160/15909]\n",
      "loss: 0.923207  [12480/15909]\n",
      "loss: 0.941274  [12800/15909]\n",
      "loss: 1.064627  [13120/15909]\n",
      "loss: 0.985249  [13440/15909]\n",
      "loss: 0.973535  [13760/15909]\n",
      "loss: 0.984868  [14080/15909]\n",
      "loss: 0.966602  [14400/15909]\n",
      "loss: 0.930235  [14720/15909]\n",
      "loss: 0.992082  [15040/15909]\n",
      "loss: 0.919619  [15360/15909]\n",
      "loss: 0.959455  [15680/15909]\n",
      "\n",
      "Epoch 12 Summary:\n",
      "  Train Loss: 0.963668\n",
      "  Train Task Loss: 0.188287\n",
      "  Val Loss: 0.173858\n",
      "Validation loss decreased (0.180796 --> 0.173858). Saving model...\n",
      "Saving best model to best_model.pth\n",
      "\n",
      "Epoch 13/50\n",
      "============================================================\n",
      "loss: 1.018157  [    0/15909]\n",
      "loss: 0.990855  [  320/15909]\n",
      "loss: 0.954424  [  640/15909]\n",
      "loss: 0.951292  [  960/15909]\n",
      "loss: 0.968661  [ 1280/15909]\n",
      "loss: 0.965097  [ 1600/15909]\n",
      "loss: 0.950458  [ 1920/15909]\n",
      "loss: 1.032053  [ 2240/15909]\n",
      "loss: 0.988499  [ 2560/15909]\n",
      "loss: 0.903515  [ 2880/15909]\n",
      "loss: 0.985440  [ 3200/15909]\n",
      "loss: 1.035567  [ 3520/15909]\n",
      "loss: 1.026917  [ 3840/15909]\n",
      "loss: 0.965877  [ 4160/15909]\n",
      "loss: 0.923947  [ 4480/15909]\n",
      "loss: 0.919336  [ 4800/15909]\n",
      "loss: 0.897040  [ 5120/15909]\n",
      "loss: 0.958563  [ 5440/15909]\n",
      "loss: 1.010914  [ 5760/15909]\n",
      "loss: 0.993247  [ 6080/15909]\n",
      "loss: 0.976163  [ 6400/15909]\n",
      "loss: 0.963434  [ 6720/15909]\n",
      "loss: 1.092125  [ 7040/15909]\n",
      "loss: 0.911949  [ 7360/15909]\n",
      "loss: 0.951912  [ 7680/15909]\n",
      "loss: 0.960403  [ 8000/15909]\n",
      "loss: 0.956222  [ 8320/15909]\n",
      "loss: 0.974197  [ 8640/15909]\n",
      "loss: 1.004553  [ 8960/15909]\n",
      "loss: 1.008015  [ 9280/15909]\n",
      "loss: 0.903062  [ 9600/15909]\n",
      "loss: 0.891079  [ 9920/15909]\n",
      "loss: 0.969520  [10240/15909]\n",
      "loss: 0.942813  [10560/15909]\n",
      "loss: 0.956284  [10880/15909]\n",
      "loss: 0.923780  [11200/15909]\n",
      "loss: 0.934838  [11520/15909]\n",
      "loss: 0.952207  [11840/15909]\n",
      "loss: 0.960847  [12160/15909]\n",
      "loss: 0.982332  [12480/15909]\n",
      "loss: 1.018599  [12800/15909]\n",
      "loss: 0.961224  [13120/15909]\n",
      "loss: 0.897122  [13440/15909]\n",
      "loss: 1.001926  [13760/15909]\n",
      "loss: 0.961638  [14080/15909]\n",
      "loss: 0.960535  [14400/15909]\n",
      "loss: 0.898048  [14720/15909]\n",
      "loss: 1.010817  [15040/15909]\n",
      "loss: 0.959255  [15360/15909]\n",
      "loss: 0.955304  [15680/15909]\n",
      "\n",
      "Epoch 13 Summary:\n",
      "  Train Loss: 0.962877\n",
      "  Train Task Loss: 0.186084\n",
      "  Val Loss: 0.200814\n",
      "EarlyStopping counter: 1 out of 5\n",
      "\n",
      "Epoch 14/50\n",
      "============================================================\n",
      "loss: 0.946415  [    0/15909]\n",
      "loss: 0.929301  [  320/15909]\n",
      "loss: 0.954903  [  640/15909]\n",
      "loss: 0.913540  [  960/15909]\n",
      "loss: 0.935579  [ 1280/15909]\n",
      "loss: 0.954951  [ 1600/15909]\n",
      "loss: 0.989648  [ 1920/15909]\n",
      "loss: 0.957265  [ 2240/15909]\n",
      "loss: 0.999441  [ 2560/15909]\n",
      "loss: 0.976528  [ 2880/15909]\n",
      "loss: 0.999154  [ 3200/15909]\n",
      "loss: 0.954511  [ 3520/15909]\n",
      "loss: 0.883498  [ 3840/15909]\n",
      "loss: 0.979269  [ 4160/15909]\n",
      "loss: 0.932900  [ 4480/15909]\n",
      "loss: 0.997847  [ 4800/15909]\n",
      "loss: 0.960142  [ 5120/15909]\n",
      "loss: 0.909014  [ 5440/15909]\n",
      "loss: 0.926001  [ 5760/15909]\n",
      "loss: 0.990151  [ 6080/15909]\n",
      "loss: 0.947363  [ 6400/15909]\n",
      "loss: 0.938211  [ 6720/15909]\n",
      "loss: 0.853763  [ 7040/15909]\n",
      "loss: 0.993774  [ 7360/15909]\n",
      "loss: 1.010486  [ 7680/15909]\n",
      "loss: 0.972648  [ 8000/15909]\n",
      "loss: 0.976823  [ 8320/15909]\n",
      "loss: 0.924907  [ 8640/15909]\n",
      "loss: 1.012915  [ 8960/15909]\n",
      "loss: 0.918576  [ 9280/15909]\n",
      "loss: 0.998570  [ 9600/15909]\n",
      "loss: 0.927112  [ 9920/15909]\n",
      "loss: 0.910705  [10240/15909]\n",
      "loss: 0.999796  [10560/15909]\n",
      "loss: 0.986765  [10880/15909]\n",
      "loss: 0.936011  [11200/15909]\n",
      "loss: 1.011236  [11520/15909]\n",
      "loss: 0.937133  [11840/15909]\n",
      "loss: 0.981719  [12160/15909]\n",
      "loss: 1.013748  [12480/15909]\n",
      "loss: 0.903458  [12800/15909]\n",
      "loss: 0.967591  [13120/15909]\n",
      "loss: 0.978638  [13440/15909]\n",
      "loss: 1.068220  [13760/15909]\n",
      "loss: 0.985401  [14080/15909]\n",
      "loss: 0.956455  [14400/15909]\n",
      "loss: 0.993580  [14720/15909]\n",
      "loss: 0.964878  [15040/15909]\n",
      "loss: 0.987463  [15360/15909]\n",
      "loss: 1.015059  [15680/15909]\n",
      "\n",
      "Epoch 14 Summary:\n",
      "  Train Loss: 0.959463\n",
      "  Train Task Loss: 0.185835\n",
      "  Val Loss: 0.182769\n",
      "EarlyStopping counter: 2 out of 5\n",
      "\n",
      "Epoch 15/50\n",
      "============================================================\n",
      "loss: 0.964401  [    0/15909]\n",
      "loss: 0.991278  [  320/15909]\n",
      "loss: 0.956175  [  640/15909]\n",
      "loss: 0.974574  [  960/15909]\n",
      "loss: 0.909402  [ 1280/15909]\n",
      "loss: 1.026723  [ 1600/15909]\n",
      "loss: 0.942117  [ 1920/15909]\n",
      "loss: 0.964482  [ 2240/15909]\n",
      "loss: 0.966827  [ 2560/15909]\n",
      "loss: 0.958465  [ 2880/15909]\n",
      "loss: 0.991576  [ 3200/15909]\n",
      "loss: 0.980618  [ 3520/15909]\n",
      "loss: 0.994911  [ 3840/15909]\n",
      "loss: 0.951083  [ 4160/15909]\n",
      "loss: 0.878973  [ 4480/15909]\n",
      "loss: 0.898625  [ 4800/15909]\n",
      "loss: 0.897405  [ 5120/15909]\n",
      "loss: 0.966028  [ 5440/15909]\n",
      "loss: 0.961183  [ 5760/15909]\n",
      "loss: 0.951689  [ 6080/15909]\n",
      "loss: 0.968352  [ 6400/15909]\n",
      "loss: 0.905908  [ 6720/15909]\n",
      "loss: 0.958191  [ 7040/15909]\n",
      "loss: 0.930014  [ 7360/15909]\n",
      "loss: 0.994953  [ 7680/15909]\n",
      "loss: 0.951913  [ 8000/15909]\n",
      "loss: 1.094409  [ 8320/15909]\n",
      "loss: 0.952943  [ 8640/15909]\n",
      "loss: 0.977174  [ 8960/15909]\n",
      "loss: 0.943416  [ 9280/15909]\n",
      "loss: 0.903937  [ 9600/15909]\n",
      "loss: 0.979192  [ 9920/15909]\n",
      "loss: 1.003950  [10240/15909]\n",
      "loss: 0.947302  [10560/15909]\n",
      "loss: 0.953206  [10880/15909]\n",
      "loss: 0.851715  [11200/15909]\n",
      "loss: 0.925090  [11520/15909]\n",
      "loss: 0.947152  [11840/15909]\n",
      "loss: 0.914834  [12160/15909]\n",
      "loss: 0.974035  [12480/15909]\n",
      "loss: 0.971148  [12800/15909]\n",
      "loss: 0.938045  [13120/15909]\n",
      "loss: 0.896419  [13440/15909]\n",
      "loss: 0.985855  [13760/15909]\n",
      "loss: 1.031859  [14080/15909]\n",
      "loss: 1.094449  [14400/15909]\n",
      "loss: 0.949954  [14720/15909]\n",
      "loss: 0.934255  [15040/15909]\n",
      "loss: 0.994178  [15360/15909]\n",
      "loss: 0.989907  [15680/15909]\n",
      "\n",
      "Epoch 15 Summary:\n",
      "  Train Loss: 0.962159\n",
      "  Train Task Loss: 0.184848\n",
      "  Val Loss: 0.231455\n",
      "EarlyStopping counter: 3 out of 5\n",
      "\n",
      "Epoch 16/50\n",
      "============================================================\n",
      "loss: 0.952368  [    0/15909]\n",
      "loss: 1.034626  [  320/15909]\n",
      "loss: 0.957287  [  640/15909]\n",
      "loss: 0.973491  [  960/15909]\n",
      "loss: 0.928217  [ 1280/15909]\n",
      "loss: 0.958643  [ 1600/15909]\n",
      "loss: 1.005506  [ 1920/15909]\n",
      "loss: 0.978384  [ 2240/15909]\n",
      "loss: 0.935140  [ 2560/15909]\n",
      "loss: 0.940984  [ 2880/15909]\n",
      "loss: 0.966052  [ 3200/15909]\n",
      "loss: 0.886571  [ 3520/15909]\n",
      "loss: 0.929588  [ 3840/15909]\n",
      "loss: 0.943144  [ 4160/15909]\n",
      "loss: 0.954091  [ 4480/15909]\n",
      "loss: 0.967577  [ 4800/15909]\n",
      "loss: 0.949724  [ 5120/15909]\n",
      "loss: 1.011847  [ 5440/15909]\n",
      "loss: 0.923601  [ 5760/15909]\n",
      "loss: 0.882273  [ 6080/15909]\n",
      "loss: 0.936591  [ 6400/15909]\n",
      "loss: 0.943455  [ 6720/15909]\n",
      "loss: 1.020940  [ 7040/15909]\n",
      "loss: 1.045526  [ 7360/15909]\n",
      "loss: 0.886356  [ 7680/15909]\n",
      "loss: 0.887087  [ 8000/15909]\n",
      "loss: 0.937065  [ 8320/15909]\n",
      "loss: 1.105367  [ 8640/15909]\n",
      "loss: 0.928940  [ 8960/15909]\n",
      "loss: 0.969759  [ 9280/15909]\n",
      "loss: 0.891244  [ 9600/15909]\n",
      "loss: 0.929695  [ 9920/15909]\n",
      "loss: 0.913989  [10240/15909]\n",
      "loss: 1.050430  [10560/15909]\n",
      "loss: 0.885781  [10880/15909]\n",
      "loss: 1.049715  [11200/15909]\n",
      "loss: 1.003097  [11520/15909]\n",
      "loss: 0.952819  [11840/15909]\n",
      "loss: 0.991564  [12160/15909]\n",
      "loss: 0.965085  [12480/15909]\n",
      "loss: 0.940734  [12800/15909]\n",
      "loss: 0.939024  [13120/15909]\n",
      "loss: 0.848466  [13440/15909]\n",
      "loss: 0.961768  [13760/15909]\n",
      "loss: 0.923103  [14080/15909]\n",
      "loss: 0.939092  [14400/15909]\n",
      "loss: 1.018187  [14720/15909]\n",
      "loss: 1.009495  [15040/15909]\n",
      "loss: 0.971099  [15360/15909]\n",
      "loss: 0.976346  [15680/15909]\n",
      "\n",
      "Epoch 16 Summary:\n",
      "  Train Loss: 0.960511\n",
      "  Train Task Loss: 0.184138\n",
      "  Val Loss: 0.172479\n",
      "Validation loss decreased (0.173858 --> 0.172479). Saving model...\n",
      "Saving best model to best_model.pth\n",
      "\n",
      "Epoch 17/50\n",
      "============================================================\n",
      "loss: 0.894600  [    0/15909]\n",
      "loss: 0.961771  [  320/15909]\n",
      "loss: 0.995512  [  640/15909]\n",
      "loss: 0.901989  [  960/15909]\n",
      "loss: 0.982684  [ 1280/15909]\n",
      "loss: 1.011278  [ 1600/15909]\n",
      "loss: 1.022195  [ 1920/15909]\n",
      "loss: 0.957177  [ 2240/15909]\n",
      "loss: 0.990252  [ 2560/15909]\n",
      "loss: 1.058778  [ 2880/15909]\n",
      "loss: 0.968383  [ 3200/15909]\n",
      "loss: 0.960882  [ 3520/15909]\n",
      "loss: 0.943740  [ 3840/15909]\n",
      "loss: 0.925088  [ 4160/15909]\n",
      "loss: 0.977908  [ 4480/15909]\n",
      "loss: 0.963461  [ 4800/15909]\n",
      "loss: 1.019732  [ 5120/15909]\n",
      "loss: 0.942611  [ 5440/15909]\n",
      "loss: 0.970680  [ 5760/15909]\n",
      "loss: 1.013627  [ 6080/15909]\n",
      "loss: 0.976010  [ 6400/15909]\n",
      "loss: 0.933377  [ 6720/15909]\n",
      "loss: 0.962371  [ 7040/15909]\n",
      "loss: 0.995560  [ 7360/15909]\n",
      "loss: 1.031679  [ 7680/15909]\n",
      "loss: 0.976808  [ 8000/15909]\n",
      "loss: 0.966289  [ 8320/15909]\n",
      "loss: 0.951713  [ 8640/15909]\n",
      "loss: 0.951391  [ 8960/15909]\n",
      "loss: 0.931663  [ 9280/15909]\n",
      "loss: 0.987245  [ 9600/15909]\n",
      "loss: 0.952358  [ 9920/15909]\n",
      "loss: 0.957298  [10240/15909]\n",
      "loss: 0.967090  [10560/15909]\n",
      "loss: 0.986245  [10880/15909]\n",
      "loss: 1.028384  [11200/15909]\n",
      "loss: 0.944145  [11520/15909]\n",
      "loss: 0.954864  [11840/15909]\n",
      "loss: 0.973869  [12160/15909]\n",
      "loss: 0.900618  [12480/15909]\n",
      "loss: 0.979056  [12800/15909]\n",
      "loss: 0.963158  [13120/15909]\n",
      "loss: 0.886485  [13440/15909]\n",
      "loss: 0.979783  [13760/15909]\n",
      "loss: 0.903224  [14080/15909]\n",
      "loss: 1.005207  [14400/15909]\n",
      "loss: 0.996337  [14720/15909]\n",
      "loss: 1.007027  [15040/15909]\n",
      "loss: 0.962850  [15360/15909]\n",
      "loss: 0.937166  [15680/15909]\n",
      "\n",
      "Epoch 17 Summary:\n",
      "  Train Loss: 0.961073\n",
      "  Train Task Loss: 0.183192\n",
      "  Val Loss: 0.187440\n",
      "EarlyStopping counter: 1 out of 5\n",
      "\n",
      "Epoch 18/50\n",
      "============================================================\n",
      "loss: 1.029233  [    0/15909]\n",
      "loss: 0.901193  [  320/15909]\n",
      "loss: 0.935308  [  640/15909]\n",
      "loss: 0.934365  [  960/15909]\n",
      "loss: 0.938633  [ 1280/15909]\n",
      "loss: 1.032814  [ 1600/15909]\n",
      "loss: 0.933136  [ 1920/15909]\n",
      "loss: 0.889818  [ 2240/15909]\n",
      "loss: 0.975605  [ 2560/15909]\n",
      "loss: 1.069230  [ 2880/15909]\n",
      "loss: 1.056676  [ 3200/15909]\n",
      "loss: 0.970548  [ 3520/15909]\n",
      "loss: 0.982695  [ 3840/15909]\n",
      "loss: 0.941884  [ 4160/15909]\n",
      "loss: 0.936947  [ 4480/15909]\n",
      "loss: 0.879845  [ 4800/15909]\n",
      "loss: 0.955814  [ 5120/15909]\n",
      "loss: 0.999280  [ 5440/15909]\n",
      "loss: 0.931381  [ 5760/15909]\n",
      "loss: 0.898534  [ 6080/15909]\n",
      "loss: 1.033313  [ 6400/15909]\n",
      "loss: 0.976289  [ 6720/15909]\n",
      "loss: 0.923434  [ 7040/15909]\n",
      "loss: 0.918597  [ 7360/15909]\n",
      "loss: 0.912029  [ 7680/15909]\n",
      "loss: 0.998598  [ 8000/15909]\n",
      "loss: 1.067664  [ 8320/15909]\n",
      "loss: 0.949689  [ 8640/15909]\n",
      "loss: 1.028539  [ 8960/15909]\n",
      "loss: 0.927326  [ 9280/15909]\n",
      "loss: 0.957289  [ 9600/15909]\n",
      "loss: 1.024207  [ 9920/15909]\n",
      "loss: 1.008895  [10240/15909]\n",
      "loss: 0.965859  [10560/15909]\n",
      "loss: 0.978995  [10880/15909]\n",
      "loss: 0.993548  [11200/15909]\n",
      "loss: 0.925552  [11520/15909]\n",
      "loss: 0.904656  [11840/15909]\n",
      "loss: 0.965785  [12160/15909]\n",
      "loss: 0.927672  [12480/15909]\n",
      "loss: 0.947083  [12800/15909]\n",
      "loss: 0.924820  [13120/15909]\n",
      "loss: 1.022290  [13440/15909]\n",
      "loss: 0.956239  [13760/15909]\n",
      "loss: 0.932464  [14080/15909]\n",
      "loss: 0.947707  [14400/15909]\n",
      "loss: 1.003564  [14720/15909]\n",
      "loss: 0.958525  [15040/15909]\n",
      "loss: 0.954183  [15360/15909]\n",
      "loss: 0.949339  [15680/15909]\n",
      "\n",
      "Epoch 18 Summary:\n",
      "  Train Loss: 0.958830\n",
      "  Train Task Loss: 0.183630\n",
      "  Val Loss: 0.200328\n",
      "EarlyStopping counter: 2 out of 5\n",
      "\n",
      "Epoch 19/50\n",
      "============================================================\n",
      "loss: 1.006345  [    0/15909]\n",
      "loss: 0.967687  [  320/15909]\n",
      "loss: 0.954497  [  640/15909]\n",
      "loss: 0.958792  [  960/15909]\n",
      "loss: 0.990643  [ 1280/15909]\n",
      "loss: 0.971810  [ 1600/15909]\n",
      "loss: 0.931037  [ 1920/15909]\n",
      "loss: 0.981501  [ 2240/15909]\n",
      "loss: 0.932138  [ 2560/15909]\n",
      "loss: 0.957613  [ 2880/15909]\n",
      "loss: 1.018324  [ 3200/15909]\n",
      "loss: 0.928150  [ 3520/15909]\n",
      "loss: 0.911735  [ 3840/15909]\n",
      "loss: 0.975107  [ 4160/15909]\n",
      "loss: 1.077210  [ 4480/15909]\n",
      "loss: 0.966958  [ 4800/15909]\n",
      "loss: 0.914159  [ 5120/15909]\n",
      "loss: 0.958231  [ 5440/15909]\n",
      "loss: 0.963085  [ 5760/15909]\n",
      "loss: 0.997326  [ 6080/15909]\n",
      "loss: 0.939491  [ 6400/15909]\n",
      "loss: 0.959476  [ 6720/15909]\n",
      "loss: 0.988460  [ 7040/15909]\n",
      "loss: 0.908913  [ 7360/15909]\n",
      "loss: 0.958176  [ 7680/15909]\n",
      "loss: 0.965677  [ 8000/15909]\n",
      "loss: 0.940495  [ 8320/15909]\n",
      "loss: 0.937582  [ 8640/15909]\n",
      "loss: 0.939026  [ 8960/15909]\n",
      "loss: 1.034149  [ 9280/15909]\n",
      "loss: 0.939106  [ 9600/15909]\n",
      "loss: 0.970349  [ 9920/15909]\n",
      "loss: 0.882403  [10240/15909]\n",
      "loss: 1.005245  [10560/15909]\n",
      "loss: 0.850448  [10880/15909]\n",
      "loss: 1.087760  [11200/15909]\n",
      "loss: 0.919007  [11520/15909]\n",
      "loss: 0.924122  [11840/15909]\n",
      "loss: 0.939237  [12160/15909]\n",
      "loss: 0.985433  [12480/15909]\n",
      "loss: 0.914305  [12800/15909]\n",
      "loss: 0.971627  [13120/15909]\n",
      "loss: 0.946844  [13440/15909]\n",
      "loss: 0.955232  [13760/15909]\n",
      "loss: 0.999091  [14080/15909]\n",
      "loss: 1.020667  [14400/15909]\n",
      "loss: 0.901267  [14720/15909]\n",
      "loss: 0.991033  [15040/15909]\n",
      "loss: 1.003268  [15360/15909]\n",
      "loss: 0.898911  [15680/15909]\n",
      "\n",
      "Epoch 19 Summary:\n",
      "  Train Loss: 0.956036\n",
      "  Train Task Loss: 0.182619\n",
      "  Val Loss: 0.175718\n",
      "EarlyStopping counter: 3 out of 5\n",
      "\n",
      "Epoch 20/50\n",
      "============================================================\n",
      "loss: 0.967747  [    0/15909]\n",
      "loss: 1.033842  [  320/15909]\n",
      "loss: 0.968563  [  640/15909]\n",
      "loss: 0.928770  [  960/15909]\n",
      "loss: 0.966219  [ 1280/15909]\n",
      "loss: 0.934085  [ 1600/15909]\n",
      "loss: 0.949449  [ 1920/15909]\n",
      "loss: 0.913268  [ 2240/15909]\n",
      "loss: 0.957072  [ 2560/15909]\n",
      "loss: 0.907348  [ 2880/15909]\n",
      "loss: 0.958387  [ 3200/15909]\n",
      "loss: 0.955252  [ 3520/15909]\n",
      "loss: 0.957794  [ 3840/15909]\n",
      "loss: 0.933446  [ 4160/15909]\n",
      "loss: 0.956260  [ 4480/15909]\n",
      "loss: 0.912230  [ 4800/15909]\n",
      "loss: 1.014707  [ 5120/15909]\n",
      "loss: 0.979409  [ 5440/15909]\n",
      "loss: 0.945600  [ 5760/15909]\n",
      "loss: 0.980036  [ 6080/15909]\n",
      "loss: 1.015057  [ 6400/15909]\n",
      "loss: 0.927463  [ 6720/15909]\n",
      "loss: 0.992579  [ 7040/15909]\n",
      "loss: 0.936702  [ 7360/15909]\n",
      "loss: 0.919063  [ 7680/15909]\n",
      "loss: 0.932752  [ 8000/15909]\n",
      "loss: 0.983518  [ 8320/15909]\n",
      "loss: 1.034809  [ 8640/15909]\n",
      "loss: 0.951889  [ 8960/15909]\n",
      "loss: 0.909990  [ 9280/15909]\n",
      "loss: 0.918510  [ 9600/15909]\n",
      "loss: 0.999362  [ 9920/15909]\n",
      "loss: 0.875212  [10240/15909]\n",
      "loss: 0.932577  [10560/15909]\n",
      "loss: 0.916625  [10880/15909]\n",
      "loss: 0.989702  [11200/15909]\n",
      "loss: 1.045157  [11520/15909]\n",
      "loss: 1.045009  [11840/15909]\n",
      "loss: 0.882999  [12160/15909]\n",
      "loss: 0.974010  [12480/15909]\n",
      "loss: 0.999660  [12800/15909]\n",
      "loss: 0.974555  [13120/15909]\n",
      "loss: 1.084590  [13440/15909]\n",
      "loss: 0.974180  [13760/15909]\n",
      "loss: 1.023913  [14080/15909]\n",
      "loss: 0.958444  [14400/15909]\n",
      "loss: 0.965054  [14720/15909]\n",
      "loss: 0.958985  [15040/15909]\n",
      "loss: 0.988460  [15360/15909]\n",
      "loss: 0.943060  [15680/15909]\n",
      "\n",
      "Epoch 20 Summary:\n",
      "  Train Loss: 0.959324\n",
      "  Train Task Loss: 0.181263\n",
      "  Val Loss: 0.207540\n",
      "EarlyStopping counter: 4 out of 5\n",
      "\n",
      "Epoch 21/50\n",
      "============================================================\n",
      "loss: 0.954377  [    0/15909]\n",
      "loss: 0.904697  [  320/15909]\n",
      "loss: 0.961015  [  640/15909]\n",
      "loss: 0.898369  [  960/15909]\n",
      "loss: 0.859387  [ 1280/15909]\n",
      "loss: 0.909915  [ 1600/15909]\n",
      "loss: 0.958730  [ 1920/15909]\n",
      "loss: 0.935585  [ 2240/15909]\n",
      "loss: 0.950216  [ 2560/15909]\n",
      "loss: 0.955481  [ 2880/15909]\n",
      "loss: 0.928399  [ 3200/15909]\n",
      "loss: 0.875205  [ 3520/15909]\n",
      "loss: 0.987905  [ 3840/15909]\n",
      "loss: 0.917290  [ 4160/15909]\n",
      "loss: 0.913540  [ 4480/15909]\n",
      "loss: 0.979648  [ 4800/15909]\n",
      "loss: 0.971389  [ 5120/15909]\n",
      "loss: 0.869384  [ 5440/15909]\n",
      "loss: 0.952329  [ 5760/15909]\n",
      "loss: 0.994452  [ 6080/15909]\n",
      "loss: 1.010804  [ 6400/15909]\n",
      "loss: 1.008863  [ 6720/15909]\n",
      "loss: 0.954211  [ 7040/15909]\n",
      "loss: 0.925764  [ 7360/15909]\n",
      "loss: 0.961370  [ 7680/15909]\n",
      "loss: 0.995765  [ 8000/15909]\n",
      "loss: 0.929011  [ 8320/15909]\n",
      "loss: 0.966045  [ 8640/15909]\n",
      "loss: 0.916896  [ 8960/15909]\n",
      "loss: 0.982508  [ 9280/15909]\n",
      "loss: 0.941989  [ 9600/15909]\n",
      "loss: 0.940985  [ 9920/15909]\n",
      "loss: 0.890112  [10240/15909]\n",
      "loss: 0.927678  [10560/15909]\n",
      "loss: 0.926886  [10880/15909]\n",
      "loss: 0.940868  [11200/15909]\n",
      "loss: 0.988896  [11520/15909]\n",
      "loss: 0.937700  [11840/15909]\n",
      "loss: 0.930150  [12160/15909]\n",
      "loss: 0.942199  [12480/15909]\n",
      "loss: 0.909747  [12800/15909]\n",
      "loss: 1.006263  [13120/15909]\n",
      "loss: 1.020799  [13440/15909]\n",
      "loss: 0.942433  [13760/15909]\n",
      "loss: 0.983086  [14080/15909]\n",
      "loss: 0.928925  [14400/15909]\n",
      "loss: 0.893338  [14720/15909]\n",
      "loss: 0.964133  [15040/15909]\n",
      "loss: 0.927779  [15360/15909]\n",
      "loss: 0.930413  [15680/15909]\n",
      "\n",
      "Epoch 21 Summary:\n",
      "  Train Loss: 0.952505\n",
      "  Train Task Loss: 0.180338\n",
      "  Val Loss: 0.176685\n",
      "EarlyStopping counter: 5 out of 5\n",
      "Early stopping triggered. Saving final model to final_model.pth\n",
      "\n",
      "============================================================\n",
      "✓ Early stopping triggered!\n",
      "\n",
      "============================================================\n",
      "Final Test Loss: 0.169595\n",
      "============================================================\n",
      "\n",
      "✓ Knowledge Distillation Training Completed!\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# Training routine with EarlyStopping and scheduler for Knowledge Distillation\n",
    "def train_model_distillation(train_loader, val_loader, student_model, teacher_model, optimizer, device, \n",
    "                              num_epochs=25, patience=7, temperature=3.0, alpha=0.5):\n",
    "    \"\"\"\n",
    "    Train student model using knowledge distillation with EarlyStopping and scheduler.\n",
    "    \n",
    "    Args:\n",
    "        train_loader: Training data loader\n",
    "        val_loader: Validation data loader\n",
    "        student_model: Student model to train\n",
    "        teacher_model: Teacher model (frozen)\n",
    "        optimizer: Optimizer for student model\n",
    "        device: Device to train on\n",
    "        num_epochs: Maximum number of epochs\n",
    "        patience: EarlyStopping patience\n",
    "        temperature: Temperature for softening probability distributions\n",
    "        alpha: Weight between distillation and task loss\n",
    "    \"\"\"\n",
    "    early_stopping = EarlyStopping(patience=patience, verbose=True)\n",
    "    scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.5, patience=3, verbose=True)\n",
    "\n",
    "    history = {\n",
    "        'train_loss': [],\n",
    "        'val_loss': []\n",
    "    }\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        print(f\"\\nEpoch {epoch+1}/{num_epochs}\")\n",
    "        print(\"=\" * 60)\n",
    "        \n",
    "        # Training phase (distillation)\n",
    "        train_loss, task_loss = train_one_epoch_distillation(\n",
    "            train_loader, student_model, teacher_model, optimizer, device, \n",
    "            temperature=temperature, alpha=alpha\n",
    "        )\n",
    "        \n",
    "        # Validation phase (student only)\n",
    "        val_loss = evaluate_student_model(val_loader, student_model, device)\n",
    "\n",
    "        history['train_loss'].append(train_loss)\n",
    "        history['val_loss'].append(val_loss)\n",
    "\n",
    "        print(f\"\\nEpoch {epoch+1} Summary:\")\n",
    "        print(f\"  Train Loss: {train_loss:.6f}\")\n",
    "        print(f\"  Train Task Loss: {task_loss:.6f}\")\n",
    "        print(f\"  Val Loss: {val_loss:.6f}\")\n",
    "\n",
    "        scheduler.step(val_loss)\n",
    "        early_stopping(val_loss, student_model)\n",
    "        if early_stopping.early_stop:\n",
    "            print(\"\\n\" + \"=\" * 60)\n",
    "            print(\"✓ Early stopping triggered!\")\n",
    "            break\n",
    "\n",
    "    # Load best model\n",
    "    student_model.load_state_dict(torch.load('checkpoint.pt'))\n",
    "    plot_training_history(history)\n",
    "    return student_model, history\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Call the training function with distillation\n",
    "    patience = config['training']['patience'] if 'patience' in config['training'] else 7\n",
    "    \n",
    "    trained_student, training_history = train_model_distillation(\n",
    "        train_loader=train_loader,\n",
    "        val_loader=val_loader,\n",
    "        student_model=student_model,\n",
    "        teacher_model=teacher_model,\n",
    "        optimizer=optimizer,\n",
    "        device=device,\n",
    "        num_epochs=epochs,\n",
    "        patience=patience,\n",
    "        temperature=3.0,\n",
    "        alpha=0.5\n",
    "    )\n",
    "    \n",
    "    # Evaluate student on test set\n",
    "    test_loss = evaluate_student_model(test_loader, trained_student, device)\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"Final Test Loss: {test_loss:.6f}\")\n",
    "    print(f\"{'='*60}\")\n",
    "    \n",
    "    print(\"\\n✓ Knowledge Distillation Training Completed!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3d613940",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Comprehensive evaluation function defined!\n"
     ]
    }
   ],
   "source": [
    "# Comprehensive Teacher vs Student Model Evaluation\n",
    "def evaluate_model_comprehensive(dataloader, model, model_name, device):\n",
    "    \"\"\"\n",
    "    Comprehensive evaluation of a model on a dataset.\n",
    "    \n",
    "    Returns:\n",
    "        dict with loss, accuracy metrics, and predictions\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    val_loss = 0\n",
    "    eps = 1e-5\n",
    "    \n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for batch in dataloader:\n",
    "            X = batch[\"X\"].to(device)\n",
    "            y_true = batch[\"y\"].to(device)\n",
    "            \n",
    "            pred = model(X)\n",
    "            loss = -(y_true * torch.log(pred + eps)).mean(-1).sum(-1).mean()\n",
    "            val_loss += loss.item()\n",
    "            \n",
    "            all_preds.append(pred.cpu())\n",
    "            all_labels.append(y_true.cpu())\n",
    "    \n",
    "    avg_loss = val_loss / len(dataloader)\n",
    "    all_preds = torch.cat(all_preds, dim=0)\n",
    "    all_labels = torch.cat(all_labels, dim=0)\n",
    "    \n",
    "    # Calculate accuracy metrics\n",
    "    pred_classes = torch.argmax(all_preds, dim=1)  # (batch, time)\n",
    "    label_classes = torch.argmax(all_labels, dim=1)  # (batch, time)\n",
    "    \n",
    "    accuracy = (pred_classes == label_classes).float().mean().item()\n",
    "    \n",
    "    # Per-class accuracy\n",
    "    class_names = ['P-wave', 'S-wave', 'Noise']\n",
    "    per_class_acc = {}\n",
    "    \n",
    "    for i, class_name in enumerate(class_names):\n",
    "        mask = (label_classes == i)\n",
    "        if mask.sum() > 0:\n",
    "            per_class_acc[class_name] = (pred_classes[mask] == i).float().mean().item()\n",
    "        else:\n",
    "            per_class_acc[class_name] = 0.0\n",
    "    \n",
    "    results = {\n",
    "        'model_name': model_name,\n",
    "        'loss': avg_loss,\n",
    "        'accuracy': accuracy,\n",
    "        'per_class_accuracy': per_class_acc,\n",
    "        'predictions': all_preds,\n",
    "        'labels': all_labels\n",
    "    }\n",
    "    \n",
    "    return results\n",
    "\n",
    "\n",
    "print(\"✓ Comprehensive evaluation function defined!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d45e6306",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "MODEL PERFORMANCE COMPARISON: TEACHER vs STUDENT\n",
      "======================================================================\n",
      "\n",
      "📊 Evaluating Teacher Model (PhaseNet)...\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'test_loader' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 8\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;66;03m# Evaluate Teacher Model (PhaseNet)\u001b[39;00m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m📊 Evaluating Teacher Model (PhaseNet)...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m----> 8\u001b[0m teacher_results \u001b[38;5;241m=\u001b[39m evaluate_model_comprehensive(\u001b[43mtest_loader\u001b[49m, teacher_model, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPhaseNet\u001b[39m\u001b[38;5;124m\"\u001b[39m, device)\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m👨‍🏫 Teacher Model (PhaseNet) Results:\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m  Loss: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mteacher_results[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mloss\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.6f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'test_loader' is not defined"
     ]
    }
   ],
   "source": [
    "# Evaluate both Teacher and Student models on Test Set\n",
    "print(\"=\" * 70)\n",
    "print(\"MODEL PERFORMANCE COMPARISON: TEACHER vs STUDENT\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# Evaluate Teacher Model (PhaseNet)\n",
    "print(\"\\n📊 Evaluating Teacher Model (PhaseNet)...\")\n",
    "teacher_results = evaluate_model_comprehensive(test_loader, teacher_model, \"PhaseNet\", device)\n",
    "\n",
    "print(f\"\\n👨‍🏫 Teacher Model (PhaseNet) Results:\")\n",
    "print(f\"  Loss: {teacher_results['loss']:.6f}\")\n",
    "print(f\"  Overall Accuracy: {teacher_results['accuracy']*100:.2f}%\")\n",
    "print(f\"  Per-class Accuracy:\")\n",
    "for class_name, acc in teacher_results['per_class_accuracy'].items():\n",
    "    print(f\"    {class_name}: {acc*100:.2f}%\")\n",
    "\n",
    "# Evaluate Student Model (XiaoNet)\n",
    "print(\"\\n📊 Evaluating Student Model (XiaoNet)...\")\n",
    "student_results = evaluate_model_comprehensive(test_loader, student_model, \"XiaoNet\", device)\n",
    "\n",
    "print(f\"\\n👨‍🎓 Student Model (XiaoNet) Results:\")\n",
    "print(f\"  Loss: {student_results['loss']:.6f}\")\n",
    "print(f\"  Overall Accuracy: {student_results['accuracy']*100:.2f}%\")\n",
    "print(f\"  Per-class Accuracy:\")\n",
    "for class_name, acc in student_results['per_class_accuracy'].items():\n",
    "    print(f\"    {class_name}: {acc*100:.2f}%\")\n",
    "\n",
    "# Performance Comparison\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"📈 COMPARISON SUMMARY\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# Model size comparison\n",
    "teacher_params = sum(p.numel() for p in teacher_model.parameters())\n",
    "student_params = sum(p.numel() for p in student_model.parameters())\n",
    "\n",
    "print(f\"\\n🔢 Model Size:\")\n",
    "print(f\"  Teacher: {teacher_params:,} parameters ({teacher_params * 4 / (1024**2):.2f} MB)\")\n",
    "print(f\"  Student: {student_params:,} parameters ({student_params * 4 / (1024**2):.2f} MB)\")\n",
    "print(f\"  Reduction: {(1 - student_params/teacher_params)*100:.1f}%\")\n",
    "\n",
    "print(f\"\\n📉 Loss Comparison:\")\n",
    "print(f\"  Teacher Loss: {teacher_results['loss']:.6f}\")\n",
    "print(f\"  Student Loss: {student_results['loss']:.6f}\")\n",
    "print(f\"  Difference: {student_results['loss'] - teacher_results['loss']:.6f} ({((student_results['loss'] / teacher_results['loss']) - 1)*100:+.2f}%)\")\n",
    "\n",
    "print(f\"\\n🎯 Accuracy Comparison:\")\n",
    "print(f\"  Teacher Accuracy: {teacher_results['accuracy']*100:.2f}%\")\n",
    "print(f\"  Student Accuracy: {student_results['accuracy']*100:.2f}%\")\n",
    "print(f\"  Difference: {(student_results['accuracy'] - teacher_results['accuracy'])*100:+.2f}%\")\n",
    "\n",
    "print(f\"\\n📊 Per-Class Accuracy Comparison:\")\n",
    "for class_name in ['P-wave', 'S-wave', 'Noise']:\n",
    "    teacher_acc = teacher_results['per_class_accuracy'][class_name]\n",
    "    student_acc = student_results['per_class_accuracy'][class_name]\n",
    "    diff = (student_acc - teacher_acc) * 100\n",
    "    print(f\"  {class_name}:\")\n",
    "    print(f\"    Teacher: {teacher_acc*100:.2f}%  |  Student: {student_acc*100:.2f}%  |  Diff: {diff:+.2f}%\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"✓ Evaluation Complete!\")\n",
    "print(\"=\" * 70)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c9d5da7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize Predictions Comparison\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_prediction_comparison(teacher_pred, student_pred, true_label, sample_idx=0):\n",
    "    \"\"\"\n",
    "    Plot comparison of teacher and student predictions for a single sample.\n",
    "    \n",
    "    Args:\n",
    "        teacher_pred: Teacher model predictions (batch, 3, time)\n",
    "        student_pred: Student model predictions (batch, 3, time)\n",
    "        true_label: Ground truth labels (batch, 3, time)\n",
    "        sample_idx: Which sample from the batch to visualize\n",
    "    \"\"\"\n",
    "    fig, axes = plt.subplots(4, 1, figsize=(15, 12))\n",
    "    \n",
    "    class_names = ['P-wave', 'S-wave', 'Noise']\n",
    "    colors = ['red', 'blue', 'gray']\n",
    "    \n",
    "    # Plot ground truth\n",
    "    for i, (class_name, color) in enumerate(zip(class_names, colors)):\n",
    "        axes[0].plot(true_label[sample_idx, i, :].numpy(), \n",
    "                     label=class_name, color=color, alpha=0.7)\n",
    "    axes[0].set_title('Ground Truth Labels', fontsize=14, fontweight='bold')\n",
    "    axes[0].set_ylabel('Probability')\n",
    "    axes[0].legend(loc='upper right')\n",
    "    axes[0].grid(True, alpha=0.3)\n",
    "    axes[0].set_ylim([-0.05, 1.05])\n",
    "    \n",
    "    # Plot teacher predictions\n",
    "    for i, (class_name, color) in enumerate(zip(class_names, colors)):\n",
    "        axes[1].plot(teacher_pred[sample_idx, i, :].numpy(), \n",
    "                     label=class_name, color=color, alpha=0.7)\n",
    "    axes[1].set_title('Teacher Model (PhaseNet) Predictions', fontsize=14, fontweight='bold')\n",
    "    axes[1].set_ylabel('Probability')\n",
    "    axes[1].legend(loc='upper right')\n",
    "    axes[1].grid(True, alpha=0.3)\n",
    "    axes[1].set_ylim([-0.05, 1.05])\n",
    "    \n",
    "    # Plot student predictions\n",
    "    for i, (class_name, color) in enumerate(zip(class_names, colors)):\n",
    "        axes[2].plot(student_pred[sample_idx, i, :].numpy(), \n",
    "                     label=class_name, color=color, alpha=0.7)\n",
    "    axes[2].set_title('Student Model (XiaoNet) Predictions', fontsize=14, fontweight='bold')\n",
    "    axes[2].set_ylabel('Probability')\n",
    "    axes[2].legend(loc='upper right')\n",
    "    axes[2].grid(True, alpha=0.3)\n",
    "    axes[2].set_ylim([-0.05, 1.05])\n",
    "    \n",
    "    # Plot difference (Student - Teacher)\n",
    "    for i, (class_name, color) in enumerate(zip(class_names, colors)):\n",
    "        diff = student_pred[sample_idx, i, :].numpy() - teacher_pred[sample_idx, i, :].numpy()\n",
    "        axes[3].plot(diff, label=class_name, color=color, alpha=0.7)\n",
    "    axes[3].axhline(y=0, color='black', linestyle='--', alpha=0.5)\n",
    "    axes[3].set_title('Difference (Student - Teacher)', fontsize=14, fontweight='bold')\n",
    "    axes[3].set_ylabel('Probability Diff')\n",
    "    axes[3].set_xlabel('Time Sample')\n",
    "    axes[3].legend(loc='upper right')\n",
    "    axes[3].grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f'prediction_comparison_sample_{sample_idx}.png', dpi=150, bbox_inches='tight')\n",
    "    plt.show()\n",
    "    \n",
    "    print(f\"✓ Saved comparison plot: prediction_comparison_sample_{sample_idx}.png\")\n",
    "\n",
    "\n",
    "# Plot first 3 samples\n",
    "print(\"\\n📊 Generating prediction comparison plots...\")\n",
    "for i in range(min(3, teacher_results['predictions'].shape[0])):\n",
    "    plot_prediction_comparison(\n",
    "        teacher_results['predictions'],\n",
    "        student_results['predictions'],\n",
    "        teacher_results['labels'],\n",
    "        sample_idx=i\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ec15f73",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Performance Efficiency Metrics\n",
    "print(\"=\" * 70)\n",
    "print(\"⚡ EFFICIENCY METRICS\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# Calculate inference time\n",
    "import time\n",
    "\n",
    "def measure_inference_time(model, dataloader, device, num_batches=10):\n",
    "    \"\"\"Measure average inference time per batch.\"\"\"\n",
    "    model.eval()\n",
    "    times = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for i, batch in enumerate(dataloader):\n",
    "            if i >= num_batches:\n",
    "                break\n",
    "            \n",
    "            X = batch[\"X\"].to(device)\n",
    "            \n",
    "            start_time = time.time()\n",
    "            _ = model(X)\n",
    "            end_time = time.time()\n",
    "            \n",
    "            times.append(end_time - start_time)\n",
    "    \n",
    "    return np.mean(times), np.std(times)\n",
    "\n",
    "print(\"\\n⏱️ Measuring inference time...\")\n",
    "\n",
    "teacher_time, teacher_std = measure_inference_time(teacher_model, test_loader, device)\n",
    "student_time, student_std = measure_inference_time(student_model, test_loader, device)\n",
    "\n",
    "print(f\"\\nTeacher Model (PhaseNet):\")\n",
    "print(f\"  Avg inference time: {teacher_time*1000:.2f} ± {teacher_std*1000:.2f} ms/batch\")\n",
    "print(f\"  Samples per second: {batch_size / teacher_time:.1f}\")\n",
    "\n",
    "print(f\"\\nStudent Model (XiaoNet):\")\n",
    "print(f\"  Avg inference time: {student_time*1000:.2f} ± {student_std*1000:.2f} ms/batch\")\n",
    "print(f\"  Samples per second: {batch_size / student_time:.1f}\")\n",
    "\n",
    "speedup = teacher_time / student_time\n",
    "print(f\"\\n🚀 Speedup: {speedup:.2f}x faster\")\n",
    "\n",
    "# Compression ratio\n",
    "print(f\"\\n💾 Compression Metrics:\")\n",
    "print(f\"  Parameter reduction: {(1 - student_params/teacher_params)*100:.1f}%\")\n",
    "print(f\"  Size reduction: {teacher_params/student_params:.1f}x smaller\")\n",
    "\n",
    "# Efficiency score (accuracy per parameter)\n",
    "teacher_efficiency = teacher_results['accuracy'] / (teacher_params / 1e6)\n",
    "student_efficiency = student_results['accuracy'] / (student_params / 1e6)\n",
    "\n",
    "print(f\"\\n📈 Efficiency (Accuracy per Million Parameters):\")\n",
    "print(f\"  Teacher: {teacher_efficiency:.4f}\")\n",
    "print(f\"  Student: {student_efficiency:.4f}\")\n",
    "print(f\"  Student is {student_efficiency/teacher_efficiency:.2f}x more parameter-efficient\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"✓ Efficiency analysis complete!\")\n",
    "print(\"=\" * 70)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ML",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
